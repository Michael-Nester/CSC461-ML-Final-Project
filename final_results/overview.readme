Eye Color Prediction and Transformation
Project Overview
This project explores the use of machine learning to analyze, reconstruct, and manipulate eye features in images. Our primary goals were to classify eye colors and enable transformations to a user-specified hue. Using the UBIRIS.v2 dataset, we trained and evaluated models under real-world conditions with challenges such as occlusions, varying lighting, and image noise.

Final Model
The final model is a Convolutional Neural Network (CNN)-based autoencoder, which serves two main purposes:

Reconstruction: Deconstructs and reconstructs eye images while preserving spatial features, such as the iris, pupil, and surrounding details.
Transformation: Modifies the eye color by manipulating the latent space representation, enabling targeted adjustments while maintaining realistic details.
Key Features
Latent Space Representation: Encodes the eye image into a compressed latent vector, capturing its most salient features.
Dimensionality Reduction: Uses UMAP and t-SNE for visualizing the latent space and understanding clustering behavior.
CNN Architecture: Optimized for preserving spatial relationships, outperforming Multi-Layer Perceptron (MLP) approaches in reconstruction quality.
Dataset
The UBIRIS.v2 dataset, containing over 11,000 images, was utilized to train and evaluate the models. Images were labeled manually for eye color categories (e.g., blue, brown, green, hazel, and gray) to enable supervised learning.

Results
High-quality reconstructions of eye images, preserving key spatial features.
Latent space visualizations revealed clustering challenges, with broader features (e.g., face shape) being prioritized over subtle differences like eye color.
Insights gained into the tradeoff between latent vector size, reconstruction accuracy, and feature separability.
Future Directions
Integrating supervised components to improve clustering based on eye color.
Incorporating advanced architectures like Variational Autoencoders (VAEs) for better feature separability.
Applying statistical analyses to rigorously evaluate clustering and reconstruction performance.
Team Members
Aeyva Rebelo
Michael Nester
Esra Bequir
Repository Structure
/code: Python scripts for training, evaluation, and visualizations.
/data: Preprocessed and raw datasets (linked as necessary).
/results: Outputs, visualizations, and metrics from experiments.
Acknowledgment
This project utilized insights and support from OpenAI's ChatGPT for drafting, structuring, and refining analyses.
