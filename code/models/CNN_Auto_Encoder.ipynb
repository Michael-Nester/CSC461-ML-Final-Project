{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pre GPU CNN Autoencoder\n",
        "\n",
        "After researching the nature of an autoencoder as well as convolutional neural networks, we realized that it may be more effective to use an autencoder with CNN, rather than with MLP layers. This code also takes a very long time to run."
      ],
      "metadata": {
        "id": "tZD5qOqf9TsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NOTE: This code was generated using ChatGPT"
      ],
      "metadata": {
        "id": "evM25WLs9qpe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75QbJKew_DUK",
        "outputId": "4658070e-310a-44c5-ace8-679fb336b8c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Training autoencoder...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check for device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "num_epochs = 20\n",
        "image_size = (128, 128)  # Resize all images to 128x128\n",
        "latent_dim = 128  # Size of the bottleneck\n",
        "\n",
        "# Custom dataset class\n",
        "class EyeDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (str): Path to the CSV file with image names and labels.\n",
        "            img_dir (str): Directory with all the images.\n",
        "            transform (callable, optional): Transform to be applied on an image.\n",
        "        \"\"\"\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        z = 0\n",
        "        while z < 150:\n",
        "          img_name = os.path.join(self.img_dir, self.data.iloc[idx, 0])  # Image file path\n",
        "          image = Image.open(img_name).convert(\"RGB\")  # Load image as RGB\n",
        "          label = self.data.iloc[idx, 1]  # Eye color label (not used in autoencoder)\n",
        "\n",
        "          if self.transform:\n",
        "              image = self.transform(image)\n",
        "          z += 1\n",
        "        return image, label  # Return image and label\n",
        "\n",
        "# Paths to the dataset\n",
        "csv_file = \"/content/drive/MyDrive/ML final project/datasets/iris_labels_part1.csv\"  # Replace with the path to your .csv file\n",
        "img_dir = \"/content/drive/MyDrive/ML final project/datasets/CLASSES_400_300_Part1\"  # Replace with the path to the folder containing images\n",
        "\n",
        "# Transformations for the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),  # Resize to 128x128\n",
        "    transforms.ToTensor(),  # Convert to tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "dataset = EyeDataset(csv_file=csv_file, img_dir=img_dir, transform=transform)\n",
        "\n",
        "# Split dataset into training and validation sets (80/20 split)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define the Convolutional Autoencoder\n",
        "class ConvAutoencoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(ConvAutoencoder, self).__init__()\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),  # (64, 64, 64)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # (128, 32, 32)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),  # (256, 16, 16)\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 16 * 16, latent_dim),  # Bottleneck\n",
        "        )\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256 * 16 * 16),\n",
        "            nn.Unflatten(1, (256, 16, 16)),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),  # (128, 32, 32)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  # (64, 64, 64)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),  # (3, 128, 128)\n",
        "            nn.Tanh(),  # Output range [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = ConvAutoencoder(latent_dim=latent_dim).to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.MSELoss()  # Reconstruction loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training function\n",
        "def train(model, train_loader, criterion, optimizer, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = 0.0\n",
        "        for images, _ in train_loader:  # Ignore labels since this is unsupervised\n",
        "            images = images.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, images)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_loss = train_loss / len(train_loader)\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Validation function\n",
        "def validate(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, _ in val_loader:\n",
        "            images = images.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, images)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_loss = val_loss / len(val_loader)\n",
        "    print(f\"Validation Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Visualize some reconstructed images\n",
        "def visualize_reconstructions(model, data_loader):\n",
        "    model.eval()\n",
        "    images, _ = next(iter(data_loader))\n",
        "    images = images.to(device)\n",
        "    with torch.no_grad():\n",
        "        reconstructed = model(images)\n",
        "\n",
        "    # Unnormalize and plot the original and reconstructed images\n",
        "    images = images.cpu() * 0.5 + 0.5  # Unnormalize\n",
        "    reconstructed = reconstructed.cpu() * 0.5 + 0.5\n",
        "    fig, axes = plt.subplots(2, 6, figsize=(12, 4))\n",
        "\n",
        "    for i in range(6):\n",
        "        # Original images\n",
        "        axes[0, i].imshow(images[i].permute(1, 2, 0).numpy())\n",
        "        axes[0, i].axis(\"off\")\n",
        "        axes[0, i].set_title(\"Original\")\n",
        "\n",
        "        # Reconstructed images\n",
        "        axes[1, i].imshow(reconstructed[i].permute(1, 2, 0).numpy())\n",
        "        axes[1, i].axis(\"off\")\n",
        "        axes[1, i].set_title(\"Reconstructed\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Main script\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Training autoencoder...\")\n",
        "    train(model, train_loader, criterion, optimizer, num_epochs)\n",
        "    print(\"Validating autoencoder...\")\n",
        "    validate(model, val_loader, criterion)\n",
        "    print(\"Visualizing reconstructions...\")\n",
        "    visualize_reconstructions(model, val_loader)"
      ]
    }
  ]
}