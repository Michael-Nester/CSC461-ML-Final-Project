{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN_AE Test Implementation\n",
        "\n",
        "This was the first model we were able to successfully train on and save from the remote GPU server"
      ],
      "metadata": {
        "id": "6c7R9LPR-8kc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCUXQ_07fuii",
        "outputId": "f984cc47-27db-4d8d-cc6c-9cacecd6d624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-02412dc89f7c>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/content/drive/MyDrive/ML final project/Trained_models/trained_model'))\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/ML final project/code')\n",
        "\n",
        "# Import the AutoEncoder class\n",
        "from csc461_cnn_ae import Autoencoder\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Load the autoencoder model\n",
        "model = Autoencoder(64)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/ML final project/Trained_models/trained_model'))\n",
        "model.eval()\n",
        "\n",
        "\n",
        "# Load the input eye image\n",
        "eye_image = Image.open('/content/drive/MyDrive/ML final project/datasets/SingleEyeTest/eye2.jpg')  # Replace with image path\n",
        "\n",
        "# Define preprocessing transforms\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Match model's input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Match training normalization\n",
        "])\n",
        "\n",
        "# Preprocess the image\n",
        "input_tensor = preprocess(eye_image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Get the reconstruction\n",
        "with torch.no_grad():\n",
        "    reconstructed_image = model.encoder(input_tensor)\n",
        "\n",
        "\n",
        "# Convert reconstructed image to numpy\n",
        "reconstructed_image_np = reconstructed_image.squeeze(0).permute(1, 2, 0).numpy()\n",
        "reconstructed_image_np = ((reconstructed_image_np + 1) * 127.5).astype(np.uint8)  # Denormalize\n",
        "\n",
        "# Convert to BGR for OpenCV\n",
        "reconstructed_image_bgr = cv2.cvtColor(reconstructed_image_np, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "# Create an iris mask (assume circular iris in the center)\n",
        "height, width, _ = reconstructed_image_bgr.shape\n",
        "center = (width // 2, height // 2)\n",
        "radius = min(height, width) // 4  # Adjust based on images\n",
        "\n",
        "mask = np.zeros((height, width), dtype=np.uint8)\n",
        "cv2.circle(mask, center, radius, (255), thickness=-1)  # Create circular mask\n",
        "\n",
        "# Blend blue hue with the iris\n",
        "blue_color = np.array([255, 0, 0], dtype=np.uint8)  # Blue in BGR for OpenCV\n",
        "blue_layer = np.zeros_like(reconstructed_image_bgr)\n",
        "blue_layer[:] = blue_color\n",
        "\n",
        "# Apply the mask to the blue layer\n",
        "iris_hue = cv2.bitwise_and(blue_layer, blue_layer, mask=mask)\n",
        "reconstructed_with_hue = cv2.addWeighted(reconstructed_image_bgr, 1.0, iris_hue, 0.5, 0)\n",
        "\n",
        "# Convert back to RGB and save\n",
        "final_image = cv2.cvtColor(reconstructed_with_hue, cv2.COLOR_BGR2RGB)\n",
        "final_pil_image = Image.fromarray(final_image)\n",
        "final_pil_image.save(\"/content/drive/MyDrive/ML final project/TestResults/output_eye_with_blue_hue_2.jpg\")\n",
        "final_pil_image.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/ML final project/code')\n",
        "\n",
        "# Import the Autoencoder class\n",
        "from csc461_cnn_ae import Autoencoder\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Precomputed color embeddings (replace with actual precomputed embeddings)\n",
        "color_embeddings = {\n",
        "    \"blue\": torch.load('/content/drive/MyDrive/ML final project/ColorEmbeddings/blue.pt'),\n",
        "    \"brown\": torch.load('/content/drive/MyDrive/ML final project/ColorEmbeddings/brown.pt'),\n",
        "    \"green\": torch.load('/content/drive/MyDrive/ML final project/ColorEmbeddings/green.pt'),\n",
        "    \"gray\": torch.load('/content/drive/MyDrive/ML final project/ColorEmbeddings/gray.pt'),\n",
        "    \"hazel\": torch.load('/content/drive/MyDrive/ML final project/ColorEmbeddings/hazel.pt')\n",
        "}\n",
        "\n",
        "# Load the autoencoder model\n",
        "model = Autoencoder(64)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/ML final project/Trained_models/trained_model_1.1'))\n",
        "model.eval()\n",
        "\n",
        "# Define preprocessing transforms\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Match your model's input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Match your training normalization\n",
        "])\n",
        "\n",
        "def change_eye_color(eye_image_path, desired_color):\n",
        "    \"\"\"\n",
        "    Change the eye color of the input image to the desired color.\n",
        "\n",
        "    Args:\n",
        "        eye_image_path (str): Path to the input eye image.\n",
        "        desired_color (str): Desired eye color (\"blue\", \"brown\", \"green\", \"gray\", \"hazel\").\n",
        "\n",
        "    Returns:\n",
        "        PIL.Image: Image with the modified eye color.\n",
        "    \"\"\"\n",
        "    # Load and preprocess the input eye image\n",
        "    eye_image = Image.open(eye_image_path)\n",
        "    input_tensor = preprocess(eye_image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    # Get the embedding for the input image\n",
        "    with torch.no_grad():\n",
        "        input_embedding = model.encoder(input_tensor)\n",
        "\n",
        "    # Retrieve the embedding for the desired color\n",
        "    if desired_color not in color_embeddings:\n",
        "        raise ValueError(f\"Invalid color: {desired_color}. Choose from {list(color_embeddings.keys())}.\")\n",
        "    desired_color_embedding = color_embeddings[desired_color]\n",
        "\n",
        "    # Combine the embeddings (simple addition; modify if needed for your use case)\n",
        "    modified_embedding = input_embedding + desired_color_embedding\n",
        "\n",
        "    # Decode the modified embedding to get the output image\n",
        "    with torch.no_grad():\n",
        "        output_tensor = model.decoder(modified_embedding)\n",
        "\n",
        "    # Convert the output tensor to an image\n",
        "    output_image_np = output_tensor.squeeze(0).permute(1, 2, 0).numpy()\n",
        "    output_image_np = ((output_image_np + 1) * 127.5).astype(np.uint8)  # Denormalize\n",
        "\n",
        "    # Convert to RGB format\n",
        "    output_image_rgb = cv2.cvtColor(output_image_np, cv2.COLOR_BGR2RGB)\n",
        "    final_pil_image = Image.fromarray(output_image_rgb)\n",
        "\n",
        "    return final_pil_image\n",
        "\n",
        "# Example usage\n",
        "output_image = change_eye_color('/content/drive/MyDrive/ML final project/datasets/SingleEyeTest/eye2.jpg', 'blue')\n",
        "output_image.save('/content/drive/MyDrive/ML final project/TestResults/output_eye_with_blue.jpg')\n",
        "output_image.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJkGN7HD00fM",
        "outputId": "76fbb0fb-a06b-4adb-8978-09d82716ba48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-f5f1f409643f>:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  \"blue\": torch.load('/content/drive/MyDrive/ML final project/ColorEmbeddings/blue.pt'),\n",
            "<ipython-input-3-f5f1f409643f>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  \"brown\": torch.load('/content/drive/MyDrive/ML final project/ColorEmbeddings/brown.pt'),\n",
            "<ipython-input-3-f5f1f409643f>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  \"green\": torch.load('/content/drive/MyDrive/ML final project/ColorEmbeddings/green.pt'),\n",
            "<ipython-input-3-f5f1f409643f>:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  \"gray\": torch.load('/content/drive/MyDrive/ML final project/ColorEmbeddings/gray.pt'),\n",
            "<ipython-input-3-f5f1f409643f>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  \"hazel\": torch.load('/content/drive/MyDrive/ML final project/ColorEmbeddings/hazel.pt')\n",
            "<ipython-input-3-f5f1f409643f>:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/content/drive/MyDrive/ML final project/Trained_models/trained_model_1.1'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/ML final project/code')\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from csc461_cnn_ae import Autoencoder\n",
        "\n",
        "# Define preprocessing transforms\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Match your model's input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Match your training normalization\n",
        "])\n",
        "\n",
        "# Load the trained autoencoder model\n",
        "model = Autoencoder(64)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/ML final project/Trained_models/trained_model_1.1'))\n",
        "model.eval()\n",
        "\n",
        "def get_embedding_from_reconstructed_image(image_path, model):\n",
        "    \"\"\"\n",
        "    Derive the embedding from a reconstructed image using the model's encoder.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the reconstructed image.\n",
        "        model: Trained autoencoder model.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Embedding for the reconstructed image.\n",
        "    \"\"\"\n",
        "    # Load and preprocess the image\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    input_tensor = preprocess(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    # Generate embedding\n",
        "    with torch.no_grad():\n",
        "        embedding = model.encoder(input_tensor)\n",
        "    return embedding.squeeze(0)  # Remove batch dimension\n",
        "\n",
        "# Define the paths for each reconstructed image\n",
        "reconstructed_images = {\n",
        "    \"blue\": \"/content/drive/MyDrive/ML final project/reconstructed_imgs/blue.jpg\",\n",
        "    \"brown\": \"/content/drive/MyDrive/ML final project/reconstructed_imgs/brown.jpg\",\n",
        "    \"green\": \"/content/drive/MyDrive/ML final project/reconstructed_imgs/green.jpg\",\n",
        "    \"gray\": \"/content/drive/MyDrive/ML final project/reconstructed_imgs/gray.jpg\",\n",
        "    \"hazel\": \"/content/drive/MyDrive/ML final project/reconstructed_imgs/hazel.jpg\"\n",
        "}\n",
        "\n",
        "# Compute and save embeddings\n",
        "color_embeddings = {}\n",
        "for color, image_path in reconstructed_images.items():\n",
        "    try:\n",
        "        print(f\"Processing {color} reconstructed image...\")\n",
        "        embedding = get_embedding_from_reconstructed_image(image_path, model)\n",
        "        color_embeddings[color] = embedding\n",
        "        torch.save(embedding, f\"/content/drive/MyDrive/ML final project/ColorEmbeddings/{color}.pt\")\n",
        "        print(f\"Saved embedding for {color}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {color} image: {e}\")\n"
      ],
      "metadata": {
        "id": "_fPNpbZ8jYr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce761d62-8a24-48c7-9c45-faaec55bef56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2ce74c7dec56>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/content/drive/MyDrive/ML final project/Trained_models/trained_model_1.1'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing blue reconstructed image...\n",
            "Saved embedding for blue.\n",
            "Processing brown reconstructed image...\n",
            "Saved embedding for brown.\n",
            "Processing green reconstructed image...\n",
            "Saved embedding for green.\n",
            "Processing gray reconstructed image...\n",
            "Saved embedding for gray.\n",
            "Processing hazel reconstructed image...\n",
            "Saved embedding for hazel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9fROwiPwsqVp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}