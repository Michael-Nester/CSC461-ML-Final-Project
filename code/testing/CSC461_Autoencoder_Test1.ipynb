{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n"
      ],
      "metadata": {
        "id": "7cb3Xg9GPIRe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume the data is in a directory called 'eye_images'\n",
        "data_dir = '/content/drive/MyDrive/ML final project/datasets/CLASSES_400_300_Part2/'\n",
        "\n",
        "# Load the images\n",
        "X = []\n",
        "for filename in os.listdir(data_dir):\n",
        "    if filename.endswith('.tiff'):\n",
        "        img = Image.open(os.path.join(data_dir, filename))\n",
        "        img = img.resize((img.width // 2, img.height // 2))  # Example: downsample by 2x\n",
        "        X.append(np.array(img))\n",
        "        X.append(np.array(img))\n",
        "X = np.array(X)\n",
        "\n",
        "# Normalize the data\n",
        "X = X / 255.0"
      ],
      "metadata": {
        "id": "zyqc1NeyPH3C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define the autoencoder model\n",
        "\"\"\"\n",
        "model = Sequential()\n",
        "input_layer = Input(shape=X.shape[1:])\n",
        "\n",
        "# Define the rest of the model\n",
        "model.addFlatten()(input_layer)\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "total_elements = np.prod(X.shape[1:])\n",
        "model.add(Dense(total_elements, activation='relu')) # Expanding to the total number of elements before reshaping\n",
        "model.add(Reshape(X.shape[1:]))\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "input_layer = Input(shape=X.shape[1:])\n",
        "\n",
        "# Define the rest of the model\n",
        "x = Flatten()(input_layer)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "total_elements = np.prod(X.shape[1:])\n",
        "x = Dense(total_elements, activation='relu')(x) # Expanding to the total number of elements before reshaping\n",
        "\n",
        "output_layer = Reshape(X.shape[1:])(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "\n",
        "\n",
        "# Train the autoencoder\n",
        "model.fit(X, X, epochs=100, batch_size=4, shuffle=True, validation_split=0.2)\n",
        "\n",
        "# Extract the iris color vectors\n",
        "iris_vectors = model.predict(X)\n",
        "\n",
        "print(iris_vectors)\n",
        "del iris_vectors\n",
        "import gc; gc.collect()\n",
        "reconstructed_images = model.predict(X)\n",
        "for i in range(10):\n",
        "    original_image = X[i]\n",
        "    reconstructed_image = reconstructed_images[i]\n",
        "    # Display the original and reconstructed images for comparison\n",
        "    print(f\"Original Image {i + 1}:\")\n",
        "    Image.fromarray((original_image * 255).astype(np.uint8)).show()"
      ],
      "metadata": {
        "id": "Breo94_PEgbN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
