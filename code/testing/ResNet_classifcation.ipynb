{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Model Testing From ResNet Model\n",
        "\n",
        "The following is a series of tests done using a ResNet model that was trained over the GPU server, using the UBIRIS_V2 dataset."
      ],
      "metadata": {
        "id": "EJbzD7SlHWG5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVK5ldvw0qzX",
        "outputId": "cbe27a86-c05f-4c24-be6f-a7edb29f7e4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niX_2BMZZbWY",
        "outputId": "600fcd2a-b3eb-4259-8e31-4a6dcdca868a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MoQkz50sEw4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import WeightedRandomSampler\n"
      ],
      "metadata": {
        "id": "EvXECbQ81dWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your saved model using torch.load()\n",
        "model_path = '/content/drive/MyDrive/ML final project/Trained_models/Classifier/ResNet_best_eye_color_classifier.pth'\n",
        "loaded_state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "#loaded_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ROGkelCa6N7",
        "outputId": "b46fc9b6-2fea-473c-b683-6ce37bbf8a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-911f54fa329a>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet Test 1\n",
        "Using resnet50, a test was done to upload, preprocess, and classify images"
      ],
      "metadata": {
        "id": "hjJ0tCFjHJ6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained ResNet50 model with ImageNet weights\n",
        "model = ResNet50(weights='imagenet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnQTUiUv12vm",
        "outputId": "7871a283-aaa8-4173-910d-b178529e8608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m102967424/102967424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load the uploaded image\n",
        "img_path = next(iter(uploaded))  # Get the first uploaded image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "Gd9ZjoLV17lz",
        "outputId": "2a9786e3-271d-4833-dce0-20f040b8657c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-993dd9bc-def6-4e10-86c6-8302c21a4265\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-993dd9bc-def6-4e10-86c6-8302c21a4265\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4e156124616b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the uploaded image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Get the first uploaded image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the image for ResNet50\n",
        "img = image.load_img(img_path, target_size=(224, 224))  # Resize to 224x224 (required by ResNet)\n",
        "img_array = image.img_to_array(img)  # Convert image to array\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "img_array = preprocess_input(img_array)  # Preprocess the image for ResNet50\n"
      ],
      "metadata": {
        "id": "9vIxTmC1EycY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "81956e11-3b87-47c3-cc91-be4e5064f319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'img_path' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-8e04c0900a79>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load and preprocess the image for ResNet50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Resize to 224x224 (required by ResNet)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert image to array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Add batch dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Preprocess the image for ResNet50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'img_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the class of the image\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "# Decode the predictions to human-readable labels\n",
        "decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
        "\n",
        "# Print the top 3 predictions\n",
        "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
        "    print(f\"{i+1}: {label} ({score:.2f})\")\n"
      ],
      "metadata": {
        "id": "S3bVRKY2E0iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1: spotted_dove (0.95)\n",
        "2: ringed_plover (0.02)\n",
        "3: eggplant (0.01)\n"
      ],
      "metadata": {
        "id": "8u13XMSkE2bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# Remove the top layer and add a new custom layer\n",
        "x = model.output\n",
        "x = GlobalAveragePooling2D()(x)  # Pooling layer\n",
        "x = Dense(512, activation='relu')(x)  # Fully connected layer\n",
        "x = Dense(num_eye_colors, activation='softmax')(x)  # Softmax output layer for eye color classification\n",
        "\n",
        "# Create the new model\n",
        "custom_model = tf.keras.Model(inputs=model.input, outputs=x)\n",
        "\n",
        "# Freeze the layers of ResNet50 and train only the new layers\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile and train the model\n",
        "custom_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "98dX31L6E4MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet Test 2\n",
        "\n",
        "Below is code used to load a trained model ResNet, that used the UBIRIS_v2 data for training and validation."
      ],
      "metadata": {
        "id": "R6UXqAZbAq1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class EyeColorPredictor:\n",
        "    def __init__(self, model_path):\n",
        "        # Load the saved model and mapping\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        checkpoint = torch.load(model_path, map_location=self.device)\n",
        "\n",
        "        # Get the color mapping\n",
        "        self.color_to_idx = checkpoint['color_to_idx']\n",
        "        self.idx_to_color = {v: k for k, v in self.color_to_idx.items()}\n",
        "\n",
        "        # Initialize and load the model\n",
        "        self.model = self.setup_model(len(self.color_to_idx))\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.model.eval()\n",
        "\n",
        "        # Setup image transforms\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def setup_model(self, num_classes):\n",
        "        model = models.resnet50(pretrained=False)\n",
        "        num_features = model.fc.in_features\n",
        "        model.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_features, num_classes)\n",
        "        )\n",
        "        model = model.to(self.device)\n",
        "        return model\n",
        "\n",
        "    def predict(self, image_path):\n",
        "        \"\"\"\n",
        "        Predict eye color from an image\n",
        "\n",
        "        Args:\n",
        "            image_path (str): Path to the image file\n",
        "\n",
        "        Returns:\n",
        "            tuple: (predicted_color, confidence_score)\n",
        "        \"\"\"\n",
        "        # Load and preprocess the image\n",
        "        try:\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            image_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
        "\n",
        "            # Get prediction\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(image_tensor)\n",
        "                probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "\n",
        "                # Get the predicted class and confidence\n",
        "                confidence, predicted = torch.max(probabilities, 1)\n",
        "                predicted_color = self.idx_to_color[predicted.item()]\n",
        "                confidence_score = confidence.item()\n",
        "\n",
        "                # Get top-3 predictions\n",
        "                top3_prob, top3_indices = torch.topk(probabilities, 3)\n",
        "                top3_predictions = [\n",
        "                    (self.idx_to_color[idx.item()], prob.item())\n",
        "                    for idx, prob in zip(top3_indices[0], top3_prob[0])\n",
        "                ]\n",
        "\n",
        "                return {\n",
        "                    'predicted_color': predicted_color,\n",
        "                    'confidence': confidence_score,\n",
        "                    'top3_predictions': top3_predictions\n",
        "                }\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error processing image: {str(e)}\"\n",
        "\n",
        "def main():\n",
        "    # Initialize predictor\n",
        "    model_path = '/content/drive/MyDrive/ML final project/Trained_models/Classifier/ResNet_best_eye_color_classifier2.pth'\n",
        "    predictor = EyeColorPredictor(model_path)\n",
        "\n",
        "    # Example usage\n",
        "    #while True:\n",
        "    image_path = ('/content/drive/MyDrive/ML final project/our_eyes/IMG_1636.JPG') #Mcihael\n",
        "    #image_path = ('/content/drive/MyDrive/ML final project/our_eyes/IMG_1644.JPG') #Esra\n",
        "    #image_path = ('/content/drive/MyDrive/ML final project/our_eyes/IMG_1650.JPG') #Aeyva\n",
        "    #if not image_path:\n",
        "    #    continue\n",
        "\n",
        "    # Make prediction\n",
        "    result = predictor.predict(image_path)\n",
        "\n",
        "    if isinstance(result, dict):\n",
        "        print(\"\\nResults:\")\n",
        "        print(f\"Predicted Eye Color: {result['predicted_color']}\")\n",
        "        print(f\"Confidence: {result['confidence']*100:.2f}%\")\n",
        "\n",
        "        print(\"\\nTop 3 Predictions:\")\n",
        "        for color, prob in result['top3_predictions']:\n",
        "            print(f\"{color}: {prob*100:.2f}%\")\n",
        "    else:\n",
        "        print(result)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EulpNILuzrwh",
        "outputId": "3cfeeb79-5211-4a28-a5b2-771794629271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-f1e24c1775c2>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_path, map_location=self.device)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results:\n",
            "Predicted Eye Color: brown\n",
            "Confidence: 47.01%\n",
            "\n",
            "Top 3 Predictions:\n",
            "brown: 47.01%\n",
            "hazel: 27.46%\n",
            "blue: 11.72%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet Test 3\n",
        "\n",
        "Below is code for loading and testing an enhanced version of the above model, using the resnet50 and plots from the first cells."
      ],
      "metadata": {
        "id": "EfvwiH4gAziR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EyeColorVisualizer:\n",
        "    def __init__(self, model_path):\n",
        "        # Load the saved model\n",
        "        self.checkpoint = torch.load(model_path, map_location='cpu')\n",
        "        self.color_to_idx = self.checkpoint['color_to_idx']\n",
        "        self.idx_to_color = {v: k for k, v in self.color_to_idx.items()}\n",
        "\n",
        "        # Initialize and load the model\n",
        "        self.model = self.setup_model(len(self.color_to_idx))\n",
        "        self.model.load_state_dict(self.checkpoint['model_state_dict'])\n",
        "        self.model.eval()\n",
        "\n",
        "        # Create color mapping for visualization\n",
        "        self.color_map = {\n",
        "            'brown': '#8B4513',\n",
        "            'blue': '#0000FF',\n",
        "            'green': '#008000',\n",
        "            'gray': '#808080',\n",
        "            'hazel': '#8E7618'\n",
        "        }\n",
        "\n",
        "    def setup_model(self, num_classes):\n",
        "        # Load pre-trained ResNet50\n",
        "        model = models.resnet50(pretrained=False)\n",
        "\n",
        "        # Add feature extraction method\n",
        "        def get_features(self, x):\n",
        "            x = self.conv1(x)\n",
        "            x = self.bn1(x)\n",
        "            x = self.relu(x)\n",
        "            x = self.maxpool(x)\n",
        "\n",
        "            x = self.layer1(x)\n",
        "            x = self.layer2(x)\n",
        "            x = self.layer3(x)\n",
        "            x = self.layer4(x)\n",
        "\n",
        "            x = self.avgpool(x)\n",
        "            x = torch.flatten(x, 1)\n",
        "            return x\n",
        "\n",
        "        model.get_features = get_features.__get__(model)\n",
        "\n",
        "        # Modify the final layer\n",
        "        num_features = model.fc.in_features\n",
        "        model.fc = nn.Sequential(\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(num_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def plot_feature_space(self, features, labels):\n",
        "        \"\"\"Plot t-SNE visualization of feature space\"\"\"\n",
        "        # Reduce dimensionality using t-SNE\n",
        "        tsne = TSNE(n_components=2, random_state=42)\n",
        "        features_2d = tsne.fit_transform(features)\n",
        "\n",
        "        # Create plot\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        for idx in range(len(self.color_to_idx)):\n",
        "            mask = labels == idx\n",
        "            color = self.color_map.get(self.idx_to_color[idx], '#000000')\n",
        "            plt.scatter(features_2d[mask, 0], features_2d[mask, 1],\n",
        "                       c=color, label=self.idx_to_color[idx], alpha=0.6)\n",
        "\n",
        "        plt.title('t-SNE Visualization of Eye Color Features')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_confusion_matrix(self, true_labels, predicted_labels):\n",
        "        \"\"\"Plot enhanced confusion matrix\"\"\"\n",
        "        cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "        # Calculate percentages\n",
        "        cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
        "\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        sns.heatmap(cm_percent, annot=True, fmt='.1f',\n",
        "                    xticklabels=self.color_to_idx.keys(),\n",
        "                    yticklabels=self.color_to_idx.keys(),\n",
        "                    cmap='YlOrRd')\n",
        "\n",
        "        plt.title('Confusion Matrix (Percentage)')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "\n",
        "        # Add total counts\n",
        "        class_counts = np.sum(cm, axis=1)\n",
        "        for i, count in enumerate(class_counts):\n",
        "            plt.text(-0.5, i, f'n={count}', va='center')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_loss_history(self):\n",
        "        \"\"\"Plot training history\"\"\"\n",
        "        losses = np.loadtxt('/content/drive/MyDrive/ML final project/Trained_models/Classifier/losses.txt', delimiter=',', skiprows=1)\n",
        "\n",
        "        epochs = losses[:, 0]\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(epochs, losses[:, 1], label='Training Loss')\n",
        "        plt.plot(epochs, losses[:, 2], label='Validation Loss')\n",
        "        plt.title('Training History')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "2Hllk32E0SYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, image_dir, labels_csv):\n",
        "        self.image_dir = image_dir\n",
        "\n",
        "        # Read labels\n",
        "        print(f\"Loading CSV from: {labels_csv}\")\n",
        "        df = pd.read_csv(labels_csv)\n",
        "        print(f\"CSV shape: {df.shape}\")\n",
        "        print(\"First few rows of CSV:\")\n",
        "        print(df.head())\n",
        "\n",
        "        # Get list of available images\n",
        "        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith('.tiff') or f.endswith('.jpg')])\n",
        "        print(f\"\\nFound {len(self.image_files)} images in directory\")\n",
        "        print(\"First few image files:\", self.image_files[:5])\n",
        "\n",
        "        # Match images with labels\n",
        "        valid_images = []\n",
        "        valid_labels = []\n",
        "\n",
        "        for img_file in self.image_files:\n",
        "            label_row = df[df['filename'] == img_file]\n",
        "            if not label_row.empty:\n",
        "                valid_images.append(img_file)\n",
        "                valid_labels.append(label_row['label'].iloc[0])\n",
        "\n",
        "        self.image_names = valid_images\n",
        "        self.labels = torch.tensor([df['label'].unique().tolist().index(label) for label in valid_labels], dtype=torch.long)\n",
        "\n",
        "        print(f\"\\nSuccessfully matched {len(self.image_names)} images with labels\")\n",
        "        print(f\"Unique labels: {df['label'].unique()}\")\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            img_path = os.path.join(self.image_dir, self.image_names[idx])\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            image = self.transform(image)\n",
        "            return image, self.labels[idx]\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {self.image_names[idx]}: {str(e)}\")\n",
        "            return None\n"
      ],
      "metadata": {
        "id": "eY-rF1FOJAl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features_and_predictions(model, data_loader, device):\n",
        "    model.eval()\n",
        "    features = []\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    print(\"Starting feature extraction...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(data_loader):\n",
        "            # Debug the batch format\n",
        "            print(f\"\\nBatch {batch_idx} type: {type(batch)}\")\n",
        "            print(f\"Batch {batch_idx} content: {batch}\")\n",
        "\n",
        "            # Handle None returns from dataset\n",
        "            if batch is None:\n",
        "                print(f\"Skipping batch {batch_idx} (None)\")\n",
        "                continue\n",
        "\n",
        "            # Try to unpack batch differently\n",
        "            try:\n",
        "                if isinstance(batch, (list, tuple)):\n",
        "                    images, labels = batch\n",
        "                    if isinstance(batch[0], torch.Tensor):\n",
        "                        images = batch[0].unsqueeze(0)\n",
        "                        labels = torch.tensor([batch[1]], device=device)\n",
        "                    else:\n",
        "                        images = torch.stack([item[0] for item in batch])\n",
        "                        labels = torch.tensor([item[1] for item in batch])\n",
        "                else:\n",
        "                    print(f\"Unexpected batch format in batch {batch_idx}: {type(batch)}\")\n",
        "                    continue\n",
        "\n",
        "                print(f\"Successfully unpacked batch {batch_idx}\")\n",
        "                print(f\"Images shape: {images.shape if hasattr(images, 'shape') else 'no shape'}\")\n",
        "                print(f\"Labels shape: {labels.shape if hasattr(labels, 'shape') else 'no shape'}\")\n",
        "\n",
        "                # Ensure tensors are on the correct device\n",
        "                images = images.to(device)\n",
        "                if not isinstance(labels, torch.Tensor):\n",
        "                    labels = torch.tensor(labels, device=device)\n",
        "                else:\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                # Get features and predictions\n",
        "                feature_vector = model.get_features(images)\n",
        "                outputs = model(images)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                features.append(feature_vector.cpu().numpy())\n",
        "                true_labels.extend(labels.cpu().numpy())\n",
        "                predicted_labels.extend(preds.cpu().numpy())\n",
        "\n",
        "                print(f\"Successfully processed batch {batch_idx}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing batch {batch_idx}: {str(e)}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                continue\n",
        "\n",
        "    print(f\"\\nExtracted features from {len(features)} batches\")\n",
        "\n",
        "    if len(features) == 0:\n",
        "        raise ValueError(\"No features were extracted. Check your data loader.\")\n",
        "\n",
        "    return np.concatenate(features), np.array(true_labels), np.array(predicted_labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "exf0K1EfJFZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and visualize the data\n",
        "print(\"Loading test data...\")\n",
        "test_data = TestDataset(\n",
        "    image_dir='/content/drive/MyDrive/ML final project/datasets/CLASSES_400_300_Part1',\n",
        "    labels_csv='/content/drive/MyDrive/ML final project/datasets/iris_labels_part1.csv'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFY3oXsMJJow",
        "outputId": "597de05a-e08f-4855-f8c3-0c0b52b788e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test data...\n",
            "Loading CSV from: /content/drive/MyDrive/ML final project/datasets/iris_labels_part1.csv\n",
            "CSV shape: (6412, 2)\n",
            "First few rows of CSV:\n",
            "        filename  label\n",
            "0  C1_S1_I1.tiff  brown\n",
            "1  C1_S1_I2.tiff  brown\n",
            "2  C1_S1_I3.tiff  brown\n",
            "3  C1_S1_I4.tiff  brown\n",
            "4  C1_S1_I5.tiff  brown\n",
            "\n",
            "Found 5799 images in directory\n",
            "First few image files: ['C100_S1_I1.tiff', 'C100_S1_I10.tiff', 'C100_S1_I11.tiff', 'C100_S1_I12.tiff', 'C100_S1_I13.tiff']\n",
            "\n",
            "Successfully matched 5799 images with labels\n",
            "Unique labels: ['brown' 'hazel' 'blue' 'green']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize the EyeColorVisualizer\n",
        "model_path = '/content/drive/MyDrive/ML final project/Trained_models/Classifier/best_eye_color_classifier3.pth'  # Update with your model path\n",
        "visualizer = EyeColorVisualizer(model_path)\n",
        "\n",
        "print(f\"\\nCreating data loader with {len(test_data)} samples\")\n",
        "test_loader = DataLoader(\n",
        "    test_data,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=0,  # Set to 0 for debugging\n",
        "    drop_last=False,\n",
        "    collate_fn=lambda x: x[0] if x[0] is not None else None  # Handle None returns\n",
        ")\n",
        "\n",
        "print(\"\\nExtracting features...\")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "test_features, true_labels, predicted_labels = extract_features_and_predictions(\n",
        "    visualizer.model,\n",
        "    test_loader,\n",
        "    device\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mydFnA9s-nU_",
        "outputId": "2d4da1d5-8565-4834-c56e-65d3008fc779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-cc16d9de986b>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.checkpoint = torch.load(model_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "         [-1.0724, -1.1247, -0.9330,  ..., -0.8633, -0.8284, -0.5495],\n",
            "         [-1.1770, -1.1770, -0.9853,  ..., -0.7413, -0.8284, -0.6715],\n",
            "         ...,\n",
            "         [ 0.1476,  0.1999,  0.2871,  ...,  0.0953,  0.0605,  0.0082],\n",
            "         [ 0.1999,  0.2348,  0.2696,  ...,  0.0431,  0.0431,  0.0256],\n",
            "         [ 0.2871,  0.2696,  0.3045,  ...,  0.0082,  0.0082,  0.0256]]]), tensor(0))\n",
            "Successfully unpacked batch 9\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 9\n",
            "\n",
            "Batch 10 type: <class 'tuple'>\n",
            "Batch 10 content: (tensor([[[-0.5767, -0.6965, -0.7308,  ..., -0.8849, -0.7479, -0.6623],\n",
            "         [-0.6109, -0.7479, -0.7993,  ..., -0.7993, -0.6965, -0.6281],\n",
            "         [-0.6281, -0.7479, -0.7993,  ..., -0.6965, -0.6452, -0.5596],\n",
            "         ...,\n",
            "         [ 0.9303,  0.8618,  0.8276,  ...,  0.3481,  0.2624,  0.2796],\n",
            "         [ 0.9132,  0.8789,  0.8618,  ...,  0.3481,  0.3138,  0.2624],\n",
            "         [ 0.8961,  0.8961,  0.8789,  ...,  0.3481,  0.2967,  0.2624]],\n",
            "\n",
            "        [[-0.8452, -0.9503, -0.9328,  ..., -1.0553, -0.9503, -0.8452],\n",
            "         [-0.8452, -0.9853, -0.9853,  ..., -0.9503, -0.8452, -0.7752],\n",
            "         [-0.8452, -0.9853, -1.0203,  ..., -0.8277, -0.7927, -0.7402],\n",
            "         ...,\n",
            "         [ 0.3102,  0.2577,  0.1877,  ..., -0.1450, -0.1625, -0.0924],\n",
            "         [ 0.2577,  0.2402,  0.2227,  ..., -0.1275, -0.0924, -0.0574],\n",
            "         [ 0.2227,  0.2402,  0.2402,  ..., -0.1099, -0.0924, -0.0399]],\n",
            "\n",
            "        [[-0.7064, -0.7761, -0.7587,  ..., -0.8981, -0.8284, -0.7587],\n",
            "         [-0.7064, -0.7761, -0.7936,  ..., -0.8110, -0.7587, -0.6890],\n",
            "         [-0.7413, -0.8110, -0.8110,  ..., -0.7238, -0.6890, -0.6367],\n",
            "         ...,\n",
            "         [ 0.0953,  0.0431,  0.0256,  ..., -0.2707, -0.3055, -0.2881],\n",
            "         [ 0.0431,  0.0431,  0.0605,  ..., -0.2881, -0.3055, -0.3230],\n",
            "         [ 0.0431,  0.0605,  0.0953,  ..., -0.3230, -0.3404, -0.3404]]]), tensor(0))\n",
            "Successfully unpacked batch 10\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 10\n",
            "\n",
            "Batch 11 type: <class 'tuple'>\n",
            "Batch 11 content: (tensor([[[ 0.7077,  0.6906,  0.6906,  ..., -1.5357, -1.5699, -1.6727],\n",
            "         [ 0.7248,  0.6563,  0.6221,  ..., -1.5357, -1.5699, -1.6727],\n",
            "         [ 0.7419,  0.6563,  0.6049,  ..., -1.6213, -1.6213, -1.6727],\n",
            "         ...,\n",
            "         [ 0.5536,  0.5707,  0.5193,  ..., -0.2171, -0.1657, -0.0458],\n",
            "         [ 0.5022,  0.5022,  0.5193,  ..., -0.2171, -0.2171, -0.0972],\n",
            "         [ 0.5022,  0.5193,  0.5193,  ..., -0.1314, -0.1828, -0.0801]],\n",
            "\n",
            "        [[-0.2850, -0.3025, -0.3025,  ..., -1.6856, -1.6856, -1.7556],\n",
            "         [-0.2675, -0.3375, -0.3200,  ..., -1.6506, -1.6506, -1.7206],\n",
            "         [-0.3025, -0.3550, -0.3375,  ..., -1.6155, -1.6506, -1.6856],\n",
            "         ...,\n",
            "         [-0.5826, -0.6001, -0.7227,  ..., -0.8277, -0.8978, -0.8102],\n",
            "         [-0.6352, -0.6877, -0.7402,  ..., -0.8803, -0.9503, -0.8452],\n",
            "         [-0.6702, -0.6877, -0.7577,  ..., -0.8627, -0.9503, -0.8978]],\n",
            "\n",
            "        [[-0.4973, -0.5321, -0.5670,  ..., -1.5953, -1.5779, -1.6476],\n",
            "         [-0.4450, -0.5321, -0.5321,  ..., -1.5256, -1.5256, -1.5953],\n",
            "         [-0.4450, -0.5147, -0.4973,  ..., -1.5430, -1.5256, -1.5604],\n",
            "         ...,\n",
            "         [-0.7238, -0.7064, -0.7761,  ..., -1.1421, -1.1073, -0.9853],\n",
            "         [-0.6715, -0.6890, -0.7064,  ..., -1.1247, -1.1596, -1.0027],\n",
            "         [-0.6890, -0.6890, -0.7238,  ..., -1.0201, -1.1073, -1.0201]]]), tensor(1))\n",
            "Successfully unpacked batch 11\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 11\n",
            "\n",
            "Batch 12 type: <class 'tuple'>\n",
            "Batch 12 content: (tensor([[[1.5468, 1.6153, 1.7009,  ..., 1.5468, 1.4954, 1.4954],\n",
            "         [1.5639, 1.6324, 1.7009,  ..., 1.4612, 1.4783, 1.5125],\n",
            "         [1.6495, 1.6324, 1.6495,  ..., 1.4440, 1.5125, 1.5297],\n",
            "         ...,\n",
            "         [1.3927, 1.4098, 1.4269,  ..., 1.4098, 1.4098, 1.3927],\n",
            "         [1.3927, 1.4098, 1.4098,  ..., 1.4269, 1.4269, 1.4098],\n",
            "         [1.4440, 1.4783, 1.4098,  ..., 1.4269, 1.4098, 1.4269]],\n",
            "\n",
            "        [[1.3782, 1.4307, 1.5182,  ..., 0.7479, 0.7654, 0.8004],\n",
            "         [1.4132, 1.4657, 1.5007,  ..., 0.6954, 0.7654, 0.8179],\n",
            "         [1.5532, 1.4832, 1.4657,  ..., 0.7129, 0.8004, 0.8529],\n",
            "         ...,\n",
            "         [0.8529, 0.8529, 0.8529,  ..., 0.6254, 0.6429, 0.6429],\n",
            "         [0.7829, 0.8004, 0.8004,  ..., 0.6429, 0.6954, 0.7129],\n",
            "         [0.7654, 0.7829, 0.7654,  ..., 0.7129, 0.7304, 0.7654]],\n",
            "\n",
            "        [[1.5594, 1.6291, 1.7163,  ..., 0.6705, 0.6531, 0.6705],\n",
            "         [1.6117, 1.6465, 1.6814,  ..., 0.6182, 0.6531, 0.7054],\n",
            "         [1.7511, 1.6640, 1.6117,  ..., 0.6008, 0.6705, 0.7228],\n",
            "         ...,\n",
            "         [0.8448, 0.8099, 0.7925,  ..., 0.5834, 0.5834, 0.5485],\n",
            "         [0.8274, 0.8274, 0.7925,  ..., 0.6356, 0.6879, 0.6705],\n",
            "         [0.8274, 0.8622, 0.7925,  ..., 0.6531, 0.7054, 0.7402]]]), tensor(3))\n",
            "Successfully unpacked batch 12\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 12\n",
            "\n",
            "Batch 13 type: <class 'tuple'>\n",
            "Batch 13 content: (tensor([[[ 1.4098,  1.4098,  1.3927,  ...,  0.5364,  0.5364,  0.5193],\n",
            "         [ 1.4269,  1.4269,  1.3584,  ...,  0.5707,  0.5536,  0.5193],\n",
            "         [ 1.4269,  1.4440,  1.4440,  ...,  0.5878,  0.5536,  0.5364],\n",
            "         ...,\n",
            "         [ 1.6153,  1.5982,  1.6324,  ...,  1.0159,  1.0331,  0.9988],\n",
            "         [ 1.5810,  1.5639,  1.5982,  ...,  1.0502,  1.0673,  1.0159],\n",
            "         [ 1.5468,  1.5125,  1.5468,  ...,  1.0673,  1.0844,  1.0331]],\n",
            "\n",
            "        [[ 0.7129,  0.7654,  0.8004,  ..., -0.0924, -0.1450, -0.1975],\n",
            "         [ 0.7304,  0.7479,  0.7654,  ..., -0.0924, -0.1275, -0.1625],\n",
            "         [ 0.7654,  0.7654,  0.7829,  ..., -0.0749, -0.1099, -0.1275],\n",
            "         ...,\n",
            "         [ 0.7129,  0.6954,  0.6954,  ...,  0.3277,  0.3102,  0.2752],\n",
            "         [ 0.7304,  0.6779,  0.6954,  ...,  0.3627,  0.3452,  0.2927],\n",
            "         [ 0.7129,  0.6779,  0.6779,  ...,  0.3452,  0.3627,  0.3277]],\n",
            "\n",
            "        [[ 0.6705,  0.6879,  0.6705,  ..., -0.4450, -0.5321, -0.6018],\n",
            "         [ 0.6879,  0.7054,  0.6705,  ..., -0.3927, -0.4450, -0.4624],\n",
            "         [ 0.7054,  0.7402,  0.7576,  ..., -0.3404, -0.3404, -0.3404],\n",
            "         ...,\n",
            "         [ 0.6182,  0.6008,  0.6531,  ...,  0.1476,  0.1128,  0.0605],\n",
            "         [ 0.6356,  0.6356,  0.6879,  ...,  0.1999,  0.1476,  0.0779],\n",
            "         [ 0.6356,  0.6182,  0.6531,  ...,  0.1825,  0.1476,  0.0431]]]), tensor(3))\n",
            "Successfully unpacked batch 13\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 13\n",
            "\n",
            "Batch 14 type: <class 'tuple'>\n",
            "Batch 14 content: (tensor([[[-1.0219, -0.6623, -1.0904,  ...,  0.2967,  0.1426,  0.0398],\n",
            "         [-0.9534, -0.5767, -1.1247,  ...,  0.0227,  0.2967,  0.4851],\n",
            "         [-0.9020, -0.6281, -1.1932,  ..., -0.3369, -0.1999,  0.0227],\n",
            "         ...,\n",
            "         [ 0.9132,  0.8276,  0.8447,  ...,  1.7180,  1.7352,  1.7009],\n",
            "         [ 0.9817,  0.8789,  0.8276,  ...,  1.7694,  1.7180,  1.6667],\n",
            "         [ 0.9988,  0.8789,  0.8276,  ...,  1.8208,  1.8208,  1.7352]],\n",
            "\n",
            "        [[-1.4755, -1.0728, -1.4755,  ..., -0.0399, -0.2150, -0.3025],\n",
            "         [-1.3704, -0.9328, -1.4405,  ..., -0.1800,  0.0826,  0.2227],\n",
            "         [-1.1429, -0.8627, -1.4580,  ..., -0.6001, -0.4426, -0.1800],\n",
            "         ...,\n",
            "         [-0.0049, -0.0749, -0.0049,  ...,  1.0105,  1.0630,  1.0455],\n",
            "         [ 0.0126, -0.0574, -0.0574,  ...,  1.0630,  1.0630,  1.0455],\n",
            "         [ 0.0476, -0.0399, -0.0749,  ...,  1.1506,  1.1681,  1.1331]],\n",
            "\n",
            "        [[-1.3164, -0.9330, -1.3861,  ..., -0.0615, -0.2358, -0.3404],\n",
            "         [-1.2641, -0.8458, -1.3861,  ..., -0.2010,  0.0431,  0.0953],\n",
            "         [-1.1596, -0.8807, -1.4036,  ..., -0.6715, -0.5670, -0.3927],\n",
            "         ...,\n",
            "         [-0.2358, -0.3055, -0.2532,  ...,  0.8274,  0.8797,  0.8971],\n",
            "         [-0.2532, -0.2881, -0.2707,  ...,  0.9319,  0.9145,  0.8971],\n",
            "         [-0.2881, -0.3055, -0.3230,  ...,  1.0365,  1.1062,  1.0365]]]), tensor(0))\n",
            "Successfully unpacked batch 14\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 14\n",
            "\n",
            "Batch 15 type: <class 'tuple'>\n",
            "Batch 15 content: (tensor([[[-0.0287, -0.0116, -0.0116,  ...,  1.4783,  1.5468,  1.5982],\n",
            "         [-0.1314, -0.1143, -0.0801,  ...,  1.4783,  1.5297,  1.5639],\n",
            "         [-0.1657, -0.1314, -0.0287,  ...,  1.5125,  1.5468,  1.5810],\n",
            "         ...,\n",
            "         [ 0.6392,  0.6734,  0.7419,  ...,  1.5982,  1.5810,  1.5810],\n",
            "         [ 0.6049,  0.6049,  0.7077,  ...,  1.6324,  1.6324,  1.6153],\n",
            "         [ 0.5536,  0.5878,  0.6221,  ...,  1.5810,  1.6153,  1.5982]],\n",
            "\n",
            "        [[-0.6877, -0.7052, -0.7052,  ...,  0.5903,  0.6604,  0.7129],\n",
            "         [-0.7052, -0.7402, -0.7577,  ...,  0.6429,  0.6954,  0.7304],\n",
            "         [-0.6877, -0.7227, -0.6527,  ...,  0.6604,  0.6954,  0.7129],\n",
            "         ...,\n",
            "         [-0.3375, -0.2850, -0.1800,  ...,  0.5028,  0.4678,  0.4678],\n",
            "         [-0.3901, -0.3901, -0.3025,  ...,  0.4503,  0.4678,  0.4503],\n",
            "         [-0.4251, -0.3901, -0.3725,  ...,  0.4153,  0.4328,  0.4153]],\n",
            "\n",
            "        [[-0.9156, -0.8807, -0.8807,  ...,  0.5136,  0.5311,  0.5834],\n",
            "         [-0.9504, -0.9504, -0.9678,  ...,  0.5659,  0.6008,  0.6008],\n",
            "         [-0.9853, -1.0201, -0.9678,  ...,  0.5834,  0.6008,  0.6182],\n",
            "         ...,\n",
            "         [-0.6890, -0.6193, -0.4798,  ...,  0.3742,  0.3742,  0.3916],\n",
            "         [-0.6715, -0.6715, -0.5495,  ...,  0.3568,  0.4265,  0.3916],\n",
            "         [-0.7064, -0.7064, -0.6541,  ...,  0.3393,  0.4265,  0.4265]]]), tensor(1))\n",
            "Successfully unpacked batch 15\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 15\n",
            "\n",
            "Batch 16 type: <class 'tuple'>\n",
            "Batch 16 content: (tensor([[[-0.3369, -0.3712, -0.4397,  ...,  0.6392,  0.6734,  0.6906],\n",
            "         [-0.1143, -0.0801, -0.0972,  ...,  0.6392,  0.6734,  0.7248],\n",
            "         [ 0.1768,  0.1939,  0.1426,  ...,  0.6049,  0.6563,  0.7248],\n",
            "         ...,\n",
            "         [ 0.4337,  0.4508,  0.5193,  ...,  0.9303,  0.9988,  0.9988],\n",
            "         [ 0.5022,  0.4679,  0.4851,  ...,  0.9303,  1.0159,  1.0331],\n",
            "         [ 0.5878,  0.5193,  0.4851,  ...,  0.9646,  0.9988,  1.0502]],\n",
            "\n",
            "        [[-0.6352, -0.6527, -0.7052,  ...,  0.2227,  0.2927,  0.3277],\n",
            "         [-0.5301, -0.4776, -0.4601,  ...,  0.2402,  0.2927,  0.3277],\n",
            "         [-0.3901, -0.3901, -0.4251,  ...,  0.2227,  0.3102,  0.3452],\n",
            "         ...,\n",
            "         [-0.1099, -0.0574,  0.0301,  ..., -0.1099, -0.0749, -0.0749],\n",
            "         [-0.0574, -0.0924,  0.0126,  ..., -0.1275, -0.0399, -0.0224],\n",
            "         [-0.0224, -0.0574, -0.0399,  ..., -0.1099, -0.0399, -0.0049]],\n",
            "\n",
            "        [[-0.9156, -0.9156, -0.8981,  ...,  0.1476,  0.2173,  0.2348],\n",
            "         [-0.7587, -0.6890, -0.6367,  ...,  0.1128,  0.1825,  0.2348],\n",
            "         [-0.5147, -0.5147, -0.5321,  ...,  0.0605,  0.1651,  0.2173],\n",
            "         ...,\n",
            "         [-0.1138, -0.1138, -0.0790,  ..., -0.1312, -0.0615, -0.0092],\n",
            "         [-0.1661, -0.2010, -0.1312,  ..., -0.1661, -0.0267,  0.0082],\n",
            "         [-0.1138, -0.1661, -0.1487,  ..., -0.1138, -0.0267,  0.0431]]]), tensor(0))\n",
            "Successfully unpacked batch 16\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 16\n",
            "\n",
            "Batch 17 type: <class 'tuple'>\n",
            "Batch 17 content: (tensor([[[-0.0801, -0.0801, -0.0116,  ...,  1.5639,  1.6153,  1.6324],\n",
            "         [-0.1486, -0.1143,  0.0056,  ...,  1.4783,  1.5297,  1.5639],\n",
            "         [-0.1143, -0.0972, -0.0458,  ...,  1.5810,  1.5468,  1.5468],\n",
            "         ...,\n",
            "         [ 0.3481,  0.3309,  0.3309,  ...,  1.4440,  1.4954,  1.4098],\n",
            "         [ 0.3481,  0.3309,  0.3481,  ...,  1.4098,  1.4783,  1.4269],\n",
            "         [ 0.3481,  0.3138,  0.2796,  ...,  1.3755,  1.3927,  1.4098]],\n",
            "\n",
            "        [[-0.4601, -0.4426, -0.3550,  ...,  1.2731,  1.3431,  1.3782],\n",
            "         [-0.3901, -0.3901, -0.2850,  ...,  1.2731,  1.3256,  1.3431],\n",
            "         [-0.3901, -0.3725, -0.3375,  ...,  1.4307,  1.3782,  1.3606],\n",
            "         ...,\n",
            "         [-0.2150, -0.2325, -0.2150,  ...,  1.1331,  1.1856,  1.1331],\n",
            "         [-0.2150, -0.2325, -0.2325,  ...,  1.1331,  1.1856,  1.1681],\n",
            "         [-0.1625, -0.1975, -0.2500,  ...,  1.1506,  1.1506,  1.1856]],\n",
            "\n",
            "        [[-0.2881, -0.2707, -0.1835,  ...,  1.3851,  1.4374,  1.4897],\n",
            "         [-0.2532, -0.2532, -0.1487,  ...,  1.3677,  1.3851,  1.4200],\n",
            "         [-0.2881, -0.2707, -0.2532,  ...,  1.5768,  1.4897,  1.4722],\n",
            "         ...,\n",
            "         [ 0.1651,  0.1476,  0.1476,  ...,  1.3677,  1.4548,  1.4025],\n",
            "         [ 0.1302,  0.1128,  0.1128,  ...,  1.4025,  1.4548,  1.4374],\n",
            "         [ 0.1302,  0.1128,  0.0605,  ...,  1.4025,  1.4200,  1.4374]]]), tensor(0))\n",
            "Successfully unpacked batch 17\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 17\n",
            "\n",
            "Batch 18 type: <class 'tuple'>\n",
            "Batch 18 content: (tensor([[[-0.7479, -0.8335, -0.9192,  ..., -1.5014, -1.4500, -1.5185],\n",
            "         [-0.8849, -0.8849, -0.8335,  ..., -1.4843, -1.3987, -1.4158],\n",
            "         [-0.8164, -0.8507, -0.8164,  ..., -1.3302, -1.3473, -1.3644],\n",
            "         ...,\n",
            "         [ 0.1768,  0.1939,  0.1939,  ...,  0.3138,  0.3652,  0.3481],\n",
            "         [ 0.1254,  0.1083,  0.1768,  ...,  0.3309,  0.3309,  0.3823],\n",
            "         [ 0.1083,  0.1083,  0.1597,  ...,  0.2967,  0.2624,  0.2453]],\n",
            "\n",
            "        [[-0.9853, -1.0378, -1.2304,  ..., -1.3354, -1.2479, -1.2829],\n",
            "         [-1.1429, -1.1429, -1.2304,  ..., -1.3179, -1.2479, -1.2654],\n",
            "         [-1.1604, -1.2304, -1.2654,  ..., -1.2304, -1.2304, -1.2129],\n",
            "         ...,\n",
            "         [-0.5301, -0.4951, -0.4776,  ..., -0.3725, -0.3200, -0.3200],\n",
            "         [-0.5651, -0.5651, -0.4776,  ..., -0.3901, -0.3901, -0.3375],\n",
            "         [-0.6001, -0.5826, -0.4776,  ..., -0.3901, -0.4601, -0.5126]],\n",
            "\n",
            "        [[-1.1247, -1.1596, -1.2990,  ..., -1.1596, -1.0550, -1.0724],\n",
            "         [-1.2816, -1.2467, -1.2467,  ..., -1.1944, -1.0724, -1.0550],\n",
            "         [-1.2816, -1.2990, -1.2816,  ..., -1.0376, -1.0724, -1.0550],\n",
            "         ...,\n",
            "         [-0.5495, -0.5495, -0.5495,  ..., -0.1835, -0.1312, -0.1487],\n",
            "         [-0.6018, -0.6193, -0.5321,  ..., -0.1661, -0.1661, -0.1312],\n",
            "         [-0.5844, -0.5844, -0.5321,  ..., -0.2010, -0.2358, -0.2707]]]), tensor(0))\n",
            "Successfully unpacked batch 18\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 18\n",
            "\n",
            "Batch 19 type: <class 'tuple'>\n",
            "Batch 19 content: (tensor([[[ 0.1939,  0.1254,  0.1768,  ..., -1.8610, -1.8610, -1.8782],\n",
            "         [ 0.0912,  0.0912,  0.0569,  ..., -1.8782, -1.8268, -1.8439],\n",
            "         [ 0.1254,  0.1426,  0.1083,  ..., -1.7925, -1.7240, -1.7412],\n",
            "         ...,\n",
            "         [ 0.6734,  0.6392,  0.6049,  ...,  0.1083,  0.1426,  0.1083],\n",
            "         [ 0.6734,  0.6563,  0.6221,  ...,  0.1254,  0.1254,  0.1254],\n",
            "         [ 0.6563,  0.6392,  0.5878,  ...,  0.1083,  0.1254,  0.1254]],\n",
            "\n",
            "        [[-0.8277, -0.8803, -0.8627,  ..., -1.8256, -1.8256, -1.8256],\n",
            "         [-0.8102, -0.8627, -0.9503,  ..., -1.8256, -1.7556, -1.7731],\n",
            "         [-0.7052, -0.7402, -0.8102,  ..., -1.8606, -1.7906, -1.7906],\n",
            "         ...,\n",
            "         [-0.5301, -0.5126, -0.5301,  ..., -0.7927, -0.7927, -0.8803],\n",
            "         [-0.6001, -0.6001, -0.5651,  ..., -0.8102, -0.8277, -0.8627],\n",
            "         [-0.5826, -0.6176, -0.6001,  ..., -0.8803, -0.8803, -0.8803]],\n",
            "\n",
            "        [[-1.0201, -1.0550, -0.9853,  ..., -1.7173, -1.6999, -1.7173],\n",
            "         [-1.0027, -0.9853, -1.0027,  ..., -1.7173, -1.6824, -1.6824],\n",
            "         [-0.8807, -0.8458, -0.8981,  ..., -1.7522, -1.6999, -1.6999],\n",
            "         ...,\n",
            "         [-0.7238, -0.7238, -0.8110,  ..., -0.9504, -0.9504, -1.0201],\n",
            "         [-0.7936, -0.8110, -0.8458,  ..., -0.9853, -0.9678, -0.9853],\n",
            "         [-0.7761, -0.8284, -0.8458,  ..., -1.0376, -1.0376, -1.0201]]]), tensor(0))\n",
            "Successfully unpacked batch 19\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 19\n",
            "\n",
            "Batch 20 type: <class 'tuple'>\n",
            "Batch 20 content: (tensor([[[ 1.4954,  1.4269,  1.3584,  ...,  2.1975,  2.1290,  2.0434],\n",
            "         [ 1.4440,  1.3584,  1.3242,  ...,  2.2318,  2.2147,  2.0777],\n",
            "         [ 1.4783,  1.4269,  1.4612,  ...,  2.2147,  2.2318,  2.1290],\n",
            "         ...,\n",
            "         [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2318],\n",
            "         [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
            "         [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
            "\n",
            "        [[ 0.2927,  0.2052,  0.1176,  ...,  1.4482,  1.3606,  1.3081],\n",
            "         [ 0.2927,  0.2052,  0.1877,  ...,  1.4657,  1.4307,  1.3081],\n",
            "         [ 0.3277,  0.3277,  0.3978,  ...,  1.5007,  1.4482,  1.3431],\n",
            "         ...,\n",
            "         [ 1.3081,  1.3782,  1.4482,  ...,  1.5007,  1.4482,  1.3782],\n",
            "         [ 1.2381,  1.3606,  1.4657,  ...,  1.4832,  1.4657,  1.4132],\n",
            "         [ 1.3431,  1.3606,  1.4307,  ...,  1.4832,  1.4307,  1.3782]],\n",
            "\n",
            "        [[ 0.1476,  0.0256, -0.1138,  ...,  1.3502,  1.2282,  1.1585],\n",
            "         [ 0.0431, -0.0790, -0.0964,  ...,  1.3677,  1.2980,  1.1934],\n",
            "         [ 0.0082, -0.0615,  0.0256,  ...,  1.4025,  1.3328,  1.2457],\n",
            "         ...,\n",
            "         [ 1.1585,  1.2108,  1.2805,  ...,  1.4548,  1.3677,  1.3328],\n",
            "         [ 1.0017,  1.1237,  1.2980,  ...,  1.4548,  1.4025,  1.3851],\n",
            "         [ 1.1237,  1.1759,  1.2631,  ...,  1.4897,  1.4548,  1.4025]]]), tensor(0))\n",
            "Successfully unpacked batch 20\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 20\n",
            "\n",
            "Batch 21 type: <class 'tuple'>\n",
            "Batch 21 content: (tensor([[[1.2043, 1.1700, 1.1700,  ..., 1.5810, 1.6153, 1.5810],\n",
            "         [1.2385, 1.2043, 1.1872,  ..., 1.5982, 1.5810, 1.5468],\n",
            "         [1.2557, 1.2899, 1.3070,  ..., 1.5639, 1.5639, 1.5639],\n",
            "         ...,\n",
            "         [1.6667, 1.6667, 1.6495,  ..., 1.6667, 1.6495, 1.7180],\n",
            "         [1.6153, 1.6667, 1.6667,  ..., 1.6838, 1.6667, 1.7352],\n",
            "         [1.6667, 1.7009, 1.6667,  ..., 1.7180, 1.7009, 1.7180]],\n",
            "\n",
            "        [[0.3277, 0.2927, 0.2752,  ..., 0.4503, 0.4853, 0.4678],\n",
            "         [0.3277, 0.2927, 0.2752,  ..., 0.4503, 0.4678, 0.4853],\n",
            "         [0.3452, 0.3803, 0.3627,  ..., 0.3803, 0.4328, 0.5028],\n",
            "         ...,\n",
            "         [0.4328, 0.4503, 0.4678,  ..., 0.3277, 0.3102, 0.3452],\n",
            "         [0.4503, 0.4853, 0.5028,  ..., 0.3452, 0.2927, 0.3452],\n",
            "         [0.5028, 0.5378, 0.5203,  ..., 0.3803, 0.3452, 0.3452]],\n",
            "\n",
            "        [[0.2173, 0.1476, 0.0779,  ..., 0.4614, 0.5311, 0.5136],\n",
            "         [0.1999, 0.1302, 0.0779,  ..., 0.4091, 0.4614, 0.4614],\n",
            "         [0.2348, 0.1999, 0.1476,  ..., 0.3393, 0.4265, 0.4962],\n",
            "         ...,\n",
            "         [0.2173, 0.2348, 0.2522,  ..., 0.1302, 0.1476, 0.1999],\n",
            "         [0.2348, 0.2696, 0.2696,  ..., 0.2173, 0.1825, 0.2522],\n",
            "         [0.3045, 0.3219, 0.3219,  ..., 0.2696, 0.2522, 0.2696]]]), tensor(0))\n",
            "Successfully unpacked batch 21\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 21\n",
            "\n",
            "Batch 22 type: <class 'tuple'>\n",
            "Batch 22 content: (tensor([[[ 1.5982,  1.5810,  1.4954,  ...,  0.9474,  0.8447,  0.8618],\n",
            "         [ 1.5982,  1.5810,  1.4954,  ...,  1.0159,  0.9474,  0.8961],\n",
            "         [ 1.4612,  1.4612,  1.5125,  ...,  1.0673,  0.9988,  0.9132],\n",
            "         ...,\n",
            "         [ 1.9064,  1.8722,  1.8722,  ...,  1.6324,  1.5982,  1.5982],\n",
            "         [ 1.9407,  1.9064,  1.8550,  ...,  1.6838,  1.6324,  1.5982],\n",
            "         [ 1.9235,  1.9407,  1.8722,  ...,  1.6667,  1.6324,  1.5982]],\n",
            "\n",
            "        [[ 0.4328,  0.4328,  0.3102,  ..., -0.1275, -0.2150, -0.1975],\n",
            "         [ 0.3978,  0.3627,  0.2927,  ..., -0.0749, -0.1975, -0.2325],\n",
            "         [ 0.3452,  0.3102,  0.3452,  ..., -0.0924, -0.1800, -0.2500],\n",
            "         ...,\n",
            "         [ 0.3627,  0.3627,  0.3627,  ...,  0.3627,  0.3452,  0.3627],\n",
            "         [ 0.3803,  0.3627,  0.3277,  ...,  0.3978,  0.3803,  0.3803],\n",
            "         [ 0.3627,  0.3803,  0.3277,  ...,  0.4328,  0.3978,  0.3978]],\n",
            "\n",
            "        [[ 0.4265,  0.3916,  0.2871,  ..., -0.3927, -0.4450, -0.4275],\n",
            "         [ 0.3916,  0.3568,  0.2522,  ..., -0.3404, -0.3927, -0.4450],\n",
            "         [ 0.3045,  0.2871,  0.3219,  ..., -0.3753, -0.4275, -0.4624],\n",
            "         ...,\n",
            "         [ 0.0256, -0.0092, -0.0267,  ..., -0.1312, -0.2010, -0.1835],\n",
            "         [-0.0092, -0.0267, -0.0441,  ..., -0.0790, -0.1661, -0.1835],\n",
            "         [-0.0267,  0.0082, -0.0441,  ..., -0.0267, -0.0964, -0.1138]]]), tensor(0))\n",
            "Successfully unpacked batch 22\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 22\n",
            "\n",
            "Batch 23 type: <class 'tuple'>\n",
            "Batch 23 content: (tensor([[[0.7591, 0.8618, 0.8447,  ..., 1.1529, 1.1872, 1.3413],\n",
            "         [0.9303, 0.9132, 0.8104,  ..., 1.2728, 1.1187, 1.2557],\n",
            "         [0.7933, 0.7762, 0.3994,  ..., 1.4783, 1.2557, 1.0159],\n",
            "         ...,\n",
            "         [1.0673, 1.1015, 1.0331,  ..., 1.6838, 1.7009, 1.7009],\n",
            "         [1.0331, 1.0673, 1.1015,  ..., 1.6667, 1.6667, 1.7180],\n",
            "         [0.8961, 0.9303, 1.0502,  ..., 1.6495, 1.6838, 1.7009]],\n",
            "\n",
            "        [[0.3803, 0.5203, 0.5203,  ..., 0.5378, 0.5553, 0.7304],\n",
            "         [0.6604, 0.6604, 0.5553,  ..., 0.6954, 0.4853, 0.6254],\n",
            "         [0.5028, 0.4853, 0.0651,  ..., 1.0105, 0.7304, 0.4153],\n",
            "         ...,\n",
            "         [0.6254, 0.6429, 0.6078,  ..., 1.3606, 1.3782, 1.3606],\n",
            "         [0.5728, 0.6254, 0.7129,  ..., 1.3782, 1.3957, 1.3957],\n",
            "         [0.5203, 0.5728, 0.7304,  ..., 1.3606, 1.3957, 1.3957]],\n",
            "\n",
            "        [[0.5659, 0.7054, 0.6879,  ..., 0.3742, 0.3742, 0.5659],\n",
            "         [0.8448, 0.8274, 0.7054,  ..., 0.5311, 0.3393, 0.4614],\n",
            "         [0.6531, 0.6182, 0.1825,  ..., 0.8448, 0.5834, 0.2871],\n",
            "         ...,\n",
            "         [0.8622, 0.8622, 0.8274,  ..., 1.4025, 1.3851, 1.3851],\n",
            "         [0.8099, 0.8622, 0.9319,  ..., 1.3851, 1.3851, 1.4200],\n",
            "         [0.7402, 0.7751, 0.9494,  ..., 1.3851, 1.4374, 1.4548]]]), tensor(2))\n",
            "Successfully unpacked batch 23\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 23\n",
            "\n",
            "Batch 24 type: <class 'tuple'>\n",
            "Batch 24 content: (tensor([[[-1.0219, -1.0562, -1.0733,  ...,  0.7591,  0.5536,  0.3481],\n",
            "         [-1.0562, -1.0562, -0.9877,  ...,  0.7762,  0.7077,  0.3138],\n",
            "         [-1.0219, -0.9363, -0.9020,  ...,  0.7591,  0.8276,  0.4166],\n",
            "         ...,\n",
            "         [ 2.0434,  1.9920,  1.8550,  ...,  1.7352,  1.7180,  1.6838],\n",
            "         [ 1.7694,  1.7865,  1.8208,  ...,  1.7865,  1.7352,  1.7352],\n",
            "         [ 1.7523,  1.7523,  1.7523,  ...,  1.7865,  1.7523,  1.7694]],\n",
            "\n",
            "        [[-1.3004, -1.2829, -1.2829,  ...,  0.2402,  0.0476, -0.1800],\n",
            "         [-1.3179, -1.2654, -1.1954,  ...,  0.2927,  0.2577, -0.1975],\n",
            "         [-1.3179, -1.2304, -1.2129,  ...,  0.2752,  0.3803, -0.0924],\n",
            "         ...,\n",
            "         [ 1.1155,  1.0805,  0.9755,  ...,  0.5728,  0.5728,  0.5378],\n",
            "         [ 0.8354,  0.8529,  0.9055,  ...,  0.5728,  0.5378,  0.5378],\n",
            "         [ 0.8179,  0.8179,  0.8179,  ...,  0.5553,  0.5378,  0.5553]],\n",
            "\n",
            "        [[-1.3861, -1.3861, -1.4036,  ...,  0.3219,  0.1128, -0.1138],\n",
            "         [-1.4210, -1.3687, -1.2641,  ...,  0.3742,  0.3219, -0.1312],\n",
            "         [-1.3513, -1.2641, -1.2467,  ...,  0.3568,  0.4439, -0.0267],\n",
            "         ...,\n",
            "         [ 0.6531,  0.6008,  0.4614,  ..., -0.0441,  0.0082, -0.0092],\n",
            "         [ 0.2871,  0.3219,  0.3916,  ...,  0.0082,  0.0431,  0.0953],\n",
            "         [ 0.2696,  0.2871,  0.3219,  ...,  0.0256,  0.0256,  0.0953]]]), tensor(3))\n",
            "Successfully unpacked batch 24\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 24\n",
            "\n",
            "Batch 25 type: <class 'tuple'>\n",
            "Batch 25 content: (tensor([[[-1.0904, -1.2617, -1.3130,  ...,  0.4166,  0.5707,  0.7248],\n",
            "         [-1.2445, -1.3644, -1.4329,  ...,  0.3823,  0.6221,  0.7591],\n",
            "         [-1.2959, -1.3815, -1.3644,  ...,  0.6392,  0.7248,  0.7762],\n",
            "         ...,\n",
            "         [ 0.8961,  0.8961,  0.8789,  ...,  1.4098,  1.4954,  1.5639],\n",
            "         [ 0.9474,  0.9817,  0.8961,  ...,  1.3755,  1.4440,  1.5125],\n",
            "         [ 0.9646,  0.9817,  0.9132,  ...,  1.4954,  1.4954,  1.4783]],\n",
            "\n",
            "        [[-1.2479, -1.4405, -1.5105,  ...,  0.3102,  0.4678,  0.6604],\n",
            "         [-1.3179, -1.4405, -1.5280,  ...,  0.2577,  0.5378,  0.6954],\n",
            "         [-1.4055, -1.4755, -1.4930,  ...,  0.5378,  0.6254,  0.7129],\n",
            "         ...,\n",
            "         [ 0.7304,  0.7829,  0.7654,  ...,  1.1681,  1.2031,  1.2556],\n",
            "         [ 0.7654,  0.8354,  0.7479,  ...,  1.1331,  1.1681,  1.2031],\n",
            "         [ 0.7654,  0.8179,  0.7129,  ...,  1.2031,  1.1681,  1.1331]],\n",
            "\n",
            "        [[-1.0201, -1.2119, -1.3164,  ...,  0.5485,  0.6879,  0.8797],\n",
            "         [-1.1073, -1.2467, -1.3339,  ...,  0.4962,  0.7576,  0.9494],\n",
            "         [-1.1944, -1.2816, -1.2816,  ...,  0.7576,  0.8622,  0.9842],\n",
            "         ...,\n",
            "         [ 0.9145,  0.9145,  0.8622,  ...,  1.2980,  1.3677,  1.4548],\n",
            "         [ 0.9494,  0.9842,  0.8622,  ...,  1.2631,  1.3154,  1.4025],\n",
            "         [ 0.9668,  1.0017,  0.8971,  ...,  1.3851,  1.3677,  1.3328]]]), tensor(0))\n",
            "Successfully unpacked batch 25\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 25\n",
            "\n",
            "Batch 26 type: <class 'tuple'>\n",
            "Batch 26 content: (tensor([[[ 0.9474,  0.9303,  0.9474,  ..., -0.4054, -0.4739, -0.5082],\n",
            "         [ 0.9646,  0.9303,  0.9988,  ..., -0.4397, -0.5082, -0.5596],\n",
            "         [ 0.9646,  0.9474,  1.0331,  ..., -0.4568, -0.5596, -0.6109],\n",
            "         ...,\n",
            "         [ 1.1358,  1.1358,  1.0673,  ...,  0.4166,  0.4337,  0.3994],\n",
            "         [ 1.1358,  1.1358,  1.0844,  ...,  0.4166,  0.4166,  0.4166],\n",
            "         [ 1.1700,  1.1529,  1.1015,  ...,  0.3652,  0.3309,  0.3309]],\n",
            "\n",
            "        [[ 0.0126, -0.0049,  0.0126,  ..., -1.0028, -1.0728, -1.1078],\n",
            "         [-0.0574, -0.0574,  0.0301,  ..., -0.9328, -0.9853, -1.0203],\n",
            "         [-0.1275, -0.0924,  0.0301,  ..., -0.8627, -0.9328, -0.9853],\n",
            "         ...,\n",
            "         [-0.0924, -0.0924, -0.1800,  ..., -0.2850, -0.3200, -0.3901],\n",
            "         [-0.1275, -0.1099, -0.1800,  ..., -0.2325, -0.2850, -0.3025],\n",
            "         [-0.1800, -0.1450, -0.1625,  ..., -0.2675, -0.3025, -0.3375]],\n",
            "\n",
            "        [[-0.1661, -0.1487, -0.1312,  ..., -1.1073, -1.1596, -1.1596],\n",
            "         [-0.1835, -0.1661, -0.0790,  ..., -1.0898, -1.1073, -1.1247],\n",
            "         [-0.2184, -0.1487, -0.0267,  ..., -1.0550, -1.1247, -1.1247],\n",
            "         ...,\n",
            "         [-0.0790, -0.0790, -0.1312,  ..., -0.4624, -0.4624, -0.4624],\n",
            "         [-0.1138, -0.1312, -0.1835,  ..., -0.4275, -0.4101, -0.3927],\n",
            "         [-0.1661, -0.2184, -0.2532,  ..., -0.4624, -0.4624, -0.4798]]]), tensor(3))\n",
            "Successfully unpacked batch 26\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 26\n",
            "\n",
            "Batch 27 type: <class 'tuple'>\n",
            "Batch 27 content: (tensor([[[ 1.1872,  1.1700,  1.1358,  ...,  1.1015,  1.1358,  1.1700],\n",
            "         [ 1.2557,  1.1872,  1.0844,  ...,  1.0331,  1.0844,  1.1358],\n",
            "         [ 1.2385,  1.1358,  1.0502,  ...,  1.0502,  1.1015,  1.1358],\n",
            "         ...,\n",
            "         [ 1.5468,  1.5468,  1.4783,  ...,  1.4098,  1.3755,  1.3584],\n",
            "         [ 1.5297,  1.4954,  1.4783,  ...,  1.4098,  1.4098,  1.3927],\n",
            "         [ 1.5125,  1.4612,  1.4440,  ...,  1.4269,  1.4440,  1.4269]],\n",
            "\n",
            "        [[ 0.7829,  0.6954,  0.5728,  ...,  0.3277,  0.3452,  0.3627],\n",
            "         [ 0.7479,  0.6604,  0.5203,  ...,  0.2752,  0.3277,  0.3627],\n",
            "         [ 0.7304,  0.6078,  0.5203,  ...,  0.2577,  0.3277,  0.3452],\n",
            "         ...,\n",
            "         [ 1.0105,  1.0455,  0.9580,  ...,  0.4853,  0.4503,  0.4503],\n",
            "         [ 1.0280,  1.0280,  0.9930,  ...,  0.4853,  0.4853,  0.4678],\n",
            "         [ 1.0105,  0.9755,  0.9580,  ...,  0.5203,  0.5203,  0.5378]],\n",
            "\n",
            "        [[ 0.8099,  0.7402,  0.6531,  ...,  0.0605,  0.0953,  0.0779],\n",
            "         [ 0.7751,  0.7228,  0.6182,  ...,  0.0256,  0.1128,  0.1128],\n",
            "         [ 0.7925,  0.6705,  0.6008,  ..., -0.0267,  0.0605,  0.0953],\n",
            "         ...,\n",
            "         [ 1.0365,  1.0365,  0.9494,  ...,  0.3916,  0.3742,  0.3219],\n",
            "         [ 1.0714,  1.0539,  0.9842,  ...,  0.4091,  0.4265,  0.3916],\n",
            "         [ 1.0714,  1.0365,  0.9842,  ...,  0.4091,  0.4265,  0.4439]]]), tensor(0))\n",
            "Successfully unpacked batch 27\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 27\n",
            "\n",
            "Batch 28 type: <class 'tuple'>\n",
            "Batch 28 content: (tensor([[[ 1.4954,  1.4269,  1.3927,  ..., -0.0801, -0.0801, -0.0458],\n",
            "         [ 1.4783,  1.4098,  1.3584,  ..., -0.0116, -0.0458, -0.0629],\n",
            "         [ 1.3755,  1.3413,  1.3413,  ..., -0.0287, -0.0458, -0.0801],\n",
            "         ...,\n",
            "         [ 1.7009,  1.6324,  1.5982,  ...,  0.5707,  0.5536,  0.5707],\n",
            "         [ 1.6324,  1.5982,  1.5810,  ...,  0.5193,  0.5193,  0.5364],\n",
            "         [ 1.5810,  1.5639,  1.5297,  ...,  0.5536,  0.5364,  0.4851]],\n",
            "\n",
            "        [[ 0.6254,  0.6078,  0.5903,  ..., -0.8627, -0.8627, -0.8277],\n",
            "         [ 0.6429,  0.5903,  0.5378,  ..., -0.8452, -0.8803, -0.8627],\n",
            "         [ 0.6078,  0.5728,  0.5203,  ..., -0.8803, -0.8452, -0.8277],\n",
            "         ...,\n",
            "         [ 0.6604,  0.5728,  0.4853,  ..., -0.1099, -0.1099, -0.1099],\n",
            "         [ 0.7479,  0.6954,  0.6078,  ..., -0.1450, -0.1625, -0.1275],\n",
            "         [ 0.8004,  0.7654,  0.6604,  ..., -0.1099, -0.1275, -0.1800]],\n",
            "\n",
            "        [[ 0.3568,  0.3219,  0.2696,  ..., -1.1421, -1.1770, -1.1596],\n",
            "         [ 0.3916,  0.3219,  0.2696,  ..., -1.1073, -1.1770, -1.1944],\n",
            "         [ 0.3742,  0.3219,  0.3045,  ..., -1.0898, -1.1421, -1.1596],\n",
            "         ...,\n",
            "         [ 0.4265,  0.3045,  0.1999,  ..., -0.3578, -0.3055, -0.2881],\n",
            "         [ 0.4788,  0.3916,  0.3219,  ..., -0.3927, -0.3753, -0.3404],\n",
            "         [ 0.5136,  0.4614,  0.3742,  ..., -0.3404, -0.3578, -0.3927]]]), tensor(0))\n",
            "Successfully unpacked batch 28\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 28\n",
            "\n",
            "Batch 29 type: <class 'tuple'>\n",
            "Batch 29 content: (tensor([[[ 1.6324,  1.6153,  1.6495,  ...,  0.0056, -0.0629, -0.1143],\n",
            "         [ 1.5810,  1.6495,  1.6667,  ...,  0.2453,  0.1597,  0.2282],\n",
            "         [ 1.6324,  1.6324,  1.6495,  ...,  0.4166,  0.3652,  0.3481],\n",
            "         ...,\n",
            "         [ 1.5982,  1.7523,  1.7694,  ...,  1.1015,  1.0844,  1.1358],\n",
            "         [ 1.6667,  1.7352,  1.7009,  ...,  1.1187,  1.0502,  1.1187],\n",
            "         [ 1.6153,  1.6153,  1.6324,  ...,  1.1187,  1.0844,  1.1358]],\n",
            "\n",
            "        [[ 0.6254,  0.6429,  0.6954,  ..., -0.5301, -0.5826, -0.5826],\n",
            "         [ 0.5728,  0.6604,  0.7129,  ..., -0.2325, -0.4426, -0.3550],\n",
            "         [ 0.5378,  0.5553,  0.6078,  ..., -0.1275, -0.2325, -0.2850],\n",
            "         ...,\n",
            "         [ 0.8704,  0.9930,  1.0105,  ...,  0.1352,  0.1702,  0.2227],\n",
            "         [ 0.9405,  0.9930,  0.9930,  ...,  0.1176,  0.1176,  0.1877],\n",
            "         [ 0.8354,  0.8704,  0.9405,  ...,  0.1527,  0.1527,  0.2052]],\n",
            "\n",
            "        [[ 0.2348,  0.2522,  0.3045,  ..., -0.7238, -0.7413, -0.7238],\n",
            "         [ 0.1999,  0.2871,  0.3393,  ..., -0.3927, -0.5844, -0.5147],\n",
            "         [ 0.1651,  0.1999,  0.2696,  ..., -0.3055, -0.3578, -0.4275],\n",
            "         ...,\n",
            "         [ 0.6705,  0.7925,  0.8448,  ..., -0.0441, -0.0964, -0.0267],\n",
            "         [ 0.7751,  0.8274,  0.8274,  ..., -0.0267, -0.0615, -0.0092],\n",
            "         [ 0.6879,  0.7054,  0.7751,  ...,  0.0605,  0.0431,  0.0431]]]), tensor(0))\n",
            "Successfully unpacked batch 29\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 29\n",
            "\n",
            "Batch 30 type: <class 'tuple'>\n",
            "Batch 30 content: (tensor([[[-0.2684, -0.2513, -0.2171,  ...,  0.9817,  0.8618,  0.5022],\n",
            "         [-0.2342, -0.2342, -0.2513,  ...,  1.0159,  0.8447,  0.5364],\n",
            "         [-0.1657, -0.1828, -0.2171,  ...,  0.9132,  0.8618,  0.7248],\n",
            "         ...,\n",
            "         [ 0.1426,  0.1939,  0.2282,  ...,  1.2214,  1.2214,  1.1700],\n",
            "         [ 0.1254,  0.1597,  0.1939,  ...,  1.1700,  1.1872,  1.1358],\n",
            "         [ 0.1597,  0.1597,  0.1426,  ...,  1.1872,  1.1529,  1.1187]],\n",
            "\n",
            "        [[-0.7577, -0.7402, -0.7227,  ...,  0.2227,  0.1702, -0.1975],\n",
            "         [-0.7927, -0.7577, -0.7227,  ...,  0.3102,  0.1527, -0.1450],\n",
            "         [-0.7752, -0.7402, -0.7227,  ...,  0.2227,  0.1527,  0.0301],\n",
            "         ...,\n",
            "         [-0.5476, -0.4951, -0.4426,  ...,  0.1877,  0.2052,  0.1527],\n",
            "         [-0.5301, -0.4951, -0.4426,  ...,  0.2052,  0.2227,  0.1702],\n",
            "         [-0.4426, -0.4426, -0.3901,  ...,  0.2927,  0.2577,  0.2052]],\n",
            "\n",
            "        [[-0.9853, -0.9678, -0.9330,  ...,  0.2173,  0.0953, -0.2532],\n",
            "         [-1.0550, -1.0376, -1.0027,  ...,  0.2522,  0.1128, -0.1835],\n",
            "         [-1.0724, -1.0550, -1.0724,  ...,  0.2173,  0.1999,  0.0953],\n",
            "         ...,\n",
            "         [-0.8458, -0.7936, -0.7413,  ...,  0.0082, -0.0267, -0.0964],\n",
            "         [-0.7761, -0.7587, -0.7064,  ..., -0.0615, -0.0615, -0.1487],\n",
            "         [-0.7064, -0.7064, -0.6715,  ...,  0.0082, -0.0615, -0.1138]]]), tensor(0))\n",
            "Successfully unpacked batch 30\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 30\n",
            "\n",
            "Batch 31 type: <class 'tuple'>\n",
            "Batch 31 content: (tensor([[[-0.1657, -0.1314, -0.1486,  ...,  0.2453,  0.2796,  0.3138],\n",
            "         [-0.0458, -0.0116,  0.0398,  ...,  0.1083,  0.1768,  0.2796],\n",
            "         [ 0.1426,  0.1083,  0.1254,  ...,  0.0741,  0.1939,  0.1939],\n",
            "         ...,\n",
            "         [ 0.9988,  0.9474,  1.0159,  ...,  0.3994,  0.3994,  0.3823],\n",
            "         [ 1.0502,  1.0331,  1.0673,  ...,  0.3481,  0.3823,  0.3994],\n",
            "         [ 1.1187,  1.1529,  1.1187,  ...,  0.3994,  0.3994,  0.4337]],\n",
            "\n",
            "        [[-0.6001, -0.5476, -0.5826,  ..., -0.1099, -0.0574, -0.0224],\n",
            "         [-0.4601, -0.4251, -0.4076,  ..., -0.1275, -0.0749, -0.0224],\n",
            "         [-0.1975, -0.2150, -0.2150,  ..., -0.1800, -0.0574, -0.0049],\n",
            "         ...,\n",
            "         [ 0.2752,  0.2227,  0.3277,  ..., -0.2325, -0.2500, -0.2150],\n",
            "         [ 0.3102,  0.2752,  0.3102,  ..., -0.1800, -0.1625, -0.1625],\n",
            "         [ 0.3978,  0.3803,  0.3277,  ..., -0.0924, -0.1275, -0.1275]],\n",
            "\n",
            "        [[-0.8110, -0.7413, -0.7761,  ..., -0.0615,  0.0082,  0.0605],\n",
            "         [-0.7064, -0.6715, -0.6541,  ..., -0.1138, -0.0615,  0.0431],\n",
            "         [-0.5321, -0.5147, -0.4798,  ..., -0.1835, -0.0441,  0.0256],\n",
            "         ...,\n",
            "         [ 0.0256, -0.0092,  0.1128,  ..., -0.2532, -0.2358, -0.2184],\n",
            "         [ 0.0431,  0.0082,  0.0605,  ..., -0.2184, -0.1487, -0.1487],\n",
            "         [ 0.0779,  0.0605,  0.0256,  ..., -0.1835, -0.1835, -0.1487]]]), tensor(0))\n",
            "Successfully unpacked batch 31\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 31\n",
            "\n",
            "Batch 32 type: <class 'tuple'>\n",
            "Batch 32 content: (tensor([[[ 0.2282,  0.3138,  0.5022,  ...,  0.9303,  0.9817,  1.0673],\n",
            "         [ 0.2282,  0.3138,  0.4337,  ...,  1.1358,  1.0844,  1.1187],\n",
            "         [ 0.2453,  0.2796,  0.2624,  ...,  1.2043,  1.1872,  1.2385],\n",
            "         ...,\n",
            "         [ 0.2282,  0.3481,  0.4337,  ...,  1.7009,  1.7865,  1.7523],\n",
            "         [ 0.2111,  0.2111,  0.2282,  ...,  1.7523,  1.7180,  1.7180],\n",
            "         [ 0.2111,  0.1768,  0.1768,  ...,  1.6667,  1.6495,  1.7009]],\n",
            "\n",
            "        [[-0.2325, -0.1450,  0.0826,  ...,  0.5728,  0.6254,  0.6954],\n",
            "         [-0.2675, -0.1450,  0.0126,  ...,  0.8004,  0.7479,  0.7654],\n",
            "         [-0.3025, -0.2500, -0.1975,  ...,  0.8704,  0.8880,  0.9405],\n",
            "         ...,\n",
            "         [-0.2850, -0.1275, -0.0399,  ...,  1.4657,  1.5882,  1.5532],\n",
            "         [-0.3550, -0.3375, -0.3375,  ...,  1.5357,  1.5007,  1.5007],\n",
            "         [-0.2850, -0.3725, -0.4426,  ...,  1.4132,  1.4132,  1.4307]],\n",
            "\n",
            "        [[-0.1487, -0.0267,  0.1999,  ...,  0.6879,  0.7402,  0.8099],\n",
            "         [-0.2010, -0.0964,  0.0605,  ...,  0.9494,  0.8622,  0.8797],\n",
            "         [-0.2532, -0.2184, -0.2184,  ...,  0.9842,  0.9842,  1.0365],\n",
            "         ...,\n",
            "         [-0.0267,  0.1128,  0.1999,  ...,  1.5768,  1.6988,  1.6640],\n",
            "         [-0.0790, -0.0615, -0.0964,  ...,  1.6465,  1.5942,  1.5942],\n",
            "         [-0.0441, -0.1312, -0.1835,  ...,  1.5768,  1.5420,  1.5594]]]), tensor(0))\n",
            "Successfully unpacked batch 32\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 32\n",
            "\n",
            "Batch 33 type: <class 'tuple'>\n",
            "Batch 33 content: (tensor([[[0.8104, 0.7933, 0.7933,  ..., 1.5125, 1.5125, 1.4954],\n",
            "         [0.7077, 0.6906, 0.7248,  ..., 1.3584, 1.4098, 1.4269],\n",
            "         [0.6906, 0.6906, 0.7248,  ..., 1.3927, 1.3755, 1.3755],\n",
            "         ...,\n",
            "         [0.5878, 0.5193, 0.4508,  ..., 1.5297, 1.5297, 1.5297],\n",
            "         [0.5364, 0.4508, 0.4166,  ..., 1.6153, 1.5468, 1.4954],\n",
            "         [0.6221, 0.5536, 0.4851,  ..., 1.5810, 1.5982, 1.5982]],\n",
            "\n",
            "        [[0.2927, 0.2927, 0.3102,  ..., 1.3256, 1.3431, 1.3256],\n",
            "         [0.2577, 0.2927, 0.3277,  ..., 1.1856, 1.2556, 1.2731],\n",
            "         [0.2752, 0.3102, 0.3452,  ..., 1.2556, 1.2381, 1.2381],\n",
            "         ...,\n",
            "         [0.5203, 0.4503, 0.3452,  ..., 1.3256, 1.3782, 1.4132],\n",
            "         [0.4503, 0.3627, 0.2752,  ..., 1.4132, 1.3957, 1.3606],\n",
            "         [0.5378, 0.4328, 0.3452,  ..., 1.4482, 1.4482, 1.4307]],\n",
            "\n",
            "        [[0.4439, 0.4439, 0.4962,  ..., 1.5768, 1.5942, 1.5594],\n",
            "         [0.3045, 0.3568, 0.4614,  ..., 1.4374, 1.4897, 1.5071],\n",
            "         [0.3568, 0.3916, 0.4439,  ..., 1.5420, 1.5071, 1.4897],\n",
            "         ...,\n",
            "         [0.7925, 0.7576, 0.6879,  ..., 1.6117, 1.6291, 1.6291],\n",
            "         [0.7576, 0.6879, 0.6531,  ..., 1.6988, 1.6465, 1.5942],\n",
            "         [0.8448, 0.7576, 0.7054,  ..., 1.6988, 1.6640, 1.6465]]]), tensor(0))\n",
            "Successfully unpacked batch 33\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 33\n",
            "\n",
            "Batch 34 type: <class 'tuple'>\n",
            "Batch 34 content: (tensor([[[ 1.2214,  1.1872,  1.2385,  ...,  0.0056, -0.1486, -0.3369],\n",
            "         [ 1.2043,  1.1872,  1.2557,  ...,  0.0056, -0.1657, -0.3541],\n",
            "         [ 1.2214,  1.2043,  1.2557,  ...,  0.0398, -0.1314, -0.3027],\n",
            "         ...,\n",
            "         [ 1.3755,  1.3755,  1.4098,  ...,  0.7419,  0.7591,  0.7419],\n",
            "         [ 1.3927,  1.4269,  1.3413,  ...,  0.7077,  0.7419,  0.7248],\n",
            "         [ 1.4440,  1.3927,  1.3070,  ...,  0.7077,  0.7248,  0.7248]],\n",
            "\n",
            "        [[ 0.4678,  0.3803,  0.3978,  ..., -0.5651, -0.6176, -0.7227],\n",
            "         [ 0.4328,  0.3803,  0.4153,  ..., -0.5301, -0.5826, -0.7227],\n",
            "         [ 0.4503,  0.4153,  0.4153,  ..., -0.4776, -0.5651, -0.6877],\n",
            "         ...,\n",
            "         [ 0.3978,  0.3803,  0.3627,  ...,  0.1352,  0.0826,  0.1176],\n",
            "         [ 0.4328,  0.4503,  0.3452,  ...,  0.1702,  0.1527,  0.1352],\n",
            "         [ 0.4678,  0.3978,  0.2927,  ...,  0.1877,  0.1527,  0.1176]],\n",
            "\n",
            "        [[ 0.4439,  0.3742,  0.3916,  ..., -0.4450, -0.5495, -0.6367],\n",
            "         [ 0.4614,  0.4091,  0.4265,  ..., -0.4450, -0.5147, -0.6890],\n",
            "         [ 0.4962,  0.4439,  0.4439,  ..., -0.4101, -0.4973, -0.6367],\n",
            "         ...,\n",
            "         [ 0.4265,  0.3916,  0.3568,  ...,  0.1302,  0.1302,  0.1302],\n",
            "         [ 0.4788,  0.4962,  0.3742,  ...,  0.1651,  0.1825,  0.1128],\n",
            "         [ 0.5311,  0.4614,  0.3568,  ...,  0.1651,  0.1825,  0.1128]]]), tensor(0))\n",
            "Successfully unpacked batch 34\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 34\n",
            "\n",
            "Batch 35 type: <class 'tuple'>\n",
            "Batch 35 content: (tensor([[[1.0331, 1.0159, 0.9474,  ..., 1.9578, 1.8893, 1.7865],\n",
            "         [1.0159, 1.0502, 1.0159,  ..., 1.9235, 1.8893, 1.8037],\n",
            "         [0.9988, 1.0502, 1.1015,  ..., 1.9235, 1.8893, 1.8379],\n",
            "         ...,\n",
            "         [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
            "         [2.2318, 2.2318, 2.2318,  ..., 2.2489, 2.2489, 2.2489],\n",
            "         [2.2489, 2.2318, 2.2318,  ..., 2.2489, 2.2489, 2.2489]],\n",
            "\n",
            "        [[0.3978, 0.3978, 0.3627,  ..., 1.5007, 1.4482, 1.3606],\n",
            "         [0.3803, 0.4153, 0.4153,  ..., 1.4482, 1.4132, 1.3782],\n",
            "         [0.3102, 0.3627, 0.4328,  ..., 1.4657, 1.4132, 1.3782],\n",
            "         ...,\n",
            "         [1.3782, 1.3957, 1.4307,  ..., 1.5707, 1.5707, 1.5707],\n",
            "         [1.3606, 1.3606, 1.3957,  ..., 1.5882, 1.5882, 1.5707],\n",
            "         [1.3957, 1.3782, 1.4132,  ..., 1.5532, 1.5532, 1.5357]],\n",
            "\n",
            "        [[0.3916, 0.4439, 0.4091,  ..., 1.4374, 1.3328, 1.1934],\n",
            "         [0.3393, 0.4091, 0.4265,  ..., 1.3851, 1.2980, 1.1934],\n",
            "         [0.2696, 0.3393, 0.3916,  ..., 1.3677, 1.2980, 1.2282],\n",
            "         ...,\n",
            "         [1.2805, 1.2805, 1.3328,  ..., 1.5942, 1.5942, 1.5942],\n",
            "         [1.2631, 1.2631, 1.3154,  ..., 1.6117, 1.6117, 1.6117],\n",
            "         [1.3154, 1.2805, 1.3502,  ..., 1.6465, 1.6465, 1.6465]]]), tensor(0))\n",
            "Successfully unpacked batch 35\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 35\n",
            "\n",
            "Batch 36 type: <class 'tuple'>\n",
            "Batch 36 content: (tensor([[[ 0.9132,  0.9303,  1.0673,  ...,  1.6495,  1.5982,  1.5982],\n",
            "         [ 0.8447,  0.8789,  1.0673,  ...,  1.6838,  1.5810,  1.6153],\n",
            "         [ 0.7419,  0.7933,  1.0331,  ...,  1.6495,  1.5982,  1.6153],\n",
            "         ...,\n",
            "         [ 0.9646,  1.0331,  1.1015,  ...,  1.3755,  1.3413,  1.3755],\n",
            "         [ 0.9988,  1.0673,  1.1187,  ...,  1.3584,  1.3584,  1.3584],\n",
            "         [ 1.0502,  1.0331,  1.0331,  ...,  1.3242,  1.3413,  1.3413]],\n",
            "\n",
            "        [[-0.0399, -0.0049,  0.1702,  ...,  0.8704,  0.7654,  0.6954],\n",
            "         [-0.1800, -0.1275,  0.1702,  ...,  0.8880,  0.7479,  0.6954],\n",
            "         [-0.3025, -0.1975,  0.1352,  ...,  0.8354,  0.7304,  0.6954],\n",
            "         ...,\n",
            "         [ 0.1527,  0.2052,  0.2402,  ...,  0.4853,  0.4503,  0.5203],\n",
            "         [ 0.1877,  0.2577,  0.2927,  ...,  0.4678,  0.4853,  0.5203],\n",
            "         [ 0.2227,  0.2227,  0.2227,  ...,  0.4503,  0.4853,  0.5378]],\n",
            "\n",
            "        [[-0.6541, -0.6018, -0.3404,  ...,  0.4265,  0.3219,  0.2348],\n",
            "         [-0.7238, -0.6541, -0.2707,  ...,  0.5136,  0.3568,  0.3045],\n",
            "         [-0.8284, -0.6715, -0.2358,  ...,  0.4788,  0.3219,  0.2522],\n",
            "         ...,\n",
            "         [-0.2707, -0.2184, -0.1312,  ...,  0.0605,  0.0082,  0.0431],\n",
            "         [-0.2707, -0.1661, -0.0615,  ...,  0.0779,  0.0605,  0.0779],\n",
            "         [-0.2532, -0.2184, -0.1661,  ...,  0.0779,  0.0953,  0.1476]]]), tensor(0))\n",
            "Successfully unpacked batch 36\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 36\n",
            "\n",
            "Batch 37 type: <class 'tuple'>\n",
            "Batch 37 content: (tensor([[[ 1.0502,  1.0844,  1.1529,  ...,  1.1872,  1.1700,  1.1358],\n",
            "         [ 1.0844,  1.1358,  1.1700,  ...,  1.2043,  1.1700,  1.1358],\n",
            "         [ 1.0844,  1.1529,  1.2214,  ...,  1.2214,  1.1872,  1.1872],\n",
            "         ...,\n",
            "         [ 1.5125,  1.4783,  1.3584,  ...,  1.4612,  1.4954,  1.4783],\n",
            "         [ 1.5810,  1.5468,  1.4269,  ...,  1.4440,  1.5125,  1.4954],\n",
            "         [ 1.5982,  1.5810,  1.4783,  ...,  1.4440,  1.4440,  1.4612]],\n",
            "\n",
            "        [[ 0.1877,  0.2052,  0.2577,  ...,  0.3627,  0.3277,  0.2402],\n",
            "         [ 0.1176,  0.1527,  0.1877,  ...,  0.3102,  0.2752,  0.2402],\n",
            "         [ 0.0826,  0.1176,  0.2052,  ...,  0.2927,  0.2752,  0.2577],\n",
            "         ...,\n",
            "         [ 0.6254,  0.5728,  0.4503,  ...,  0.6954,  0.7479,  0.7304],\n",
            "         [ 0.6429,  0.5903,  0.4853,  ...,  0.7304,  0.7829,  0.7479],\n",
            "         [ 0.6604,  0.6254,  0.5378,  ...,  0.6954,  0.7129,  0.7129]],\n",
            "\n",
            "        [[-0.3404, -0.3230, -0.2707,  ..., -0.3404, -0.4101, -0.4798],\n",
            "         [-0.4450, -0.3927, -0.3404,  ..., -0.3753, -0.4624, -0.5321],\n",
            "         [-0.5321, -0.4450, -0.3230,  ..., -0.3927, -0.4624, -0.5147],\n",
            "         ...,\n",
            "         [ 0.1651,  0.1651,  0.0779,  ...,  0.0779,  0.1302,  0.1128],\n",
            "         [ 0.1128,  0.1128,  0.0779,  ...,  0.0953,  0.1651,  0.1128],\n",
            "         [ 0.1128,  0.1128,  0.0779,  ...,  0.0605,  0.0779,  0.0779]]]), tensor(0))\n",
            "Successfully unpacked batch 37\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 37\n",
            "\n",
            "Batch 38 type: <class 'tuple'>\n",
            "Batch 38 content: (tensor([[[ 0.3138,  0.3823,  0.4679,  ...,  1.4783,  1.4783,  1.4612],\n",
            "         [ 0.3309,  0.3994,  0.4851,  ...,  1.4612,  1.4440,  1.4440],\n",
            "         [ 0.4337,  0.4679,  0.5193,  ...,  1.4269,  1.4269,  1.4098],\n",
            "         ...,\n",
            "         [ 1.2043,  1.2214,  1.2899,  ...,  1.2557,  1.2728,  1.2557],\n",
            "         [ 1.1529,  1.1872,  1.2385,  ...,  1.2557,  1.2899,  1.2899],\n",
            "         [ 1.1015,  1.1358,  1.2214,  ...,  1.2214,  1.2557,  1.2385]],\n",
            "\n",
            "        [[-0.4601, -0.3901, -0.3025,  ...,  0.5728,  0.5378,  0.5553],\n",
            "         [-0.4601, -0.3901, -0.3025,  ...,  0.5728,  0.5378,  0.5553],\n",
            "         [-0.3550, -0.3375, -0.2850,  ...,  0.5903,  0.5728,  0.5378],\n",
            "         ...,\n",
            "         [ 0.0301,  0.0301,  0.1001,  ...,  0.2052,  0.1877,  0.1527],\n",
            "         [-0.0049,  0.0301,  0.1001,  ...,  0.2052,  0.1877,  0.1527],\n",
            "         [-0.0224,  0.0126,  0.1001,  ...,  0.2227,  0.2227,  0.1877]],\n",
            "\n",
            "        [[-0.5844, -0.5147, -0.4275,  ...,  0.4091,  0.3393,  0.3219],\n",
            "         [-0.5844, -0.4973, -0.3927,  ...,  0.4265,  0.3219,  0.3045],\n",
            "         [-0.5670, -0.5321, -0.4624,  ...,  0.4788,  0.4265,  0.3393],\n",
            "         ...,\n",
            "         [-0.0092,  0.0256,  0.0431,  ..., -0.0092, -0.0441, -0.0964],\n",
            "         [-0.0441,  0.0082,  0.0256,  ..., -0.0092, -0.0267, -0.0615],\n",
            "         [-0.1138, -0.0441,  0.0082,  ...,  0.0431,  0.0082, -0.0441]]]), tensor(0))\n",
            "Successfully unpacked batch 38\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 38\n",
            "\n",
            "Batch 39 type: <class 'tuple'>\n",
            "Batch 39 content: (tensor([[[ 0.6563,  0.5536,  0.5022,  ...,  1.3755,  1.3584,  1.3413],\n",
            "         [ 0.6734,  0.6392,  0.6221,  ...,  1.3927,  1.3927,  1.3755],\n",
            "         [ 0.6906,  0.7077,  0.6906,  ...,  1.3584,  1.3584,  1.3584],\n",
            "         ...,\n",
            "         [ 1.9578,  1.9578,  1.9749,  ...,  2.1975,  2.1462,  2.1462],\n",
            "         [ 1.9578,  1.9578,  1.9749,  ...,  2.1119,  2.1290,  2.1633],\n",
            "         [ 1.9578,  2.0092,  2.0434,  ...,  2.1804,  2.1804,  2.1975]],\n",
            "\n",
            "        [[ 0.0651, -0.0399, -0.0749,  ...,  0.3102,  0.3277,  0.3452],\n",
            "         [ 0.0301, -0.0224, -0.0574,  ...,  0.2927,  0.3803,  0.3978],\n",
            "         [ 0.0476,  0.0476,  0.0301,  ...,  0.3803,  0.3978,  0.3978],\n",
            "         ...,\n",
            "         [ 1.0630,  1.0805,  1.0805,  ...,  1.1681,  1.1155,  1.1331],\n",
            "         [ 1.0455,  1.0455,  1.0455,  ...,  1.0805,  1.0805,  1.1155],\n",
            "         [ 1.0105,  1.0630,  1.0980,  ...,  1.1155,  1.0980,  1.1155]],\n",
            "\n",
            "        [[-0.0092, -0.1138, -0.1312,  ..., -0.0615, -0.0615, -0.0441],\n",
            "         [-0.0615, -0.0964, -0.0790,  ..., -0.0964, -0.0615, -0.0441],\n",
            "         [-0.0441, -0.0267, -0.0092,  ..., -0.0267, -0.0267, -0.0267],\n",
            "         ...,\n",
            "         [ 0.6879,  0.7054,  0.7228,  ...,  0.7228,  0.6356,  0.6531],\n",
            "         [ 0.6356,  0.6356,  0.6356,  ...,  0.6356,  0.6182,  0.6356],\n",
            "         [ 0.6008,  0.6356,  0.7054,  ...,  0.7054,  0.6531,  0.6705]]]), tensor(0))\n",
            "Successfully unpacked batch 39\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 39\n",
            "\n",
            "Batch 40 type: <class 'tuple'>\n",
            "Batch 40 content: (tensor([[[-1.0904, -1.1589, -1.1589,  ...,  1.0159,  0.9988,  1.0159],\n",
            "         [-1.1760, -1.2445, -1.2617,  ...,  1.0159,  1.0159,  1.0331],\n",
            "         [-1.2959, -1.3130, -1.3644,  ...,  1.0673,  1.0673,  1.0159],\n",
            "         ...,\n",
            "         [ 0.8789,  0.8447,  0.9303,  ..., -1.4672, -1.4329, -1.4158],\n",
            "         [ 0.8618,  0.8789,  0.9303,  ..., -1.3987, -1.3473, -1.2617],\n",
            "         [ 0.7933,  0.8447,  0.9474,  ..., -1.3815, -1.2959, -1.1075]],\n",
            "\n",
            "        [[-1.4405, -1.4580, -1.4580,  ...,  0.3102,  0.3102,  0.3277],\n",
            "         [-1.5455, -1.5455, -1.5280,  ...,  0.3627,  0.3627,  0.3803],\n",
            "         [-1.5805, -1.5630, -1.5455,  ...,  0.4328,  0.4328,  0.3803],\n",
            "         ...,\n",
            "         [ 0.1702,  0.1702,  0.2227,  ..., -1.6155, -1.6331, -1.6681],\n",
            "         [ 0.2052,  0.1877,  0.1877,  ..., -1.5980, -1.6155, -1.6331],\n",
            "         [ 0.1527,  0.1702,  0.2227,  ..., -1.5980, -1.6155, -1.5805]],\n",
            "\n",
            "        [[-1.4384, -1.4907, -1.4559,  ...,  0.5311,  0.5485,  0.5834],\n",
            "         [-1.5430, -1.5430, -1.5081,  ...,  0.5485,  0.6008,  0.6356],\n",
            "         [-1.5779, -1.5604, -1.5256,  ...,  0.5136,  0.5311,  0.5311],\n",
            "         ...,\n",
            "         [ 0.1128,  0.0605,  0.1302,  ..., -1.5081, -1.5604, -1.5953],\n",
            "         [ 0.1128,  0.0605,  0.0953,  ..., -1.4907, -1.5430, -1.5604],\n",
            "         [ 0.1302,  0.0953,  0.1476,  ..., -1.4559, -1.4907, -1.4559]]]), tensor(1))\n",
            "Successfully unpacked batch 40\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 40\n",
            "\n",
            "Batch 41 type: <class 'tuple'>\n",
            "Batch 41 content: (tensor([[[-0.1143, -0.2513, -0.4568,  ...,  0.8104,  0.8104,  0.5364],\n",
            "         [-0.1828, -0.3883, -0.6281,  ...,  0.6221,  0.9303,  0.8961],\n",
            "         [-0.3712, -0.6452, -0.7822,  ...,  0.3652,  0.6392,  0.6906],\n",
            "         ...,\n",
            "         [ 0.4337,  0.3994,  0.3994,  ...,  0.9474,  0.9474,  0.9474],\n",
            "         [ 0.4851,  0.4166,  0.3823,  ...,  0.9988,  0.9988,  0.9474],\n",
            "         [ 0.4337,  0.3481,  0.3309,  ...,  0.9646,  0.9646,  0.9474]],\n",
            "\n",
            "        [[-0.6176, -0.7577, -1.0028,  ..., -0.1450, -0.1450, -0.3725],\n",
            "         [-0.6702, -0.8452, -1.1253,  ..., -0.3725,  0.0301,  0.0651],\n",
            "         [-0.9153, -1.1253, -1.2129,  ..., -0.5826, -0.3025, -0.1625],\n",
            "         ...,\n",
            "         [-0.0224, -0.0749, -0.1275,  ..., -0.0574, -0.1275, -0.1450],\n",
            "         [-0.0749, -0.1450, -0.1800,  ..., -0.0749, -0.1099, -0.1275],\n",
            "         [-0.1450, -0.2325, -0.2675,  ..., -0.0399, -0.0749, -0.0924]],\n",
            "\n",
            "        [[-0.6018, -0.6890, -0.9156,  ..., -0.3578, -0.4101, -0.6541],\n",
            "         [-0.6541, -0.8284, -1.0724,  ..., -0.6367, -0.3055, -0.3055],\n",
            "         [-0.7936, -1.0376, -1.1247,  ..., -0.9504, -0.7413, -0.6367],\n",
            "         ...,\n",
            "         [ 0.1302,  0.0779,  0.0605,  ..., -0.3578, -0.3578, -0.3578],\n",
            "         [ 0.1302,  0.0779,  0.0605,  ..., -0.3578, -0.3404, -0.3404],\n",
            "         [ 0.0605, -0.0267, -0.0441,  ..., -0.3927, -0.3404, -0.3230]]]), tensor(1))\n",
            "Successfully unpacked batch 41\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 41\n",
            "\n",
            "Batch 42 type: <class 'tuple'>\n",
            "Batch 42 content: (tensor([[[0.9303, 0.9474, 0.9646,  ..., 1.2385, 1.3242, 1.3413],\n",
            "         [0.9303, 0.9303, 0.9817,  ..., 1.3242, 1.3584, 1.3584],\n",
            "         [0.9132, 0.9303, 0.9988,  ..., 1.1187, 1.2385, 1.2728],\n",
            "         ...,\n",
            "         [1.5468, 1.5810, 1.5297,  ..., 1.6667, 1.6495, 1.5982],\n",
            "         [1.4954, 1.4954, 1.4783,  ..., 1.6667, 1.6667, 1.6153],\n",
            "         [1.4612, 1.5125, 1.5468,  ..., 1.7009, 1.6838, 1.6153]],\n",
            "\n",
            "        [[0.2927, 0.2752, 0.3102,  ..., 0.6254, 0.7304, 0.7304],\n",
            "         [0.3102, 0.2927, 0.3277,  ..., 0.6779, 0.7304, 0.7479],\n",
            "         [0.2752, 0.2927, 0.3277,  ..., 0.4678, 0.5903, 0.6604],\n",
            "         ...,\n",
            "         [0.4678, 0.5028, 0.4678,  ..., 1.0105, 1.0280, 0.9755],\n",
            "         [0.4503, 0.4328, 0.4328,  ..., 1.0105, 1.0455, 1.0105],\n",
            "         [0.4503, 0.4853, 0.5203,  ..., 1.0105, 1.0630, 1.0105]],\n",
            "\n",
            "        [[0.0779, 0.1128, 0.1999,  ..., 0.5834, 0.6879, 0.6879],\n",
            "         [0.1128, 0.1302, 0.2173,  ..., 0.7054, 0.7576, 0.7576],\n",
            "         [0.1302, 0.1476, 0.2348,  ..., 0.5136, 0.6182, 0.6531],\n",
            "         ...,\n",
            "         [0.5659, 0.6008, 0.5311,  ..., 1.0539, 1.0539, 1.0017],\n",
            "         [0.4265, 0.4265, 0.4614,  ..., 1.0714, 1.0714, 1.0365],\n",
            "         [0.3742, 0.4265, 0.5311,  ..., 1.0365, 1.0714, 1.0365]]]), tensor(0))\n",
            "Successfully unpacked batch 42\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 42\n",
            "\n",
            "Batch 43 type: <class 'tuple'>\n",
            "Batch 43 content: (tensor([[[ 1.1015,  1.0844,  0.9817,  ...,  1.3070,  1.1872,  1.1700],\n",
            "         [ 1.0502,  1.0502,  0.9988,  ...,  1.3070,  1.4269,  1.2214],\n",
            "         [ 1.0673,  1.0673,  1.0502,  ...,  1.2728,  1.6153,  1.3242],\n",
            "         ...,\n",
            "         [ 2.0777,  2.0434,  2.0263,  ...,  2.0948,  2.1290,  2.0948],\n",
            "         [ 2.0434,  1.9920,  2.0434,  ...,  2.0948,  2.0948,  2.0948],\n",
            "         [ 1.9407,  1.9064,  2.0092,  ...,  2.1290,  2.0948,  2.1290]],\n",
            "\n",
            "        [[ 0.2052,  0.1877,  0.0651,  ...,  0.7129,  0.6429,  0.5903],\n",
            "         [ 0.1352,  0.1176,  0.0476,  ...,  0.7654,  0.8704,  0.6429],\n",
            "         [ 0.0651,  0.0651,  0.0651,  ...,  0.7654,  1.0805,  0.7129],\n",
            "         ...,\n",
            "         [ 1.4832,  1.5007,  1.4832,  ...,  1.4132,  1.4657,  1.4307],\n",
            "         [ 1.4657,  1.4832,  1.5357,  ...,  1.4307,  1.4307,  1.4132],\n",
            "         [ 1.3957,  1.4132,  1.5182,  ...,  1.4482,  1.3957,  1.3957]],\n",
            "\n",
            "        [[-0.0267, -0.0790, -0.2358,  ...,  0.5136,  0.4265,  0.3916],\n",
            "         [-0.0790, -0.1138, -0.2010,  ...,  0.5485,  0.6705,  0.4265],\n",
            "         [-0.1487, -0.1487, -0.1487,  ...,  0.5659,  0.8797,  0.5136],\n",
            "         ...,\n",
            "         [ 1.3677,  1.3677,  1.3851,  ...,  1.2108,  1.2805,  1.2631],\n",
            "         [ 1.3851,  1.3851,  1.4374,  ...,  1.2457,  1.2457,  1.2282],\n",
            "         [ 1.2980,  1.2805,  1.4025,  ...,  1.2631,  1.2108,  1.2282]]]), tensor(0))\n",
            "Successfully unpacked batch 43\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 43\n",
            "\n",
            "Batch 44 type: <class 'tuple'>\n",
            "Batch 44 content: (tensor([[[ 0.8447,  0.7762,  0.2796,  ..., -1.5699, -1.6042, -1.6042],\n",
            "         [ 0.8789,  0.8618,  0.3994,  ..., -1.5528, -1.5870, -1.6042],\n",
            "         [ 0.9474,  0.9474,  0.5707,  ..., -1.5357, -1.5185, -1.5528],\n",
            "         ...,\n",
            "         [ 2.2489,  2.2489,  2.2489,  ...,  2.0605,  2.0434,  2.0434],\n",
            "         [ 2.2489,  2.2489,  2.2489,  ...,  2.0605,  2.0777,  2.0605],\n",
            "         [ 2.2489,  2.2489,  2.2489,  ...,  2.0092,  2.0092,  2.0263]],\n",
            "\n",
            "        [[ 0.1702,  0.0826, -0.4426,  ..., -1.6155, -1.6681, -1.7206],\n",
            "         [ 0.2052,  0.1877, -0.3025,  ..., -1.6155, -1.6681, -1.7381],\n",
            "         [ 0.2227,  0.2402, -0.1450,  ..., -1.6155, -1.6155, -1.6856],\n",
            "         ...,\n",
            "         [ 1.3431,  1.4657,  1.5182,  ...,  1.4832,  1.4657,  1.4657],\n",
            "         [ 1.3606,  1.4132,  1.4832,  ...,  1.4832,  1.5007,  1.4832],\n",
            "         [ 1.4482,  1.4482,  1.4482,  ...,  1.4482,  1.4657,  1.4832]],\n",
            "\n",
            "        [[ 0.1651,  0.0953, -0.4275,  ..., -1.4907, -1.5430, -1.5779],\n",
            "         [ 0.1302,  0.1302, -0.3404,  ..., -1.4733, -1.5256, -1.5604],\n",
            "         [ 0.1651,  0.1825, -0.1661,  ..., -1.4559, -1.4559, -1.5081],\n",
            "         ...,\n",
            "         [ 1.3677,  1.4897,  1.5420,  ...,  1.5420,  1.5245,  1.5420],\n",
            "         [ 1.4025,  1.4722,  1.5245,  ...,  1.5420,  1.5594,  1.5420],\n",
            "         [ 1.4897,  1.5071,  1.4897,  ...,  1.5594,  1.5594,  1.5420]]]), tensor(0))\n",
            "Successfully unpacked batch 44\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 44\n",
            "\n",
            "Batch 45 type: <class 'tuple'>\n",
            "Batch 45 content: (tensor([[[ 0.3994,  0.1254, -0.0801,  ...,  1.4954,  1.4954,  1.5125],\n",
            "         [ 0.0912, -0.1828, -0.2856,  ...,  1.4954,  1.5125,  1.5297],\n",
            "         [ 0.0569, -0.1828, -0.3712,  ...,  1.4783,  1.5639,  1.6153],\n",
            "         ...,\n",
            "         [ 2.0777,  2.0777,  2.0605,  ...,  2.1462,  2.1804,  2.1975],\n",
            "         [ 2.0948,  2.0948,  2.0777,  ...,  2.2147,  2.1975,  2.1975],\n",
            "         [ 2.1119,  2.1290,  2.1119,  ...,  2.2489,  2.2318,  2.2318]],\n",
            "\n",
            "        [[-0.8627, -1.0028, -1.0378,  ...,  0.2402,  0.2927,  0.3277],\n",
            "         [-1.0553, -1.2479, -1.1954,  ...,  0.2577,  0.3102,  0.3627],\n",
            "         [-0.8978, -1.0553, -1.1779,  ...,  0.2227,  0.3452,  0.4328],\n",
            "         ...,\n",
            "         [ 0.6954,  0.7304,  0.7654,  ...,  0.7479,  0.7829,  0.7829],\n",
            "         [ 0.6954,  0.7479,  0.7829,  ...,  0.7829,  0.7479,  0.7479],\n",
            "         [ 0.7654,  0.8004,  0.8004,  ...,  0.7479,  0.7129,  0.7479]],\n",
            "\n",
            "        [[-1.2119, -1.3164, -1.2990,  ...,  0.0082,  0.0605,  0.0953],\n",
            "         [-1.3339, -1.4559, -1.3861,  ...,  0.0605,  0.0953,  0.1302],\n",
            "         [-1.1770, -1.3339, -1.4210,  ...,  0.0779,  0.1651,  0.2173],\n",
            "         ...,\n",
            "         [ 0.3045,  0.3219,  0.3393,  ...,  0.0431,  0.0779,  0.1128],\n",
            "         [ 0.3045,  0.3393,  0.3393,  ...,  0.1128,  0.1128,  0.1128],\n",
            "         [ 0.3568,  0.3916,  0.3742,  ...,  0.1825,  0.1825,  0.1999]]]), tensor(0))\n",
            "Successfully unpacked batch 45\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 45\n",
            "\n",
            "Batch 46 type: <class 'tuple'>\n",
            "Batch 46 content: (tensor([[[ 1.2043,  1.1187,  1.0844,  ..., -1.9124, -2.0494, -2.1008],\n",
            "         [ 1.2557,  1.0673,  1.0673,  ..., -1.9124, -1.9980, -2.0665],\n",
            "         [ 1.2043,  1.1358,  1.1187,  ..., -1.9638, -1.9980, -2.0323],\n",
            "         ...,\n",
            "         [ 1.4440,  1.4783,  1.4269,  ...,  0.9474,  0.8447,  0.7933],\n",
            "         [ 1.4269,  1.4783,  1.4612,  ...,  0.9817,  0.8961,  0.7933],\n",
            "         [ 1.4269,  1.4612,  1.4783,  ...,  0.9132,  0.8618,  0.7762]],\n",
            "\n",
            "        [[ 0.3803,  0.3452,  0.3452,  ..., -1.8957, -1.9482, -1.9657],\n",
            "         [ 0.4503,  0.2927,  0.3102,  ..., -1.8957, -1.9307, -1.9482],\n",
            "         [ 0.3627,  0.3452,  0.3277,  ..., -1.8782, -1.9307, -1.9482],\n",
            "         ...,\n",
            "         [ 0.5378,  0.5728,  0.5553,  ...,  0.2752,  0.1877,  0.0651],\n",
            "         [ 0.5903,  0.6078,  0.5903,  ...,  0.3102,  0.2052,  0.0476],\n",
            "         [ 0.5903,  0.6078,  0.5903,  ...,  0.2402,  0.1702,  0.0651]],\n",
            "\n",
            "        [[ 0.4439,  0.4265,  0.4265,  ..., -1.7347, -1.8044, -1.8044],\n",
            "         [ 0.4439,  0.3045,  0.3393,  ..., -1.7522, -1.7870, -1.8044],\n",
            "         [ 0.3393,  0.3219,  0.3219,  ..., -1.7696, -1.7696, -1.7870],\n",
            "         ...,\n",
            "         [ 0.4614,  0.5311,  0.5136,  ...,  0.3393,  0.2522,  0.1476],\n",
            "         [ 0.4788,  0.5311,  0.5485,  ...,  0.4788,  0.3742,  0.1999],\n",
            "         [ 0.5311,  0.5659,  0.5834,  ...,  0.3742,  0.3393,  0.2348]]]), tensor(0))\n",
            "Successfully unpacked batch 46\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 46\n",
            "\n",
            "Batch 47 type: <class 'tuple'>\n",
            "Batch 47 content: (tensor([[[ 0.6563,  0.6734,  0.6734,  ...,  0.5536,  0.3652,  0.4337],\n",
            "         [ 0.6221,  0.6906,  0.6392,  ...,  0.3481,  0.2796,  0.5193],\n",
            "         [ 0.5707,  0.6563,  0.5707,  ..., -0.0116, -0.0116,  0.2624],\n",
            "         ...,\n",
            "         [ 1.2043,  1.2043,  1.1529,  ...,  1.2214,  1.1529,  1.1529],\n",
            "         [ 1.1872,  1.2043,  1.2043,  ...,  1.3242,  1.2043,  1.1700],\n",
            "         [ 1.2043,  1.2043,  1.2557,  ...,  1.4612,  1.4440,  1.3413]],\n",
            "\n",
            "        [[ 0.1527,  0.2052,  0.2577,  ...,  0.0826, -0.1099, -0.0749],\n",
            "         [ 0.1001,  0.1877,  0.1877,  ..., -0.2150, -0.2675, -0.0399],\n",
            "         [-0.0399,  0.1001,  0.0476,  ..., -0.5476, -0.5826, -0.3200],\n",
            "         ...,\n",
            "         [ 0.5728,  0.5903,  0.5203,  ...,  0.7479,  0.7304,  0.7479],\n",
            "         [ 0.5903,  0.5903,  0.5728,  ...,  0.9055,  0.7829,  0.7654],\n",
            "         [ 0.6078,  0.5903,  0.6078,  ...,  1.0805,  1.0455,  0.9405]],\n",
            "\n",
            "        [[ 0.1128,  0.1128,  0.0953,  ...,  0.2173, -0.0092,  0.0082],\n",
            "         [ 0.0431,  0.1128,  0.1128,  ..., -0.0441, -0.1312,  0.0605],\n",
            "         [-0.0441,  0.0779,  0.0605,  ..., -0.3927, -0.4101, -0.1661],\n",
            "         ...,\n",
            "         [ 0.5659,  0.5659,  0.5311,  ...,  0.7576,  0.7402,  0.7402],\n",
            "         [ 0.5311,  0.5485,  0.5659,  ...,  0.9145,  0.7402,  0.6705],\n",
            "         [ 0.5834,  0.5834,  0.6182,  ...,  1.1062,  1.0017,  0.8622]]]), tensor(0))\n",
            "Successfully unpacked batch 47\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 47\n",
            "\n",
            "Batch 48 type: <class 'tuple'>\n",
            "Batch 48 content: (tensor([[[-0.7822, -0.6965, -0.6623,  ..., -0.6794, -0.7137, -0.7479],\n",
            "         [-0.6452, -0.6281, -0.7308,  ..., -0.6965, -0.6965, -0.7479],\n",
            "         [-0.3712, -0.4054, -0.5253,  ..., -0.7993, -0.6623, -0.6623],\n",
            "         ...,\n",
            "         [ 0.3309,  0.3652,  0.3994,  ...,  0.0056,  0.0227, -0.0116],\n",
            "         [ 0.3138,  0.3652,  0.4166,  ..., -0.1143, -0.0801, -0.0629],\n",
            "         [ 0.3481,  0.3994,  0.3823,  ..., -0.0972, -0.1314, -0.1314]],\n",
            "\n",
            "        [[-1.1604, -1.1078, -1.1253,  ..., -0.9328, -0.9328, -0.9503],\n",
            "         [-1.0553, -1.0553, -1.1954,  ..., -0.9503, -0.9153, -0.9678],\n",
            "         [-0.8452, -0.8627, -0.9853,  ..., -1.0203, -0.9153, -0.9678],\n",
            "         ...,\n",
            "         [-0.4251, -0.4076, -0.4426,  ..., -0.5651, -0.5301, -0.5651],\n",
            "         [-0.4251, -0.4076, -0.4251,  ..., -0.6001, -0.5651, -0.5476],\n",
            "         [-0.4426, -0.4076, -0.4251,  ..., -0.5651, -0.5476, -0.5476]],\n",
            "\n",
            "        [[-1.0376, -0.9678, -0.9853,  ..., -0.8981, -0.9678, -0.9853],\n",
            "         [-0.8981, -0.9156, -1.0898,  ..., -0.8633, -0.9156, -0.9504],\n",
            "         [-0.7238, -0.7761, -0.9156,  ..., -0.8807, -0.8284, -0.8633],\n",
            "         ...,\n",
            "         [-0.6715, -0.6715, -0.6367,  ..., -0.3230, -0.3055, -0.3404],\n",
            "         [-0.6193, -0.6367, -0.6193,  ..., -0.3753, -0.3578, -0.3230],\n",
            "         [-0.5844, -0.5844, -0.6193,  ..., -0.3230, -0.3230, -0.3230]]]), tensor(1))\n",
            "Successfully unpacked batch 48\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 48\n",
            "\n",
            "Batch 49 type: <class 'tuple'>\n",
            "Batch 49 content: (tensor([[[-0.4911, -0.4568, -0.3541,  ..., -0.2513, -0.4226, -0.4911],\n",
            "         [-0.5424, -0.4739, -0.3712,  ..., -0.4739, -0.3369, -0.2342],\n",
            "         [-0.4911, -0.4568, -0.3541,  ..., -0.3198, -0.1143, -0.1314],\n",
            "         ...,\n",
            "         [-0.3883, -0.3883, -0.4568,  ...,  0.6563,  0.6734,  0.6392],\n",
            "         [-0.4397, -0.4911, -0.4911,  ...,  0.6392,  0.6049,  0.6049],\n",
            "         [-0.5082, -0.5767, -0.6109,  ...,  0.6221,  0.5707,  0.5707]],\n",
            "\n",
            "        [[-0.9678, -0.9153, -0.8452,  ..., -0.7227, -0.9328, -1.0028],\n",
            "         [-1.0028, -0.9678, -0.8978,  ..., -0.9328, -0.8627, -0.7927],\n",
            "         [-0.9153, -0.8452, -0.7927,  ..., -0.7227, -0.5826, -0.6176],\n",
            "         ...,\n",
            "         [-0.8978, -0.9328, -0.9853,  ..., -0.1450, -0.1275, -0.1625],\n",
            "         [-0.9328, -1.0028, -1.0028,  ..., -0.1800, -0.1800, -0.1450],\n",
            "         [-0.8627, -0.9328, -0.9678,  ..., -0.2150, -0.1975, -0.1975]],\n",
            "\n",
            "        [[-0.8981, -0.9156, -0.8284,  ..., -0.4450, -0.6890, -0.8110],\n",
            "         [-0.9330, -0.8981, -0.8458,  ..., -0.6715, -0.6367, -0.6018],\n",
            "         [-0.8458, -0.8110, -0.7238,  ..., -0.4973, -0.3927, -0.4798],\n",
            "         ...,\n",
            "         [-0.7761, -0.7936, -0.8458,  ..., -0.3578, -0.3578, -0.3927],\n",
            "         [-0.7936, -0.8633, -0.8284,  ..., -0.3753, -0.4101, -0.3753],\n",
            "         [-0.7936, -0.8284, -0.8284,  ..., -0.3404, -0.3753, -0.3578]]]), tensor(1))\n",
            "Successfully unpacked batch 49\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 49\n",
            "\n",
            "Batch 50 type: <class 'tuple'>\n",
            "Batch 50 content: (tensor([[[1.2214, 1.1872, 1.2214,  ..., 0.8276, 0.7762, 0.8447],\n",
            "         [1.2557, 1.2385, 1.2214,  ..., 0.9132, 0.8104, 0.7762],\n",
            "         [1.2385, 1.2214, 1.2385,  ..., 0.8961, 0.8447, 0.7762],\n",
            "         ...,\n",
            "         [1.2557, 1.3070, 1.3070,  ..., 1.0502, 1.0159, 0.9988],\n",
            "         [1.2385, 1.2728, 1.3584,  ..., 1.0673, 0.9988, 1.0159],\n",
            "         [1.2557, 1.2899, 1.3413,  ..., 1.0673, 1.0159, 1.0159]],\n",
            "\n",
            "        [[0.4853, 0.4503, 0.4503,  ..., 0.1352, 0.1527, 0.2577],\n",
            "         [0.5028, 0.4853, 0.4328,  ..., 0.2052, 0.1527, 0.1702],\n",
            "         [0.4503, 0.4153, 0.4153,  ..., 0.2227, 0.2052, 0.1877],\n",
            "         ...,\n",
            "         [0.1702, 0.2577, 0.3277,  ..., 0.3627, 0.3277, 0.3102],\n",
            "         [0.1702, 0.2227, 0.3102,  ..., 0.3978, 0.3627, 0.3803],\n",
            "         [0.2577, 0.2752, 0.2927,  ..., 0.4153, 0.4153, 0.4503]],\n",
            "\n",
            "        [[0.4439, 0.3916, 0.4439,  ..., 0.1128, 0.0953, 0.1825],\n",
            "         [0.4788, 0.4614, 0.4439,  ..., 0.2348, 0.1302, 0.1302],\n",
            "         [0.5136, 0.4788, 0.4788,  ..., 0.2871, 0.1825, 0.1302],\n",
            "         ...,\n",
            "         [0.1476, 0.1999, 0.2696,  ..., 0.3568, 0.3045, 0.2696],\n",
            "         [0.0779, 0.1128, 0.2522,  ..., 0.3568, 0.3219, 0.3393],\n",
            "         [0.1128, 0.1302, 0.2348,  ..., 0.3219, 0.3393, 0.3742]]]), tensor(1))\n",
            "Successfully unpacked batch 50\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 50\n",
            "\n",
            "Batch 51 type: <class 'tuple'>\n",
            "Batch 51 content: (tensor([[[1.2557, 1.2899, 1.2899,  ..., 2.0263, 2.0092, 2.0434],\n",
            "         [1.3070, 1.3242, 1.2728,  ..., 1.9578, 1.9920, 2.0263],\n",
            "         [1.3242, 1.3413, 1.3242,  ..., 1.9749, 1.9749, 2.0092],\n",
            "         ...,\n",
            "         [2.1975, 2.1975, 2.2318,  ..., 2.1633, 2.1119, 2.0948],\n",
            "         [2.2147, 2.2147, 2.2318,  ..., 2.1290, 2.1290, 2.1290],\n",
            "         [2.1633, 2.2318, 2.2318,  ..., 2.1290, 2.1804, 2.1633]],\n",
            "\n",
            "        [[0.3803, 0.4153, 0.4503,  ..., 1.3431, 1.3256, 1.3606],\n",
            "         [0.3978, 0.4153, 0.3978,  ..., 1.2731, 1.3081, 1.3606],\n",
            "         [0.3803, 0.4153, 0.4153,  ..., 1.3081, 1.2906, 1.3431],\n",
            "         ...,\n",
            "         [1.3081, 1.2731, 1.2906,  ..., 1.3081, 1.2731, 1.2906],\n",
            "         [1.3081, 1.2731, 1.2906,  ..., 1.2906, 1.2906, 1.3256],\n",
            "         [1.2206, 1.2906, 1.3081,  ..., 1.3081, 1.3782, 1.3606]],\n",
            "\n",
            "        [[0.1825, 0.1999, 0.2348,  ..., 1.3154, 1.2980, 1.3502],\n",
            "         [0.1825, 0.1825, 0.1476,  ..., 1.2457, 1.2805, 1.3328],\n",
            "         [0.1999, 0.2173, 0.1825,  ..., 1.2457, 1.2457, 1.2980],\n",
            "         ...,\n",
            "         [1.3154, 1.2980, 1.3328,  ..., 1.3851, 1.3154, 1.2980],\n",
            "         [1.3502, 1.3154, 1.3502,  ..., 1.3851, 1.3328, 1.3328],\n",
            "         [1.2457, 1.3154, 1.3677,  ..., 1.3677, 1.3677, 1.3502]]]), tensor(0))\n",
            "Successfully unpacked batch 51\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 51\n",
            "\n",
            "Batch 52 type: <class 'tuple'>\n",
            "Batch 52 content: (tensor([[[ 1.7352,  1.7009,  1.6667,  ...,  1.4783,  1.5982,  1.6153],\n",
            "         [ 1.7523,  1.7865,  1.7523,  ...,  1.3927,  1.5468,  1.5639],\n",
            "         [ 1.7694,  1.8379,  1.8037,  ...,  1.3242,  1.4954,  1.5297],\n",
            "         ...,\n",
            "         [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
            "         [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
            "         [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
            "\n",
            "        [[ 0.6429,  0.5903,  0.5203,  ...,  0.1352,  0.2577,  0.3102],\n",
            "         [ 0.6078,  0.6779,  0.6779,  ...,  0.0826,  0.2227,  0.2577],\n",
            "         [ 0.6254,  0.7654,  0.7829,  ...,  0.0126,  0.1877,  0.2227],\n",
            "         ...,\n",
            "         [ 1.1506,  1.1155,  1.0980,  ...,  0.7479,  0.7304,  0.7129],\n",
            "         [ 1.1331,  1.0805,  1.0805,  ...,  0.7829,  0.6954,  0.7304],\n",
            "         [ 1.1506,  1.1155,  1.1155,  ...,  0.7129,  0.6604,  0.7129]],\n",
            "\n",
            "        [[-0.1138, -0.1312, -0.1487,  ..., -0.2184, -0.0964, -0.0267],\n",
            "         [-0.1661, -0.0615, -0.0441,  ..., -0.2532, -0.1312, -0.0790],\n",
            "         [-0.1138,  0.0431,  0.0953,  ..., -0.3404, -0.1835, -0.1138],\n",
            "         ...,\n",
            "         [ 0.6531,  0.6182,  0.6356,  ...,  0.3916,  0.3916,  0.4265],\n",
            "         [ 0.6356,  0.6008,  0.6182,  ...,  0.3916,  0.3219,  0.3916],\n",
            "         [ 0.6356,  0.6356,  0.6356,  ...,  0.3045,  0.2522,  0.3045]]]), tensor(2))\n",
            "Successfully unpacked batch 52\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 52\n",
            "\n",
            "Batch 53 type: <class 'tuple'>\n",
            "Batch 53 content: (tensor([[[ 0.1768,  0.2624,  0.3138,  ...,  0.7933,  0.7933,  0.8104],\n",
            "         [ 0.2796,  0.3481,  0.3823,  ...,  0.8104,  0.8104,  0.8447],\n",
            "         [ 0.3823,  0.3481,  0.3652,  ...,  0.8276,  0.8276,  0.8104],\n",
            "         ...,\n",
            "         [ 1.1529,  1.1700,  1.1872,  ...,  1.3070,  1.3070,  1.3070],\n",
            "         [ 1.1358,  1.1700,  1.1872,  ...,  1.3242,  1.3070,  1.3070],\n",
            "         [ 1.0673,  1.0844,  1.1358,  ...,  1.2899,  1.2899,  1.2728]],\n",
            "\n",
            "        [[-0.7752, -0.7052, -0.6877,  ..., -0.0049, -0.0574, -0.0749],\n",
            "         [-0.7227, -0.6702, -0.6527,  ..., -0.0574, -0.0924, -0.0749],\n",
            "         [-0.6352, -0.6527, -0.6176,  ..., -0.0749, -0.0924, -0.1099],\n",
            "         ...,\n",
            "         [ 0.1527,  0.1527,  0.2052,  ...,  0.3803,  0.3803,  0.3627],\n",
            "         [ 0.1001,  0.1527,  0.2052,  ...,  0.3803,  0.3452,  0.3452],\n",
            "         [ 0.0651,  0.1001,  0.1877,  ...,  0.3452,  0.3277,  0.3277]],\n",
            "\n",
            "        [[-0.8284, -0.7936, -0.8284,  ..., -0.0964, -0.1138, -0.1138],\n",
            "         [-0.7238, -0.7064, -0.7587,  ..., -0.1312, -0.1835, -0.1835],\n",
            "         [-0.6541, -0.7413, -0.7761,  ..., -0.0964, -0.1312, -0.1661],\n",
            "         ...,\n",
            "         [ 0.1128,  0.0779,  0.0779,  ...,  0.3742,  0.4091,  0.4091],\n",
            "         [ 0.0779,  0.0605,  0.0779,  ...,  0.3916,  0.3916,  0.3916],\n",
            "         [ 0.0082,  0.0082,  0.0605,  ...,  0.3393,  0.3393,  0.3219]]]), tensor(2))\n",
            "Successfully unpacked batch 53\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 53\n",
            "\n",
            "Batch 54 type: <class 'tuple'>\n",
            "Batch 54 content: (tensor([[[-0.9534, -1.0048, -1.0904,  ...,  0.0741,  0.1597,  0.1083],\n",
            "         [-1.0390, -1.0733, -1.1589,  ..., -0.0116,  0.1597,  0.1597],\n",
            "         [-1.0904, -1.0904, -1.1418,  ..., -0.1314,  0.1083,  0.1597],\n",
            "         ...,\n",
            "         [ 0.9988,  1.0159,  1.0159,  ...,  1.2557,  1.2043,  1.2214],\n",
            "         [ 0.9988,  0.9817,  0.9988,  ...,  1.2557,  1.2557,  1.3070],\n",
            "         [ 0.9303,  0.9474,  0.9988,  ...,  1.2899,  1.3242,  1.3242]],\n",
            "\n",
            "        [[-1.2479, -1.3004, -1.3529,  ..., -0.6877, -0.5826, -0.6352],\n",
            "         [-1.3004, -1.3354, -1.4055,  ..., -0.7227, -0.5826, -0.5826],\n",
            "         [-1.3529, -1.3529, -1.3880,  ..., -0.7752, -0.6176, -0.5651],\n",
            "         ...,\n",
            "         [ 0.2402,  0.2402,  0.1877,  ...,  0.3102,  0.2752,  0.2927],\n",
            "         [ 0.2402,  0.2052,  0.1877,  ...,  0.3102,  0.3102,  0.3627],\n",
            "         [ 0.2227,  0.2052,  0.2227,  ...,  0.3102,  0.3803,  0.3803]],\n",
            "\n",
            "        [[-1.0724, -1.1073, -1.1770,  ..., -0.5321, -0.4624, -0.5147],\n",
            "         [-1.1247, -1.1596, -1.2467,  ..., -0.6018, -0.4101, -0.4101],\n",
            "         [-1.1770, -1.1944, -1.2293,  ..., -0.7413, -0.4450, -0.4101],\n",
            "         ...,\n",
            "         [ 0.2348,  0.2173,  0.1651,  ...,  0.1999,  0.1476,  0.1825],\n",
            "         [ 0.2871,  0.1999,  0.1476,  ...,  0.2173,  0.2173,  0.2871],\n",
            "         [ 0.2522,  0.1999,  0.1651,  ...,  0.2696,  0.3045,  0.3045]]]), tensor(1))\n",
            "Successfully unpacked batch 54\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 54\n",
            "\n",
            "Batch 55 type: <class 'tuple'>\n",
            "Batch 55 content: (tensor([[[ 0.1597, -0.3712, -0.2856,  ..., -0.7137, -0.7822, -0.7822],\n",
            "         [-0.1486, -0.6109, -0.3027,  ..., -0.7993, -0.9192, -0.9877],\n",
            "         [-0.4911, -0.6965, -0.3027,  ..., -0.6623, -0.7650, -0.8507],\n",
            "         ...,\n",
            "         [ 1.9407,  2.0092,  2.0092,  ...,  1.9578,  1.9578,  1.9749],\n",
            "         [ 1.9920,  1.9920,  1.9920,  ...,  1.9920,  1.9578,  1.9578],\n",
            "         [ 1.9064,  1.9064,  1.9749,  ...,  2.0263,  1.9920,  1.9920]],\n",
            "\n",
            "        [[-0.6702, -1.1604, -1.0553,  ..., -1.3179, -1.3354, -1.3179],\n",
            "         [-0.8627, -1.3354, -1.0378,  ..., -1.3880, -1.4405, -1.4755],\n",
            "         [-1.1779, -1.4230, -1.0378,  ..., -1.3704, -1.4230, -1.4405],\n",
            "         ...,\n",
            "         [ 0.3978,  0.4678,  0.4853,  ...,  0.7129,  0.7479,  0.7479],\n",
            "         [ 0.4678,  0.4853,  0.4853,  ...,  0.7304,  0.7304,  0.7479],\n",
            "         [ 0.4328,  0.4153,  0.4678,  ...,  0.7654,  0.7304,  0.7479]],\n",
            "\n",
            "        [[-0.6367, -1.1944, -1.1073,  ..., -1.3513, -1.3861, -1.3687],\n",
            "         [-0.8458, -1.3687, -1.1073,  ..., -1.3513, -1.4036, -1.4384],\n",
            "         [-1.1770, -1.4559, -1.1247,  ..., -1.3513, -1.3687, -1.3861],\n",
            "         ...,\n",
            "         [-0.1835, -0.0964, -0.0790,  ...,  0.0953,  0.0431,  0.0256],\n",
            "         [-0.0964, -0.0441, -0.0267,  ...,  0.0953, -0.0092, -0.0267],\n",
            "         [-0.1138, -0.1138, -0.0267,  ...,  0.2173,  0.1302,  0.0779]]]), tensor(1))\n",
            "Successfully unpacked batch 55\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 55\n",
            "\n",
            "Batch 56 type: <class 'tuple'>\n",
            "Batch 56 content: (tensor([[[-0.5767, -0.6794, -0.7479,  ...,  0.1254,  0.1597,  0.1939],\n",
            "         [-0.5767, -0.5253, -0.5596,  ...,  0.2453,  0.2453,  0.1939],\n",
            "         [-0.4397, -0.3883, -0.4054,  ...,  0.2967,  0.2624,  0.1768],\n",
            "         ...,\n",
            "         [ 0.6221,  0.6049,  0.5878,  ...,  0.2967,  0.2624,  0.2453],\n",
            "         [ 0.6049,  0.6221,  0.6221,  ...,  0.2796,  0.2624,  0.2282],\n",
            "         [ 0.6392,  0.6563,  0.6734,  ...,  0.2282,  0.2453,  0.2282]],\n",
            "\n",
            "        [[-0.9678, -1.0028, -1.0028,  ..., -0.3725, -0.3725, -0.3200],\n",
            "         [-0.9853, -0.8452, -0.7577,  ..., -0.3200, -0.3375, -0.3901],\n",
            "         [-0.8277, -0.7052, -0.6702,  ..., -0.3200, -0.3550, -0.4251],\n",
            "         ...,\n",
            "         [ 0.0476,  0.0301,  0.0301,  ..., -0.2850, -0.2850, -0.2675],\n",
            "         [ 0.0651,  0.0651,  0.0476,  ..., -0.3025, -0.2850, -0.3025],\n",
            "         [ 0.0651,  0.0826,  0.1001,  ..., -0.3375, -0.3025, -0.3025]],\n",
            "\n",
            "        [[-1.0027, -1.0550, -1.0201,  ..., -0.3927, -0.3578, -0.2707],\n",
            "         [-1.0724, -0.9330, -0.8284,  ..., -0.4101, -0.3578, -0.3753],\n",
            "         [-0.8981, -0.7761, -0.7238,  ..., -0.4275, -0.4101, -0.4973],\n",
            "         ...,\n",
            "         [-0.1661, -0.1661, -0.1487,  ..., -0.4275, -0.4450, -0.4275],\n",
            "         [-0.1835, -0.1661, -0.1487,  ..., -0.4275, -0.4101, -0.4450],\n",
            "         [-0.1661, -0.1312, -0.0790,  ..., -0.4798, -0.4275, -0.4450]]]), tensor(0))\n",
            "Successfully unpacked batch 56\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 56\n",
            "\n",
            "Batch 57 type: <class 'tuple'>\n",
            "Batch 57 content: (tensor([[[ 0.6392,  0.5536,  0.6049,  ...,  0.2453,  0.2967,  0.2967],\n",
            "         [ 0.6392,  0.5536,  0.5878,  ...,  0.2453,  0.3309,  0.3138],\n",
            "         [ 0.6563,  0.6049,  0.6049,  ...,  0.2796,  0.3138,  0.3138],\n",
            "         ...,\n",
            "         [ 0.5878,  0.5536,  0.5193,  ...,  0.3138,  0.3652,  0.3652],\n",
            "         [ 0.5707,  0.5364,  0.5022,  ...,  0.3823,  0.3823,  0.3652],\n",
            "         [ 0.5536,  0.5536,  0.5193,  ...,  0.4508,  0.3994,  0.3994]],\n",
            "\n",
            "        [[-0.3375, -0.4251, -0.4076,  ..., -0.4076, -0.4076, -0.4601],\n",
            "         [-0.3200, -0.3901, -0.3725,  ..., -0.3550, -0.3200, -0.3901],\n",
            "         [-0.2850, -0.3200, -0.3200,  ..., -0.3550, -0.3375, -0.3901],\n",
            "         ...,\n",
            "         [-0.3550, -0.4076, -0.4251,  ..., -0.4601, -0.4426, -0.4776],\n",
            "         [-0.3901, -0.4601, -0.5126,  ..., -0.4251, -0.4251, -0.4251],\n",
            "         [-0.3901, -0.4251, -0.5301,  ..., -0.4076, -0.4076, -0.3725]],\n",
            "\n",
            "        [[-0.6715, -0.7936, -0.7587,  ..., -0.8284, -0.8284, -0.8458],\n",
            "         [-0.6018, -0.6890, -0.6715,  ..., -0.7936, -0.7238, -0.7761],\n",
            "         [-0.6367, -0.6715, -0.6715,  ..., -0.7761, -0.7238, -0.7413],\n",
            "         ...,\n",
            "         [-0.5147, -0.5844, -0.6367,  ..., -0.6715, -0.6367, -0.6541],\n",
            "         [-0.4973, -0.5670, -0.6541,  ..., -0.6890, -0.7064, -0.6890],\n",
            "         [-0.4798, -0.4973, -0.6193,  ..., -0.7587, -0.7761, -0.7413]]]), tensor(0))\n",
            "Successfully unpacked batch 57\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 57\n",
            "\n",
            "Batch 58 type: <class 'tuple'>\n",
            "Batch 58 content: (tensor([[[1.3755, 1.3584, 1.4269,  ..., 1.1872, 1.1872, 1.1700],\n",
            "         [1.4269, 1.3755, 1.3584,  ..., 1.2214, 1.2385, 1.1529],\n",
            "         [1.5468, 1.4783, 1.3927,  ..., 1.3242, 1.2899, 1.2043],\n",
            "         ...,\n",
            "         [1.4783, 1.4440, 1.4098,  ..., 1.6324, 1.6324, 1.5468],\n",
            "         [1.4269, 1.3927, 1.3755,  ..., 1.6324, 1.5468, 1.5468],\n",
            "         [1.4612, 1.4098, 1.4269,  ..., 1.5810, 1.5125, 1.5468]],\n",
            "\n",
            "        [[0.9930, 0.9755, 1.0280,  ..., 0.4328, 0.3803, 0.2927],\n",
            "         [1.0280, 0.9755, 0.9405,  ..., 0.4328, 0.3978, 0.2752],\n",
            "         [1.1155, 1.0455, 0.9580,  ..., 0.4328, 0.3803, 0.2752],\n",
            "         ...,\n",
            "         [0.9230, 0.8880, 0.8354,  ..., 0.5378, 0.5728, 0.5203],\n",
            "         [0.8354, 0.8004, 0.8004,  ..., 0.5553, 0.5203, 0.5378],\n",
            "         [0.7829, 0.7829, 0.8179,  ..., 0.5378, 0.5203, 0.5553]],\n",
            "\n",
            "        [[0.8622, 0.8797, 0.9319,  ..., 0.2871, 0.2173, 0.0779],\n",
            "         [0.9319, 0.9145, 0.9145,  ..., 0.2696, 0.2173, 0.0431],\n",
            "         [1.1062, 1.0539, 0.9842,  ..., 0.2871, 0.2173, 0.0779],\n",
            "         ...,\n",
            "         [0.7925, 0.7054, 0.6531,  ..., 0.5659, 0.5834, 0.4788],\n",
            "         [0.7576, 0.6879, 0.6531,  ..., 0.5311, 0.4614, 0.4439],\n",
            "         [0.7402, 0.7054, 0.7054,  ..., 0.4439, 0.3568, 0.3742]]]), tensor(0))\n",
            "Successfully unpacked batch 58\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 58\n",
            "\n",
            "Batch 59 type: <class 'tuple'>\n",
            "Batch 59 content: (tensor([[[ 1.4783,  1.4440,  1.4783,  ...,  0.5878,  0.5364,  0.4508],\n",
            "         [ 1.4612,  1.4612,  1.4954,  ...,  0.5878,  0.5193,  0.4508],\n",
            "         [ 1.5125,  1.5297,  1.5125,  ...,  0.5707,  0.4851,  0.4679],\n",
            "         ...,\n",
            "         [ 1.0502,  1.0673,  1.1187,  ...,  1.1872,  1.1700,  1.1872],\n",
            "         [ 0.9988,  1.0159,  1.0844,  ...,  1.1700,  1.1358,  1.1187],\n",
            "         [ 1.0331,  1.0502,  1.0331,  ...,  1.1358,  1.0844,  1.0844]],\n",
            "\n",
            "        [[ 0.5378,  0.4853,  0.5203,  ..., -0.0399, -0.0574, -0.1275],\n",
            "         [ 0.5553,  0.5553,  0.5728,  ..., -0.0574, -0.0924, -0.1275],\n",
            "         [ 0.5728,  0.5728,  0.5728,  ..., -0.0399, -0.0924, -0.0924],\n",
            "         ...,\n",
            "         [-0.0399,  0.0126,  0.1352,  ...,  0.2927,  0.2927,  0.3277],\n",
            "         [-0.0224,  0.0126,  0.1352,  ...,  0.2752,  0.2752,  0.2927],\n",
            "         [ 0.0301,  0.0826,  0.1176,  ...,  0.2752,  0.2752,  0.3102]],\n",
            "\n",
            "        [[ 0.3393,  0.3045,  0.3393,  ..., -0.3927, -0.4275, -0.4624],\n",
            "         [ 0.3045,  0.3045,  0.3219,  ..., -0.3404, -0.3927, -0.4275],\n",
            "         [ 0.3393,  0.3393,  0.3045,  ..., -0.3055, -0.3753, -0.3753],\n",
            "         ...,\n",
            "         [-0.2707, -0.2532, -0.1312,  ..., -0.0441, -0.0964, -0.0790],\n",
            "         [-0.2358, -0.2010, -0.0964,  ..., -0.0441, -0.0790, -0.0790],\n",
            "         [-0.0615, -0.0267, -0.0267,  ...,  0.0082, -0.0267, -0.0267]]]), tensor(0))\n",
            "Successfully unpacked batch 59\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 59\n",
            "\n",
            "Batch 60 type: <class 'tuple'>\n",
            "Batch 60 content: (tensor([[[ 1.1872,  0.6734,  0.5193,  ...,  1.1700,  1.1872,  1.2557],\n",
            "         [ 0.8447,  0.6563,  0.5536,  ...,  1.1358,  1.1529,  1.2385],\n",
            "         [ 0.5878,  0.5536,  0.4508,  ...,  1.0331,  1.1187,  1.2214],\n",
            "         ...,\n",
            "         [ 2.2318,  2.2147,  2.2489,  ...,  2.2318,  2.2489,  2.2318],\n",
            "         [ 2.1975,  2.1804,  2.2489,  ...,  2.2318,  2.2489,  2.2318],\n",
            "         [ 2.2147,  2.2147,  2.2147,  ...,  2.2318,  2.2318,  2.2489]],\n",
            "\n",
            "        [[ 0.1176, -0.4076, -0.4951,  ...,  0.2577,  0.2402,  0.2752],\n",
            "         [-0.3375, -0.4776, -0.4251,  ...,  0.1702,  0.1702,  0.2402],\n",
            "         [-0.5826, -0.4776, -0.4251,  ...,  0.0126,  0.1001,  0.2227],\n",
            "         ...,\n",
            "         [ 1.0280,  1.0455,  1.0455,  ...,  0.8004,  0.8179,  0.7829],\n",
            "         [ 1.0280,  1.0280,  1.0280,  ...,  0.8179,  0.8179,  0.8179],\n",
            "         [ 1.0105,  1.0105,  1.0280,  ...,  0.8704,  0.8529,  0.8529]],\n",
            "\n",
            "        [[-0.4101, -0.9156, -0.9678,  ..., -0.0441, -0.0092,  0.0431],\n",
            "         [-0.8110, -0.9330, -0.8807,  ..., -0.1138, -0.0790,  0.0082],\n",
            "         [-0.9853, -0.8807, -0.8807,  ..., -0.2184, -0.1138,  0.0082],\n",
            "         ...,\n",
            "         [ 0.3219,  0.3568,  0.3568,  ...,  0.2173,  0.2522,  0.2348],\n",
            "         [ 0.2522,  0.2522,  0.3219,  ...,  0.1999,  0.2173,  0.2173],\n",
            "         [ 0.2348,  0.2522,  0.3045,  ...,  0.2348,  0.2522,  0.2522]]]), tensor(0))\n",
            "Successfully unpacked batch 60\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 60\n",
            "\n",
            "Batch 61 type: <class 'tuple'>\n",
            "Batch 61 content: (tensor([[[-1.2274, -1.1247, -1.0390,  ...,  0.5707,  0.6049,  0.5878],\n",
            "         [-1.1418, -1.0562, -0.9877,  ...,  0.5536,  0.6049,  0.6049],\n",
            "         [-1.0904, -1.0562, -0.9705,  ...,  0.5707,  0.6392,  0.6221],\n",
            "         ...,\n",
            "         [-0.4397, -0.3883, -0.3541,  ...,  1.1358,  1.1358,  1.0673],\n",
            "         [-0.5082, -0.4568, -0.4226,  ...,  1.1529,  1.1358,  1.1187],\n",
            "         [-0.4911, -0.5082, -0.4739,  ...,  1.1529,  1.1529,  1.1358]],\n",
            "\n",
            "        [[-1.4930, -1.4580, -1.4055,  ..., -0.4601, -0.4076, -0.3901],\n",
            "         [-1.5280, -1.4230, -1.3529,  ..., -0.4776, -0.4251, -0.4076],\n",
            "         [-1.4755, -1.4055, -1.3704,  ..., -0.4776, -0.4601, -0.4951],\n",
            "         ...,\n",
            "         [-1.0203, -1.0203, -1.0378,  ..., -0.3025, -0.2500, -0.2325],\n",
            "         [-1.0203, -1.0028, -1.0203,  ..., -0.3375, -0.2675, -0.2150],\n",
            "         [-1.0028, -0.9853, -0.9678,  ..., -0.3550, -0.2850, -0.2850]],\n",
            "\n",
            "        [[-1.5256, -1.4733, -1.4210,  ..., -0.7064, -0.6541, -0.6367],\n",
            "         [-1.4907, -1.4036, -1.3513,  ..., -0.6890, -0.6193, -0.6018],\n",
            "         [-1.4384, -1.4210, -1.3861,  ..., -0.6193, -0.5844, -0.6367],\n",
            "         ...,\n",
            "         [-1.2467, -1.1944, -1.1421,  ..., -0.7064, -0.6367, -0.6367],\n",
            "         [-1.2990, -1.2467, -1.2293,  ..., -0.6890, -0.6193, -0.5844],\n",
            "         [-1.3164, -1.3339, -1.3164,  ..., -0.6367, -0.5670, -0.5670]]]), tensor(0))\n",
            "Successfully unpacked batch 61\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 61\n",
            "\n",
            "Batch 62 type: <class 'tuple'>\n",
            "Batch 62 content: (tensor([[[-1.5528, -1.5699, -1.5870,  ..., -1.2788, -1.4329, -1.4158],\n",
            "         [-1.6384, -1.6042, -1.6213,  ..., -1.3473, -1.5185, -1.4500],\n",
            "         [-1.6727, -1.6555, -1.6555,  ..., -1.3302, -1.5185, -1.4843],\n",
            "         ...,\n",
            "         [ 0.1254,  0.1426,  0.0912,  ..., -0.2171, -0.2513, -0.1828],\n",
            "         [ 0.1083,  0.1426,  0.1426,  ..., -0.1828, -0.2342, -0.1999],\n",
            "         [ 0.0569,  0.0569,  0.0912,  ..., -0.1143, -0.1143, -0.1314]],\n",
            "\n",
            "        [[-1.6155, -1.6331, -1.6331,  ..., -1.3880, -1.4755, -1.4405],\n",
            "         [-1.5805, -1.5805, -1.6155,  ..., -1.3529, -1.5105, -1.4405],\n",
            "         [-1.5455, -1.5105, -1.5455,  ..., -1.3179, -1.5455, -1.5105],\n",
            "         ...,\n",
            "         [-0.3725, -0.3375, -0.4251,  ..., -0.6877, -0.7577, -0.7052],\n",
            "         [-0.3901, -0.3550, -0.3725,  ..., -0.7227, -0.7577, -0.7402],\n",
            "         [-0.3375, -0.3550, -0.3550,  ..., -0.7227, -0.7227, -0.7227]],\n",
            "\n",
            "        [[-1.4907, -1.4907, -1.5081,  ..., -1.1421, -1.2816, -1.2641],\n",
            "         [-1.5256, -1.4907, -1.5256,  ..., -1.1770, -1.3513, -1.2641],\n",
            "         [-1.4733, -1.4559, -1.4733,  ..., -1.1596, -1.3687, -1.3339],\n",
            "         ...,\n",
            "         [-0.4450, -0.4450, -0.5321,  ..., -0.6018, -0.7064, -0.7064],\n",
            "         [-0.4101, -0.3927, -0.4275,  ..., -0.6890, -0.7587, -0.7587],\n",
            "         [-0.3578, -0.3753, -0.3927,  ..., -0.7413, -0.7587, -0.7413]]]), tensor(1))\n",
            "Successfully unpacked batch 62\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 62\n",
            "\n",
            "Batch 63 type: <class 'tuple'>\n",
            "Batch 63 content: (tensor([[[-0.8335, -0.7993, -0.7479,  ..., -0.9877, -0.9534, -0.9877],\n",
            "         [-0.8849, -0.8678, -0.7993,  ..., -0.9192, -0.8335, -0.8164],\n",
            "         [-0.9020, -0.9020, -0.8678,  ..., -0.8849, -0.8507, -0.7308],\n",
            "         ...,\n",
            "         [-0.0287,  0.0056, -0.0972,  ..., -0.1143, -0.0801, -0.0972],\n",
            "         [ 0.0056,  0.0398, -0.0801,  ..., -0.0458, -0.0458, -0.0629],\n",
            "         [-0.0972, -0.0458, -0.1314,  ..., -0.0287,  0.0056,  0.0056]],\n",
            "\n",
            "        [[-0.9853, -1.0028, -0.9853,  ..., -1.0553, -1.0203, -1.0203],\n",
            "         [-0.9503, -0.9503, -0.9503,  ..., -0.8803, -0.8277, -0.8102],\n",
            "         [-0.9153, -0.9328, -1.0028,  ..., -0.8277, -0.7752, -0.6527],\n",
            "         ...,\n",
            "         [-0.4251, -0.4076, -0.5301,  ..., -0.4776, -0.5126, -0.5126],\n",
            "         [-0.4076, -0.3901, -0.5301,  ..., -0.4426, -0.4601, -0.4426],\n",
            "         [-0.4251, -0.4076, -0.5301,  ..., -0.3550, -0.3550, -0.3375]],\n",
            "\n",
            "        [[-0.9156, -0.8981, -0.8633,  ..., -0.8458, -0.8110, -0.8284],\n",
            "         [-0.9156, -0.8981, -0.8807,  ..., -0.7064, -0.6541, -0.6367],\n",
            "         [-0.9504, -0.9330, -0.9504,  ..., -0.6541, -0.6018, -0.4798],\n",
            "         ...,\n",
            "         [-0.2358, -0.2184, -0.3055,  ..., -0.3055, -0.3055, -0.2881],\n",
            "         [-0.2532, -0.2184, -0.3404,  ..., -0.2532, -0.2707, -0.2184],\n",
            "         [-0.3230, -0.2881, -0.3927,  ..., -0.2010, -0.1835, -0.1312]]]), tensor(1))\n",
            "Successfully unpacked batch 63\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 63\n",
            "\n",
            "Batch 64 type: <class 'tuple'>\n",
            "Batch 64 content: (tensor([[[-0.4911, -0.4911, -0.4054,  ..., -1.4843, -1.3644, -1.3987],\n",
            "         [-0.4739, -0.5253, -0.4054,  ..., -1.5528, -1.2788, -1.2103],\n",
            "         [-0.3541, -0.3369, -0.3027,  ..., -1.5699, -1.2445, -1.0733],\n",
            "         ...,\n",
            "         [-0.1657, -0.1657, -0.1314,  ..., -0.3198, -0.2684, -0.3027],\n",
            "         [-0.1657, -0.1828, -0.1486,  ..., -0.3883, -0.3369, -0.3541],\n",
            "         [-0.0801, -0.1314, -0.1657,  ..., -0.4911, -0.4739, -0.4739]],\n",
            "\n",
            "        [[-0.6527, -0.6527, -0.5651,  ..., -1.4930, -1.3529, -1.4055],\n",
            "         [-0.6702, -0.7227, -0.6176,  ..., -1.5280, -1.3179, -1.2654],\n",
            "         [-0.6176, -0.6176, -0.6001,  ..., -1.5980, -1.3704, -1.2304],\n",
            "         ...,\n",
            "         [-0.5301, -0.5126, -0.4776,  ..., -0.8627, -0.8627, -0.9153],\n",
            "         [-0.5651, -0.5826, -0.6001,  ..., -0.8803, -0.8978, -0.9328],\n",
            "         [-0.6352, -0.6702, -0.7227,  ..., -0.9153, -0.9328, -0.9503]],\n",
            "\n",
            "        [[-0.6890, -0.6715, -0.5844,  ..., -1.3687, -1.2293, -1.2816],\n",
            "         [-0.7238, -0.7761, -0.7064,  ..., -1.4210, -1.1770, -1.1247],\n",
            "         [-0.6367, -0.6193, -0.6367,  ..., -1.5081, -1.2119, -1.0550],\n",
            "         ...,\n",
            "         [-0.8110, -0.7936, -0.7064,  ..., -0.9504, -0.9156, -0.9504],\n",
            "         [-0.7761, -0.8458, -0.8284,  ..., -1.0201, -0.9853, -1.0027],\n",
            "         [-0.7936, -0.8458, -0.9156,  ..., -1.0898, -1.0550, -1.0724]]]), tensor(0))\n",
            "Successfully unpacked batch 64\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 64\n",
            "\n",
            "Batch 65 type: <class 'tuple'>\n",
            "Batch 65 content: (tensor([[[ 1.3413,  1.2899,  1.2899,  ..., -1.2959, -1.4843, -1.5699],\n",
            "         [ 1.3413,  1.2899,  1.2899,  ..., -1.1075, -1.3130, -1.4500],\n",
            "         [ 1.2899,  1.2899,  1.3242,  ..., -1.0390, -1.3130, -1.4843],\n",
            "         ...,\n",
            "         [ 1.4440,  1.4098,  1.3927,  ...,  1.0844,  0.9474,  0.9817],\n",
            "         [ 1.4269,  1.3927,  1.3927,  ...,  1.0844,  0.9474,  0.9646],\n",
            "         [ 1.4269,  1.3927,  1.3755,  ...,  1.1872,  1.0844,  1.0331]],\n",
            "\n",
            "        [[ 0.4328,  0.4328,  0.4853,  ..., -1.5805, -1.7031, -1.7556],\n",
            "         [ 0.4678,  0.4503,  0.4853,  ..., -1.6155, -1.7381, -1.7731],\n",
            "         [ 0.4328,  0.4328,  0.5028,  ..., -1.5630, -1.7031, -1.7556],\n",
            "         ...,\n",
            "         [ 0.2927,  0.2577,  0.2402,  ...,  0.2227,  0.0826,  0.0826],\n",
            "         [ 0.3102,  0.2577,  0.2577,  ...,  0.2227,  0.0826,  0.0826],\n",
            "         [ 0.3102,  0.2577,  0.2402,  ...,  0.2752,  0.1877,  0.1527]],\n",
            "\n",
            "        [[ 0.1476,  0.1476,  0.1825,  ..., -1.5256, -1.6127, -1.6476],\n",
            "         [ 0.1999,  0.1825,  0.2173,  ..., -1.5081, -1.6127, -1.6476],\n",
            "         [ 0.1825,  0.1825,  0.2696,  ..., -1.4559, -1.5953, -1.6476],\n",
            "         ...,\n",
            "         [-0.0092, -0.0267, -0.0092,  ...,  0.0256, -0.1138, -0.1138],\n",
            "         [ 0.0256, -0.0092,  0.0082,  ...,  0.0605, -0.0615, -0.0790],\n",
            "         [ 0.0779,  0.0256, -0.0092,  ...,  0.1476,  0.0605, -0.0092]]]), tensor(0))\n",
            "Successfully unpacked batch 65\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 65\n",
            "\n",
            "Batch 66 type: <class 'tuple'>\n",
            "Batch 66 content: (tensor([[[ 0.4679,  0.5022,  0.5536,  ...,  1.4783,  1.5125,  1.6153],\n",
            "         [ 0.5193,  0.5536,  0.6392,  ...,  1.4954,  1.5125,  1.4954],\n",
            "         [ 0.5536,  0.6049,  0.6734,  ...,  1.4783,  1.4612,  1.4440],\n",
            "         ...,\n",
            "         [ 1.3755,  1.3927,  1.4440,  ...,  1.9064,  2.0263,  2.0605],\n",
            "         [ 1.3927,  1.4098,  1.4612,  ...,  1.9578,  1.9920,  2.0092],\n",
            "         [ 1.3584,  1.3927,  1.4098,  ...,  1.9920,  1.9749,  1.9749]],\n",
            "\n",
            "        [[-0.3375, -0.3375, -0.3200,  ...,  0.4503,  0.5378,  0.6779],\n",
            "         [-0.2850, -0.2850, -0.2325,  ...,  0.4678,  0.5203,  0.5203],\n",
            "         [-0.2675, -0.2675, -0.2150,  ...,  0.4678,  0.4853,  0.4678],\n",
            "         ...,\n",
            "         [ 0.4328,  0.4328,  0.4328,  ...,  0.6779,  0.8354,  0.9055],\n",
            "         [ 0.4503,  0.4503,  0.4678,  ...,  0.7304,  0.8004,  0.8529],\n",
            "         [ 0.4503,  0.4503,  0.4678,  ...,  0.7304,  0.7654,  0.7829]],\n",
            "\n",
            "        [[-0.7064, -0.6890, -0.6541,  ...,  0.1825,  0.2696,  0.4265],\n",
            "         [-0.6541, -0.6367, -0.5670,  ...,  0.2348,  0.2871,  0.2871],\n",
            "         [-0.6541, -0.6193, -0.5321,  ...,  0.2522,  0.2173,  0.1999],\n",
            "         ...,\n",
            "         [-0.1138, -0.1138, -0.0790,  ...,  0.3045,  0.4788,  0.5659],\n",
            "         [-0.0964, -0.0790, -0.0615,  ...,  0.3393,  0.4091,  0.4788],\n",
            "         [-0.0790, -0.0441, -0.0267,  ...,  0.3742,  0.3742,  0.4091]]]), tensor(0))\n",
            "Successfully unpacked batch 66\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 66\n",
            "\n",
            "Batch 67 type: <class 'tuple'>\n",
            "Batch 67 content: (tensor([[[ 0.8104,  0.6563,  0.6221,  ..., -0.1314,  0.0227,  0.1768],\n",
            "         [ 0.7419,  0.6221,  0.6734,  ..., -0.3027, -0.1828, -0.0116],\n",
            "         [ 0.7248,  0.5536,  0.7248,  ..., -0.3712, -0.3027, -0.2513],\n",
            "         ...,\n",
            "         [ 1.0502,  1.0673,  1.0331,  ...,  1.0844,  1.1187,  1.0844],\n",
            "         [ 1.0331,  1.0331,  1.0331,  ...,  1.0844,  1.0673,  1.0673],\n",
            "         [ 1.0502,  1.0331,  1.0331,  ...,  1.0159,  1.0502,  1.0673]],\n",
            "\n",
            "        [[-0.0399, -0.2325, -0.3025,  ..., -0.9853, -0.8803, -0.7227],\n",
            "         [-0.0749, -0.2325, -0.1975,  ..., -1.0378, -0.9853, -0.8803],\n",
            "         [-0.1099, -0.2675, -0.0924,  ..., -1.1078, -1.0728, -1.0553],\n",
            "         ...,\n",
            "         [ 0.0301,  0.0301, -0.0399,  ...,  0.1702,  0.1877,  0.1527],\n",
            "         [ 0.0126,  0.0126, -0.0224,  ...,  0.1702,  0.1702,  0.1527],\n",
            "         [ 0.0126,  0.0126, -0.0049,  ...,  0.1001,  0.1352,  0.1702]],\n",
            "\n",
            "        [[-0.1661, -0.3404, -0.4450,  ..., -1.1596, -1.0376, -0.8981],\n",
            "         [-0.2532, -0.3753, -0.3230,  ..., -1.1770, -1.1944, -1.1073],\n",
            "         [-0.3404, -0.4798, -0.2358,  ..., -1.2119, -1.2293, -1.2467],\n",
            "         ...,\n",
            "         [-0.1661, -0.1835, -0.2358,  ..., -0.1661, -0.1312, -0.1312],\n",
            "         [-0.1312, -0.1487, -0.1661,  ..., -0.1312, -0.1138, -0.1138],\n",
            "         [-0.0964, -0.1138, -0.1312,  ..., -0.1661, -0.1312, -0.0964]]]), tensor(0))\n",
            "Successfully unpacked batch 67\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 67\n",
            "\n",
            "Batch 68 type: <class 'tuple'>\n",
            "Batch 68 content: (tensor([[[ 1.6838,  1.6495,  1.5468,  ...,  1.7694,  1.7523,  1.7694],\n",
            "         [ 1.5810,  1.4783,  1.4440,  ...,  1.8037,  1.7865,  1.8208],\n",
            "         [ 1.3584,  1.4783,  1.6153,  ...,  1.8208,  1.8208,  1.8208],\n",
            "         ...,\n",
            "         [ 1.9920,  1.9235,  1.8722,  ...,  2.0777,  2.1290,  2.1633],\n",
            "         [ 1.9235,  1.8722,  1.8550,  ...,  2.0263,  2.0948,  2.1633],\n",
            "         [ 1.8379,  1.8379,  1.8722,  ...,  2.0263,  2.1119,  2.1633]],\n",
            "\n",
            "        [[ 0.6254,  0.5728,  0.4678,  ...,  0.8004,  0.8004,  0.7829],\n",
            "         [ 0.4503,  0.3102,  0.3277,  ...,  0.7654,  0.7829,  0.8179],\n",
            "         [ 0.2402,  0.3102,  0.4853,  ...,  0.7479,  0.8004,  0.8179],\n",
            "         ...,\n",
            "         [ 0.8704,  0.8354,  0.8354,  ...,  0.8004,  0.8880,  0.9230],\n",
            "         [ 0.8354,  0.8004,  0.8354,  ...,  0.7654,  0.8529,  0.9580],\n",
            "         [ 0.7654,  0.7829,  0.8880,  ...,  0.7479,  0.8704,  0.9755]],\n",
            "\n",
            "        [[ 0.1651,  0.0431, -0.0790,  ...,  0.4614,  0.4265,  0.4265],\n",
            "         [-0.0092, -0.2010, -0.2532,  ...,  0.4091,  0.3916,  0.4265],\n",
            "         [-0.3230, -0.2184, -0.0964,  ...,  0.3742,  0.4265,  0.4614],\n",
            "         ...,\n",
            "         [ 0.1825,  0.1128,  0.0779,  ...,  0.0431,  0.2173,  0.3219],\n",
            "         [ 0.1302,  0.0605,  0.1128,  ...,  0.0082,  0.1476,  0.2871],\n",
            "         [ 0.0256,  0.0256,  0.1302,  ...,  0.0431,  0.1825,  0.3219]]]), tensor(0))\n",
            "Successfully unpacked batch 68\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 68\n",
            "\n",
            "Batch 69 type: <class 'tuple'>\n",
            "Batch 69 content: (tensor([[[-0.5424, -0.6452, -0.5082,  ..., -0.5424, -0.6281, -0.6965],\n",
            "         [-0.6965, -0.5596, -0.4911,  ..., -0.3883, -0.3712, -0.3198],\n",
            "         [-0.6281, -0.4397, -0.5082,  ..., -0.1999, -0.1999, -0.1999],\n",
            "         ...,\n",
            "         [ 0.9646,  0.9474,  0.9817,  ...,  1.1358,  1.1529,  1.1358],\n",
            "         [ 0.9474,  0.9474,  0.9474,  ...,  1.1700,  1.2043,  1.1700],\n",
            "         [ 0.9817,  0.9646,  0.9646,  ...,  1.1358,  1.1529,  1.1700]],\n",
            "\n",
            "        [[-1.0903, -1.1954, -0.9678,  ..., -0.9503, -1.0028, -1.0378],\n",
            "         [-1.1429, -1.0378, -0.9328,  ..., -0.8452, -0.7577, -0.6702],\n",
            "         [-1.0028, -0.8452, -0.9153,  ..., -0.5826, -0.6176, -0.6176],\n",
            "         ...,\n",
            "         [-0.0399, -0.0399, -0.0224,  ...,  0.2577,  0.2752,  0.2752],\n",
            "         [-0.0574, -0.0574, -0.0399,  ...,  0.3277,  0.3627,  0.3452],\n",
            "         [-0.0224, -0.0399, -0.0399,  ...,  0.3452,  0.3803,  0.3803]],\n",
            "\n",
            "        [[-0.9853, -1.0550, -0.8284,  ..., -0.7936, -0.8284, -0.8284],\n",
            "         [-1.0201, -0.8807, -0.7761,  ..., -0.7587, -0.5844, -0.4798],\n",
            "         [-0.8807, -0.6890, -0.7587,  ..., -0.5495, -0.4798, -0.4624],\n",
            "         ...,\n",
            "         [-0.2881, -0.3404, -0.3404,  ...,  0.1825,  0.1651,  0.1302],\n",
            "         [-0.2707, -0.2881, -0.3230,  ...,  0.2522,  0.2522,  0.1999],\n",
            "         [-0.2532, -0.2881, -0.2881,  ...,  0.2348,  0.2696,  0.2696]]]), tensor(0))\n",
            "Successfully unpacked batch 69\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 69\n",
            "\n",
            "Batch 70 type: <class 'tuple'>\n",
            "Batch 70 content: (tensor([[[ 1.1358,  1.1358,  1.1700,  ...,  1.4440,  1.4612,  1.4954],\n",
            "         [ 1.1700,  1.1529,  1.1529,  ...,  1.4612,  1.4954,  1.4954],\n",
            "         [ 1.1358,  1.1358,  1.1358,  ...,  1.4612,  1.4954,  1.4954],\n",
            "         ...,\n",
            "         [ 1.2728,  1.2728,  1.2214,  ...,  1.5125,  1.4783,  1.4269],\n",
            "         [ 1.3070,  1.3413,  1.2214,  ...,  1.4783,  1.4440,  1.4440],\n",
            "         [ 1.3070,  1.3242,  1.2214,  ...,  1.4098,  1.3755,  1.4098]],\n",
            "\n",
            "        [[ 0.7129,  0.7129,  0.6954,  ...,  0.7129,  0.7129,  0.7129],\n",
            "         [ 0.7129,  0.6954,  0.6604,  ...,  0.7129,  0.7129,  0.7129],\n",
            "         [ 0.7129,  0.6779,  0.6429,  ...,  0.6954,  0.6954,  0.7129],\n",
            "         ...,\n",
            "         [ 0.2402,  0.2577,  0.1702,  ...,  0.8179,  0.7479,  0.6604],\n",
            "         [ 0.2927,  0.3277,  0.1702,  ...,  0.7654,  0.7129,  0.6954],\n",
            "         [ 0.2927,  0.2927,  0.1702,  ...,  0.6954,  0.6954,  0.6954]],\n",
            "\n",
            "        [[ 0.6008,  0.6008,  0.6356,  ...,  0.6008,  0.6182,  0.5834],\n",
            "         [ 0.6008,  0.6008,  0.6008,  ...,  0.6008,  0.5834,  0.5311],\n",
            "         [ 0.5834,  0.5834,  0.5834,  ...,  0.5485,  0.5311,  0.5136],\n",
            "         ...,\n",
            "         [-0.3055, -0.2707, -0.3578,  ...,  0.6356,  0.5659,  0.4614],\n",
            "         [-0.3055, -0.2532, -0.3753,  ...,  0.5311,  0.5311,  0.5136],\n",
            "         [-0.3404, -0.3055, -0.4101,  ...,  0.3916,  0.4788,  0.4962]]]), tensor(0))\n",
            "Successfully unpacked batch 70\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 70\n",
            "\n",
            "Batch 71 type: <class 'tuple'>\n",
            "Batch 71 content: (tensor([[[-0.2513, -0.3541, -0.3027,  ...,  0.7419,  0.7419,  0.7591],\n",
            "         [ 0.0056, -0.1314, -0.1999,  ...,  0.6734,  0.7077,  0.7077],\n",
            "         [ 0.1939,  0.1597,  0.1426,  ...,  0.6221,  0.6734,  0.6734],\n",
            "         ...,\n",
            "         [ 0.0912,  0.1768,  0.1768,  ...,  1.4612,  1.9407,  1.6324],\n",
            "         [ 0.0912,  0.1426,  0.0398,  ...,  1.5297,  1.7009,  1.6324],\n",
            "         [ 0.0227, -0.0458, -0.0629,  ...,  1.5982,  1.6153,  1.6495]],\n",
            "\n",
            "        [[-0.5301, -0.6702, -0.6527,  ...,  0.2752,  0.2752,  0.2927],\n",
            "         [-0.3025, -0.4776, -0.5826,  ...,  0.2402,  0.2752,  0.2752],\n",
            "         [-0.1450, -0.2325, -0.2675,  ...,  0.2052,  0.2577,  0.2577],\n",
            "         ...,\n",
            "         [-0.2850, -0.2150, -0.2325,  ...,  1.1331,  1.6408,  1.3081],\n",
            "         [-0.2850, -0.2150, -0.2850,  ...,  1.1331,  1.2906,  1.2381],\n",
            "         [-0.3901, -0.4076, -0.3901,  ...,  1.2031,  1.1856,  1.2556]],\n",
            "\n",
            "        [[-0.4624, -0.5844, -0.5670,  ...,  0.2348,  0.1999,  0.2696],\n",
            "         [-0.3055, -0.4450, -0.5321,  ...,  0.1302,  0.1476,  0.1999],\n",
            "         [-0.2184, -0.2532, -0.3055,  ...,  0.0779,  0.0953,  0.1476],\n",
            "         ...,\n",
            "         [-0.0964,  0.0256,  0.0605,  ...,  1.0714,  1.5942,  1.2980],\n",
            "         [-0.0441,  0.0256, -0.0092,  ...,  1.0539,  1.2108,  1.2108],\n",
            "         [-0.1138, -0.1661, -0.1312,  ...,  1.1411,  1.1062,  1.1934]]]), tensor(1))\n",
            "Successfully unpacked batch 71\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 71\n",
            "\n",
            "Batch 72 type: <class 'tuple'>\n",
            "Batch 72 content: (tensor([[[1.3927, 1.3584, 1.3755,  ..., 1.4612, 1.3927, 1.4269],\n",
            "         [1.3242, 1.3413, 1.3755,  ..., 1.4783, 1.4612, 1.4954],\n",
            "         [1.3755, 1.4098, 1.4098,  ..., 1.4269, 1.4440, 1.4612],\n",
            "         ...,\n",
            "         [1.5297, 1.5297, 1.5810,  ..., 1.6324, 1.6153, 1.6153],\n",
            "         [1.5297, 1.5468, 1.5297,  ..., 1.6667, 1.5810, 1.6153],\n",
            "         [1.4783, 1.4783, 1.4612,  ..., 1.7009, 1.6324, 1.6324]],\n",
            "\n",
            "        [[0.5378, 0.5028, 0.5203,  ..., 0.6954, 0.6779, 0.7479],\n",
            "         [0.4678, 0.4678, 0.5028,  ..., 0.6779, 0.6954, 0.7479],\n",
            "         [0.4853, 0.5028, 0.5028,  ..., 0.6429, 0.6604, 0.6954],\n",
            "         ...,\n",
            "         [0.5903, 0.5728, 0.6254,  ..., 0.7654, 0.7304, 0.7129],\n",
            "         [0.6078, 0.6254, 0.6078,  ..., 0.8004, 0.7129, 0.6954],\n",
            "         [0.5903, 0.6078, 0.5903,  ..., 0.7829, 0.7129, 0.6779]],\n",
            "\n",
            "        [[0.5834, 0.5659, 0.6008,  ..., 0.7925, 0.7751, 0.8099],\n",
            "         [0.4962, 0.5311, 0.5834,  ..., 0.7925, 0.7751, 0.8274],\n",
            "         [0.4788, 0.5311, 0.5485,  ..., 0.7402, 0.7576, 0.7751],\n",
            "         ...,\n",
            "         [0.7925, 0.7751, 0.7751,  ..., 1.0017, 0.9842, 0.9668],\n",
            "         [0.7576, 0.7751, 0.7054,  ..., 1.0191, 0.9842, 0.9842],\n",
            "         [0.7751, 0.7925, 0.7402,  ..., 1.0017, 0.9842, 0.9668]]]), tensor(0))\n",
            "Successfully unpacked batch 72\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 72\n",
            "\n",
            "Batch 73 type: <class 'tuple'>\n",
            "Batch 73 content: (tensor([[[ 1.1529,  1.1872,  1.0673,  ...,  1.7352,  1.7352,  1.7352],\n",
            "         [ 1.1529,  1.1187,  0.9817,  ...,  1.6838,  1.6667,  1.6495],\n",
            "         [ 1.1015,  1.0159,  0.9817,  ...,  1.6495,  1.6495,  1.6324],\n",
            "         ...,\n",
            "         [ 2.1975,  2.2147,  2.1633,  ...,  1.9407,  1.9064,  1.9578],\n",
            "         [ 2.1804,  2.2147,  2.1633,  ...,  1.9235,  1.9749,  2.0434],\n",
            "         [ 2.1633,  2.1804,  2.1633,  ...,  1.9578,  1.9920,  2.0263]],\n",
            "\n",
            "        [[ 0.2927,  0.3102,  0.1527,  ...,  1.0805,  1.0455,  1.0105],\n",
            "         [ 0.2752,  0.2227,  0.0826,  ...,  1.0980,  1.0805,  1.0455],\n",
            "         [ 0.2052,  0.0826,  0.1001,  ...,  1.0805,  1.0805,  1.0630],\n",
            "         ...,\n",
            "         [ 1.2206,  1.2731,  1.2556,  ...,  1.3782,  1.3256,  1.3606],\n",
            "         [ 1.2031,  1.2731,  1.2556,  ...,  1.3431,  1.3606,  1.4132],\n",
            "         [ 1.2381,  1.2906,  1.2906,  ...,  1.3431,  1.3606,  1.4132]],\n",
            "\n",
            "        [[ 0.1999,  0.2173,  0.0082,  ...,  0.8971,  0.8622,  0.8448],\n",
            "         [ 0.1128,  0.0605, -0.1138,  ...,  0.8971,  0.8797,  0.8448],\n",
            "         [ 0.0256, -0.1138, -0.1661,  ...,  0.8971,  0.9145,  0.8971],\n",
            "         ...,\n",
            "         [ 1.1934,  1.2457,  1.2108,  ...,  1.1934,  1.1759,  1.2282],\n",
            "         [ 1.1759,  1.2282,  1.2108,  ...,  1.1585,  1.2108,  1.2980],\n",
            "         [ 1.1934,  1.2457,  1.2282,  ...,  1.1759,  1.2282,  1.2980]]]), tensor(0))\n",
            "Successfully unpacked batch 73\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 73\n",
            "\n",
            "Batch 74 type: <class 'tuple'>\n",
            "Batch 74 content: (tensor([[[ 1.4098,  1.3070,  0.6906,  ...,  1.7865,  1.7865,  1.8208],\n",
            "         [ 1.2557,  1.0673,  0.8447,  ...,  1.8379,  1.7865,  1.8379],\n",
            "         [ 1.1187,  0.8618,  0.9303,  ...,  1.9235,  1.9407,  1.7694],\n",
            "         ...,\n",
            "         [ 1.8893,  2.0092,  1.8379,  ...,  1.7009,  1.6838,  1.6667],\n",
            "         [ 1.9064,  1.8893,  1.8550,  ...,  1.6838,  1.5810,  1.4440],\n",
            "         [ 1.9235,  1.8379,  1.7865,  ...,  1.4269,  1.2385,  1.0673]],\n",
            "\n",
            "        [[ 0.4678,  0.3978, -0.3200,  ...,  0.9405,  0.9930,  1.1155],\n",
            "         [ 0.3102,  0.1352, -0.1450,  ...,  1.0105,  1.0105,  1.1155],\n",
            "         [ 0.1176, -0.1625, -0.1275,  ...,  1.0980,  1.1856,  1.0455],\n",
            "         ...,\n",
            "         [ 0.9930,  1.1681,  1.0105,  ...,  0.6954,  0.6954,  0.6954],\n",
            "         [ 0.9930,  1.0105,  1.0280,  ...,  0.7479,  0.6429,  0.5553],\n",
            "         [ 0.9930,  0.9230,  0.9230,  ...,  0.5728,  0.3978,  0.2227]],\n",
            "\n",
            "        [[ 0.3393,  0.2696, -0.3578,  ...,  0.8448,  0.9145,  1.0017],\n",
            "         [ 0.1476, -0.0267, -0.2881,  ...,  0.9494,  0.9668,  1.0714],\n",
            "         [-0.0441, -0.3230, -0.3055,  ...,  1.0365,  1.1411,  1.0191],\n",
            "         ...,\n",
            "         [ 0.9494,  1.1585,  1.0539,  ...,  0.5485,  0.5136,  0.4788],\n",
            "         [ 0.9668,  1.0539,  1.0888,  ...,  0.5485,  0.4265,  0.3045],\n",
            "         [ 1.0017,  0.9668,  0.9842,  ...,  0.3568,  0.1825,  0.0082]]]), tensor(3))\n",
            "Successfully unpacked batch 74\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 74\n",
            "\n",
            "Batch 75 type: <class 'tuple'>\n",
            "Batch 75 content: (tensor([[[1.2385, 1.2557, 1.3584,  ..., 1.5982, 1.5982, 1.6324],\n",
            "         [1.1872, 1.2214, 1.3242,  ..., 1.5810, 1.6324, 1.6495],\n",
            "         [1.1872, 1.2214, 1.3413,  ..., 1.6153, 1.6324, 1.6495],\n",
            "         ...,\n",
            "         [1.7865, 1.7694, 1.7694,  ..., 1.9578, 1.9920, 1.9920],\n",
            "         [1.7352, 1.7352, 1.7523,  ..., 1.9749, 2.0092, 2.0263],\n",
            "         [1.7009, 1.7009, 1.7352,  ..., 2.0092, 2.0434, 2.0434]],\n",
            "\n",
            "        [[0.5553, 0.5728, 0.6954,  ..., 0.6254, 0.6254, 0.6779],\n",
            "         [0.6078, 0.6254, 0.6779,  ..., 0.6429, 0.6604, 0.6779],\n",
            "         [0.5903, 0.6078, 0.6604,  ..., 0.6604, 0.6604, 0.6604],\n",
            "         ...,\n",
            "         [1.2381, 1.1681, 1.1155,  ..., 0.9405, 0.9405, 0.9230],\n",
            "         [1.2206, 1.1506, 1.0980,  ..., 0.9580, 0.9405, 0.9230],\n",
            "         [1.1681, 1.1155, 1.0980,  ..., 0.9930, 0.9755, 0.9405]],\n",
            "\n",
            "        [[0.4614, 0.4788, 0.5834,  ..., 0.5311, 0.5311, 0.6182],\n",
            "         [0.4265, 0.4439, 0.5136,  ..., 0.5659, 0.5659, 0.6008],\n",
            "         [0.3916, 0.4091, 0.4788,  ..., 0.6356, 0.6182, 0.6356],\n",
            "         ...,\n",
            "         [1.1411, 1.1062, 1.1062,  ..., 0.8622, 0.8622, 0.8622],\n",
            "         [1.1237, 1.0888, 1.0714,  ..., 0.8797, 0.8797, 0.8797],\n",
            "         [1.0365, 1.0191, 1.0191,  ..., 0.9145, 0.8971, 0.8274]]]), tensor(0))\n",
            "Successfully unpacked batch 75\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 75\n",
            "\n",
            "Batch 76 type: <class 'tuple'>\n",
            "Batch 76 content: (tensor([[[-0.6109, -0.5596, -0.4911,  ..., -0.5082, -0.3369, -0.1657],\n",
            "         [-0.3883, -0.4397, -0.4739,  ..., -0.4568, -0.4226, -0.2684],\n",
            "         [-0.1999, -0.3541, -0.4739,  ..., -0.3541, -0.4226, -0.4568],\n",
            "         ...,\n",
            "         [ 0.1254,  0.1768,  0.2282,  ..., -0.5082, -0.5596, -0.6109],\n",
            "         [ 0.0912,  0.0912,  0.0912,  ..., -0.4911, -0.5424, -0.5424],\n",
            "         [ 0.1426,  0.1254,  0.0741,  ..., -0.4226, -0.5082, -0.4397]],\n",
            "\n",
            "        [[-0.9153, -0.9153, -0.9153,  ..., -0.8277, -0.6877, -0.5826],\n",
            "         [-0.7752, -0.8277, -0.8978,  ..., -0.8102, -0.7752, -0.6702],\n",
            "         [-0.6877, -0.8452, -0.9328,  ..., -0.7577, -0.8102, -0.8277],\n",
            "         ...,\n",
            "         [-0.3725, -0.3375, -0.3375,  ..., -1.0203, -1.0203, -1.0553],\n",
            "         [-0.3901, -0.4251, -0.4251,  ..., -1.0203, -1.0028, -1.0378],\n",
            "         [-0.4426, -0.4601, -0.4951,  ..., -0.9503, -1.0028, -1.0028]],\n",
            "\n",
            "        [[-1.0550, -1.0724, -1.0724,  ..., -0.8981, -0.7587, -0.6193],\n",
            "         [-0.9156, -0.9853, -1.0376,  ..., -0.8458, -0.7936, -0.6890],\n",
            "         [-0.7587, -0.9504, -1.0550,  ..., -0.7413, -0.7761, -0.8284],\n",
            "         ...,\n",
            "         [-0.6193, -0.5495, -0.5147,  ..., -1.1073, -1.1421, -1.1596],\n",
            "         [-0.6541, -0.6541, -0.6541,  ..., -1.1073, -1.0898, -1.0898],\n",
            "         [-0.6367, -0.6541, -0.6890,  ..., -1.0724, -1.1073, -1.0724]]]), tensor(0))\n",
            "Successfully unpacked batch 76\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 76\n",
            "\n",
            "Batch 77 type: <class 'tuple'>\n",
            "Batch 77 content: (tensor([[[ 1.6495,  1.6838,  1.6324,  ..., -0.5082, -0.3369, -0.3027],\n",
            "         [ 1.5810,  1.6667,  1.5125,  ..., -0.4054, -0.3198, -0.2856],\n",
            "         [ 1.5468,  1.5982,  1.5125,  ..., -0.3883, -0.3712, -0.3541],\n",
            "         ...,\n",
            "         [ 1.8722,  1.8550,  1.8208,  ...,  1.1529,  1.1529,  1.1529],\n",
            "         [ 1.8893,  1.8550,  1.7865,  ...,  1.1700,  1.1872,  1.1700],\n",
            "         [ 1.8893,  1.8722,  1.8037,  ...,  1.1529,  1.1700,  1.1700]],\n",
            "\n",
            "        [[ 0.9930,  0.9755,  0.9230,  ..., -0.6702, -0.5301, -0.5476],\n",
            "         [ 0.8880,  0.9405,  0.8004,  ..., -0.6176, -0.5651, -0.5651],\n",
            "         [ 0.9230,  0.9580,  0.8704,  ..., -0.6001, -0.6001, -0.5826],\n",
            "         ...,\n",
            "         [ 0.6779,  0.6954,  0.7304,  ...,  1.0805,  1.1155,  1.1331],\n",
            "         [ 0.7129,  0.7129,  0.7129,  ...,  1.0980,  1.1331,  1.0980],\n",
            "         [ 0.7304,  0.7304,  0.6954,  ...,  1.0805,  1.0980,  1.0980]],\n",
            "\n",
            "        [[ 1.1062,  1.1062,  1.0191,  ..., -0.7064, -0.5844, -0.5844],\n",
            "         [ 1.0191,  1.0714,  0.9145,  ..., -0.6541, -0.6367, -0.6193],\n",
            "         [ 1.0539,  1.0888,  1.0017,  ..., -0.6367, -0.6541, -0.6541],\n",
            "         ...,\n",
            "         [ 0.6356,  0.6705,  0.6705,  ...,  1.0191,  1.0365,  1.0539],\n",
            "         [ 0.7402,  0.7402,  0.7054,  ...,  1.0191,  1.0714,  1.0539],\n",
            "         [ 0.7751,  0.7576,  0.7054,  ...,  1.0191,  1.0365,  1.0365]]]), tensor(0))\n",
            "Successfully unpacked batch 77\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 77\n",
            "\n",
            "Batch 78 type: <class 'tuple'>\n",
            "Batch 78 content: (tensor([[[-0.1999, -0.1828, -0.1657,  ...,  0.3481,  0.3652,  0.3481],\n",
            "         [-0.1999, -0.1828, -0.1143,  ...,  0.3138,  0.2967,  0.2967],\n",
            "         [-0.1486, -0.1314, -0.0629,  ...,  0.2796,  0.2453,  0.2453],\n",
            "         ...,\n",
            "         [-0.4226, -0.4226, -0.4739,  ...,  0.7933,  0.8104,  0.7933],\n",
            "         [-0.4226, -0.4226, -0.4739,  ...,  0.8276,  0.8447,  0.8104],\n",
            "         [-0.3541, -0.3712, -0.4226,  ...,  0.8276,  0.8104,  0.8276]],\n",
            "\n",
            "        [[-0.5651, -0.5126, -0.4601,  ..., -0.4951, -0.4601, -0.4601],\n",
            "         [-0.5826, -0.5476, -0.4776,  ..., -0.5301, -0.5301, -0.5301],\n",
            "         [-0.5476, -0.5126, -0.4951,  ..., -0.6176, -0.6176, -0.5826],\n",
            "         ...,\n",
            "         [-1.0378, -1.0553, -1.0028,  ...,  0.1176,  0.1877,  0.1702],\n",
            "         [-1.0203, -1.0378, -1.0203,  ...,  0.1527,  0.2052,  0.1702],\n",
            "         [-1.0203, -1.0553, -1.0378,  ...,  0.1352,  0.1176,  0.1352]],\n",
            "\n",
            "        [[-0.5495, -0.5147, -0.4973,  ..., -0.7587, -0.7064, -0.6890],\n",
            "         [-0.5495, -0.4973, -0.4101,  ..., -0.8284, -0.8458, -0.8284],\n",
            "         [-0.5147, -0.4450, -0.3578,  ..., -0.9330, -0.9678, -0.9156],\n",
            "         ...,\n",
            "         [-1.0027, -1.0376, -1.0724,  ..., -0.2881, -0.2184, -0.2184],\n",
            "         [-1.0376, -1.0898, -1.1421,  ..., -0.2532, -0.1835, -0.2010],\n",
            "         [-1.0550, -1.1073, -1.1770,  ..., -0.2881, -0.2707, -0.2184]]]), tensor(0))\n",
            "Successfully unpacked batch 78\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 78\n",
            "\n",
            "Batch 79 type: <class 'tuple'>\n",
            "Batch 79 content: (tensor([[[ 0.8276,  0.8618,  0.8618,  ...,  0.5878,  0.5878,  0.5536],\n",
            "         [ 0.8447,  0.8961,  0.9303,  ...,  0.6221,  0.5536,  0.5536],\n",
            "         [ 0.8618,  0.9132,  0.9132,  ...,  0.6221,  0.5878,  0.6049],\n",
            "         ...,\n",
            "         [ 1.3584,  1.3070,  1.2214,  ...,  1.4440,  1.3927,  1.3584],\n",
            "         [ 1.3242,  1.2899,  1.2728,  ...,  1.4612,  1.4783,  1.3927],\n",
            "         [ 1.3242,  1.3413,  1.3413,  ...,  1.4098,  1.4098,  1.3584]],\n",
            "\n",
            "        [[-0.1800, -0.1275, -0.1275,  ..., -0.0224,  0.0126, -0.0399],\n",
            "         [-0.2150, -0.1800, -0.1099,  ...,  0.0476,  0.0301, -0.0049],\n",
            "         [-0.2850, -0.2150, -0.1625,  ...,  0.0301,  0.0651,  0.0126],\n",
            "         ...,\n",
            "         [ 0.4678,  0.4678,  0.4153,  ...,  0.5553,  0.4503,  0.3978],\n",
            "         [ 0.5028,  0.5203,  0.5203,  ...,  0.5378,  0.4853,  0.3978],\n",
            "         [ 0.5203,  0.5203,  0.5553,  ...,  0.5728,  0.5203,  0.4503]],\n",
            "\n",
            "        [[-0.3927, -0.3404, -0.3404,  ...,  0.0431,  0.0431, -0.0615],\n",
            "         [-0.3927, -0.3230, -0.2707,  ...,  0.0256, -0.0092, -0.0441],\n",
            "         [-0.4450, -0.3230, -0.2358,  ..., -0.0790, -0.0441, -0.0441],\n",
            "         ...,\n",
            "         [ 0.3916,  0.3393,  0.2696,  ...,  0.4962,  0.4265,  0.4091],\n",
            "         [ 0.3742,  0.3219,  0.3393,  ...,  0.4614,  0.4614,  0.4265],\n",
            "         [ 0.3742,  0.3742,  0.3916,  ...,  0.4614,  0.4788,  0.4614]]]), tensor(0))\n",
            "Successfully unpacked batch 79\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 79\n",
            "\n",
            "Batch 80 type: <class 'tuple'>\n",
            "Batch 80 content: (tensor([[[-0.3198, -0.3027, -0.1828,  ...,  1.4440,  1.4440,  1.4269],\n",
            "         [-0.3027, -0.2342, -0.1143,  ...,  1.5125,  1.5297,  1.4612],\n",
            "         [-0.2856, -0.1999, -0.0629,  ...,  1.5125,  1.6153,  1.4954],\n",
            "         ...,\n",
            "         [ 0.5878,  0.6906,  0.7248,  ...,  1.4954,  1.4440,  1.4783],\n",
            "         [ 0.6221,  0.6392,  0.7248,  ...,  1.4783,  1.4612,  1.5468],\n",
            "         [ 0.6392,  0.6221,  0.6906,  ...,  1.5297,  1.5125,  1.5810]],\n",
            "\n",
            "        [[-1.0378, -1.0378, -0.9503,  ...,  0.2402,  0.3627,  0.3978],\n",
            "         [-1.0728, -1.0028, -0.9328,  ...,  0.3627,  0.4853,  0.4678],\n",
            "         [-1.0728, -0.9853, -0.8978,  ...,  0.3978,  0.5903,  0.5028],\n",
            "         ...,\n",
            "         [-0.4951, -0.3901, -0.3200,  ...,  0.0826,  0.0301,  0.0651],\n",
            "         [-0.4076, -0.3550, -0.2850,  ...,  0.0826,  0.1352,  0.2402],\n",
            "         [-0.3725, -0.3200, -0.2850,  ...,  0.2402,  0.2227,  0.3102]],\n",
            "\n",
            "        [[-1.2467, -1.2816, -1.2641,  ..., -0.2707, -0.1835, -0.1487],\n",
            "         [-1.2641, -1.2816, -1.2467,  ..., -0.1312, -0.0441, -0.0790],\n",
            "         [-1.2990, -1.2816, -1.2467,  ..., -0.0267,  0.1825,  0.0605],\n",
            "         ...,\n",
            "         [-1.0376, -0.9504, -0.9330,  ..., -0.5321, -0.5670, -0.5321],\n",
            "         [-1.0201, -1.0027, -0.9678,  ..., -0.4798, -0.4450, -0.3578],\n",
            "         [-0.9504, -0.9678, -0.9678,  ..., -0.3927, -0.3753, -0.3230]]]), tensor(0))\n",
            "Successfully unpacked batch 80\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 80\n",
            "\n",
            "Batch 81 type: <class 'tuple'>\n",
            "Batch 81 content: (tensor([[[-0.2513, -0.2342, -0.1657,  ...,  1.5810,  1.5810,  1.6153],\n",
            "         [-0.2342, -0.1999, -0.1486,  ...,  1.5810,  1.5639,  1.6153],\n",
            "         [-0.0801, -0.0458, -0.0629,  ...,  1.6153,  1.5810,  1.5982],\n",
            "         ...,\n",
            "         [ 1.5297,  1.4954,  1.4783,  ...,  1.6495,  1.6495,  1.6495],\n",
            "         [ 1.4269,  1.4612,  1.4954,  ...,  1.6153,  1.6324,  1.6324],\n",
            "         [ 1.4954,  1.5125,  1.5297,  ...,  1.6153,  1.6324,  1.6495]],\n",
            "\n",
            "        [[-1.0378, -1.0553, -1.0028,  ...,  0.8704,  0.8529,  0.8704],\n",
            "         [-0.9853, -0.9678, -0.9328,  ...,  0.8704,  0.8354,  0.8529],\n",
            "         [-0.9328, -0.8803, -0.8978,  ...,  0.9055,  0.8354,  0.8179],\n",
            "         ...,\n",
            "         [ 0.6429,  0.6078,  0.5728,  ...,  0.4153,  0.3803,  0.3452],\n",
            "         [ 0.5728,  0.6078,  0.5903,  ...,  0.3978,  0.3803,  0.3277],\n",
            "         [ 0.6254,  0.6254,  0.6429,  ...,  0.3978,  0.3627,  0.3102]],\n",
            "\n",
            "        [[-1.1770, -1.1770, -1.0898,  ...,  1.0191,  1.0191,  1.0191],\n",
            "         [-1.1421, -1.1247, -1.0898,  ...,  1.0365,  1.0191,  1.0191],\n",
            "         [-1.0724, -1.0550, -1.0724,  ...,  1.0888,  1.0539,  1.0191],\n",
            "         ...,\n",
            "         [ 0.3393,  0.3393,  0.3045,  ...,  0.0431, -0.0267, -0.0790],\n",
            "         [ 0.3219,  0.3742,  0.3742,  ...,  0.0082, -0.0441, -0.0964],\n",
            "         [ 0.3742,  0.4091,  0.4614,  ..., -0.0441, -0.0790, -0.0964]]]), tensor(0))\n",
            "Successfully unpacked batch 81\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 81\n",
            "\n",
            "Batch 82 type: <class 'tuple'>\n",
            "Batch 82 content: (tensor([[[ 1.1187,  1.1015,  1.0673,  ...,  1.6153,  1.6324,  1.6324],\n",
            "         [ 1.0673,  1.1015,  1.0673,  ...,  1.6495,  1.6667,  1.6495],\n",
            "         [ 1.0844,  1.0673,  1.0502,  ...,  1.6495,  1.6667,  1.6667],\n",
            "         ...,\n",
            "         [-0.8335, -0.7822, -0.7308,  ...,  1.1700,  1.3413,  1.3927],\n",
            "         [-0.6794, -0.6794, -0.6965,  ...,  1.2385,  1.3584,  1.4783],\n",
            "         [-0.3883, -0.4911, -0.5938,  ...,  1.3584,  1.3927,  1.4954]],\n",
            "\n",
            "        [[ 0.2927,  0.2752,  0.2577,  ...,  0.7479,  0.7304,  0.7129],\n",
            "         [ 0.2577,  0.3102,  0.2752,  ...,  0.7479,  0.7129,  0.7129],\n",
            "         [ 0.3277,  0.3452,  0.3277,  ...,  0.7829,  0.7304,  0.7304],\n",
            "         ...,\n",
            "         [-1.5280, -1.4930, -1.4930,  ...,  0.3102,  0.3978,  0.4853],\n",
            "         [-1.4930, -1.5105, -1.5280,  ...,  0.3277,  0.3803,  0.5378],\n",
            "         [-1.4230, -1.4930, -1.5630,  ...,  0.3803,  0.4503,  0.5728]],\n",
            "\n",
            "        [[ 0.2348,  0.2522,  0.2173,  ...,  0.4265,  0.4265,  0.4091],\n",
            "         [ 0.2348,  0.2871,  0.2522,  ...,  0.4439,  0.4265,  0.4265],\n",
            "         [ 0.3045,  0.3219,  0.2871,  ...,  0.4962,  0.4788,  0.4788],\n",
            "         ...,\n",
            "         [-1.3861, -1.3861, -1.3513,  ..., -0.0092,  0.0082,  0.0953],\n",
            "         [-1.3861, -1.4036, -1.3861,  ..., -0.0790, -0.0267,  0.1128],\n",
            "         [-1.3164, -1.3861, -1.4384,  ..., -0.0441, -0.0092,  0.1476]]]), tensor(0))\n",
            "Successfully unpacked batch 82\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 82\n",
            "\n",
            "Batch 83 type: <class 'tuple'>\n",
            "Batch 83 content: (tensor([[[1.4783, 1.4954, 1.5639,  ..., 1.1700, 1.2043, 1.1529],\n",
            "         [1.5468, 1.5297, 1.5468,  ..., 1.2043, 1.1529, 1.1529],\n",
            "         [1.5297, 1.5468, 1.5810,  ..., 1.2043, 1.1700, 1.1529],\n",
            "         ...,\n",
            "         [1.6153, 1.6153, 1.5982,  ..., 1.2557, 1.2043, 1.1700],\n",
            "         [1.6153, 1.5810, 1.5982,  ..., 1.2043, 1.1358, 1.0673],\n",
            "         [1.5982, 1.5810, 1.5982,  ..., 1.2043, 1.0844, 0.9817]],\n",
            "\n",
            "        [[0.9580, 0.9230, 0.9230,  ..., 0.7304, 0.7654, 0.7129],\n",
            "         [0.9580, 0.8880, 0.8704,  ..., 0.7479, 0.7129, 0.6954],\n",
            "         [0.8354, 0.8354, 0.8529,  ..., 0.7304, 0.7304, 0.6954],\n",
            "         ...,\n",
            "         [0.6954, 0.6954, 0.6429,  ..., 0.8004, 0.7129, 0.6429],\n",
            "         [0.6954, 0.6429, 0.6078,  ..., 0.7654, 0.6954, 0.6429],\n",
            "         [0.7129, 0.6779, 0.6078,  ..., 0.8004, 0.6779, 0.6078]],\n",
            "\n",
            "        [[0.9494, 0.9145, 0.9145,  ..., 0.4962, 0.5311, 0.4614],\n",
            "         [0.9145, 0.8622, 0.8274,  ..., 0.5659, 0.5311, 0.5136],\n",
            "         [0.7751, 0.7751, 0.8274,  ..., 0.5485, 0.5311, 0.5311],\n",
            "         ...,\n",
            "         [0.7054, 0.6705, 0.6008,  ..., 0.5659, 0.4788, 0.4091],\n",
            "         [0.6705, 0.6008, 0.5485,  ..., 0.5659, 0.4788, 0.4091],\n",
            "         [0.6531, 0.5834, 0.5311,  ..., 0.6182, 0.4614, 0.3393]]]), tensor(1))\n",
            "Successfully unpacked batch 83\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 83\n",
            "\n",
            "Batch 84 type: <class 'tuple'>\n",
            "Batch 84 content: (tensor([[[0.6049, 0.8276, 0.9988,  ..., 0.8618, 0.6049, 0.5536],\n",
            "         [0.6392, 0.8961, 1.0331,  ..., 0.7077, 0.8789, 1.0673],\n",
            "         [0.7591, 0.9303, 0.9988,  ..., 1.1358, 1.2214, 1.1015],\n",
            "         ...,\n",
            "         [1.6495, 1.6667, 1.4954,  ..., 1.5297, 1.5468, 1.5468],\n",
            "         [1.6324, 1.6495, 1.5125,  ..., 1.5297, 1.5810, 1.5810],\n",
            "         [1.5982, 1.6324, 1.5639,  ..., 1.5125, 1.6153, 1.5982]],\n",
            "\n",
            "        [[0.2402, 0.4678, 0.6078,  ..., 0.7479, 0.5203, 0.4503],\n",
            "         [0.2927, 0.5553, 0.6604,  ..., 0.5553, 0.7129, 0.9055],\n",
            "         [0.4503, 0.6078, 0.6429,  ..., 0.8880, 0.9930, 0.9230],\n",
            "         ...,\n",
            "         [1.2031, 1.2206, 1.0455,  ..., 0.8704, 0.8880, 0.9055],\n",
            "         [1.2031, 1.2381, 1.0805,  ..., 0.8179, 0.8529, 0.8880],\n",
            "         [1.1506, 1.1681, 1.1155,  ..., 0.8004, 0.8529, 0.8529]],\n",
            "\n",
            "        [[0.1476, 0.4091, 0.5311,  ..., 0.8971, 0.7228, 0.6356],\n",
            "         [0.2173, 0.4962, 0.6008,  ..., 0.7228, 0.9145, 1.0714],\n",
            "         [0.4091, 0.5834, 0.5834,  ..., 1.1062, 1.1934, 1.0888],\n",
            "         ...,\n",
            "         [1.1759, 1.2282, 1.0888,  ..., 0.8971, 0.9319, 0.9319],\n",
            "         [1.1062, 1.1585, 1.0714,  ..., 0.8797, 0.9319, 0.9319],\n",
            "         [1.0714, 1.0888, 1.0539,  ..., 0.8274, 0.9145, 0.8971]]]), tensor(1))\n",
            "Successfully unpacked batch 84\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 84\n",
            "\n",
            "Batch 85 type: <class 'tuple'>\n",
            "Batch 85 content: (tensor([[[ 0.3309,  0.3481,  0.2796,  ..., -0.8507, -0.7650, -0.6794],\n",
            "         [ 0.2624,  0.2111,  0.0912,  ..., -0.5424, -0.3883, -0.2856],\n",
            "         [ 0.0912,  0.0227,  0.0227,  ..., -0.2856, -0.1657, -0.1143],\n",
            "         ...,\n",
            "         [ 0.7077,  0.6392,  0.5364,  ...,  1.8037,  1.7523,  1.7009],\n",
            "         [ 0.6734,  0.8104,  0.8447,  ...,  1.9578,  1.9407,  1.8722],\n",
            "         [ 0.6906,  0.7762,  0.8104,  ...,  1.9064,  1.8722,  1.7865]],\n",
            "\n",
            "        [[-0.2150, -0.1975, -0.1450,  ..., -0.8803, -0.8277, -0.7577],\n",
            "         [-0.1800, -0.2325, -0.2675,  ..., -0.4601, -0.3025, -0.1975],\n",
            "         [-0.2150, -0.2675, -0.2675,  ..., -0.0749,  0.0651,  0.1352],\n",
            "         ...,\n",
            "         [ 0.3627,  0.3627,  0.2927,  ...,  1.6057,  1.5532,  1.4832],\n",
            "         [ 0.4328,  0.6604,  0.7654,  ...,  1.7808,  1.7808,  1.6933],\n",
            "         [ 0.4853,  0.6078,  0.7129,  ...,  1.7108,  1.6933,  1.6232]],\n",
            "\n",
            "        [[-0.0790, -0.0092,  0.0256,  ..., -0.7413, -0.6541, -0.5844],\n",
            "         [-0.0964, -0.1138, -0.1138,  ..., -0.3230, -0.1487, -0.0267],\n",
            "         [-0.0790, -0.1138, -0.0790,  ...,  0.0953,  0.2348,  0.3045],\n",
            "         ...,\n",
            "         [ 0.7576,  0.7228,  0.6356,  ...,  1.7860,  1.7163,  1.6465],\n",
            "         [ 0.7751,  0.9842,  1.0191,  ...,  1.9603,  1.9428,  1.8383],\n",
            "         [ 0.8448,  0.9494,  1.0191,  ...,  1.8557,  1.8731,  1.8034]]]), tensor(0))\n",
            "Successfully unpacked batch 85\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 85\n",
            "\n",
            "Batch 86 type: <class 'tuple'>\n",
            "Batch 86 content: (tensor([[[-0.1143, -0.0287, -0.1143,  ...,  1.2385,  1.2728,  1.3242],\n",
            "         [-0.1486, -0.0458, -0.0801,  ...,  1.2214,  1.2728,  1.2899],\n",
            "         [-0.0972, -0.0458, -0.0629,  ...,  1.2385,  1.2214,  1.2385],\n",
            "         ...,\n",
            "         [ 0.2282,  0.1768,  0.1768,  ...,  1.3927,  1.3584,  1.3584],\n",
            "         [ 0.2282,  0.2624,  0.2282,  ...,  1.3927,  1.3584,  1.3584],\n",
            "         [ 0.3138,  0.3309,  0.3309,  ...,  1.3584,  1.3584,  1.3755]],\n",
            "\n",
            "        [[-0.4601, -0.4076, -0.4251,  ...,  0.9930,  1.0630,  1.0630],\n",
            "         [-0.5301, -0.4426, -0.4601,  ...,  0.9755,  1.0630,  1.0630],\n",
            "         [-0.4951, -0.4426, -0.4776,  ...,  0.9580,  0.9755,  0.9580],\n",
            "         ...,\n",
            "         [-0.1975, -0.2850, -0.3025,  ...,  1.1856,  1.0805,  1.0805],\n",
            "         [-0.3025, -0.3200, -0.3375,  ...,  1.1681,  1.0980,  1.0980],\n",
            "         [-0.3200, -0.3375, -0.3025,  ...,  1.1506,  1.1155,  1.1155]],\n",
            "\n",
            "        [[-0.2532, -0.2010, -0.2532,  ...,  1.1237,  1.2108,  1.2108],\n",
            "         [-0.2881, -0.2010, -0.2358,  ...,  1.1411,  1.2282,  1.2108],\n",
            "         [-0.2184, -0.1835, -0.2184,  ...,  1.1585,  1.1585,  1.1062],\n",
            "         ...,\n",
            "         [ 0.0082, -0.0790, -0.1138,  ...,  1.3328,  1.2108,  1.1934],\n",
            "         [-0.0267, -0.0790, -0.1138,  ...,  1.2457,  1.1411,  1.1411],\n",
            "         [ 0.0256, -0.0267, -0.0441,  ...,  1.1759,  1.1062,  1.1237]]]), tensor(1))\n",
            "Successfully unpacked batch 86\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 86\n",
            "\n",
            "Batch 87 type: <class 'tuple'>\n",
            "Batch 87 content: (tensor([[[1.4440, 1.3755, 1.4098,  ..., 1.1187, 1.1015, 1.1529],\n",
            "         [1.4440, 1.3584, 1.4098,  ..., 1.1187, 1.1187, 1.1187],\n",
            "         [1.4269, 1.4098, 1.4440,  ..., 1.1187, 1.1187, 1.1187],\n",
            "         ...,\n",
            "         [1.5810, 1.5639, 1.5125,  ..., 1.4612, 1.4612, 1.4954],\n",
            "         [1.5468, 1.5810, 1.5810,  ..., 1.4612, 1.4440, 1.4612],\n",
            "         [1.5810, 1.5468, 1.5810,  ..., 1.4612, 1.4440, 1.4612]],\n",
            "\n",
            "        [[0.6604, 0.6078, 0.6779,  ..., 0.5553, 0.4678, 0.4853],\n",
            "         [0.6779, 0.6254, 0.6954,  ..., 0.5028, 0.4853, 0.4678],\n",
            "         [0.6604, 0.6954, 0.7479,  ..., 0.4853, 0.5203, 0.5028],\n",
            "         ...,\n",
            "         [0.8179, 0.7829, 0.7654,  ..., 0.8179, 0.7829, 0.8179],\n",
            "         [0.8179, 0.8004, 0.7654,  ..., 0.8354, 0.7829, 0.8179],\n",
            "         [0.8179, 0.7654, 0.7479,  ..., 0.8529, 0.8179, 0.8179]],\n",
            "\n",
            "        [[0.8797, 0.8099, 0.8448,  ..., 0.4788, 0.4091, 0.4788],\n",
            "         [0.8971, 0.7925, 0.8274,  ..., 0.4091, 0.3916, 0.4091],\n",
            "         [0.9319, 0.9145, 0.8797,  ..., 0.4265, 0.4091, 0.4091],\n",
            "         ...,\n",
            "         [0.8971, 0.8622, 0.8274,  ..., 0.9145, 0.8448, 0.8797],\n",
            "         [0.8448, 0.8274, 0.8274,  ..., 0.9319, 0.8622, 0.8797],\n",
            "         [0.8622, 0.8099, 0.8099,  ..., 0.9145, 0.8971, 0.8971]]]), tensor(0))\n",
            "Successfully unpacked batch 87\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 87\n",
            "\n",
            "Batch 88 type: <class 'tuple'>\n",
            "Batch 88 content: (tensor([[[1.3070, 1.3413, 1.2899,  ..., 1.9235, 1.8893, 1.8722],\n",
            "         [1.3584, 1.3413, 1.2899,  ..., 1.9749, 1.9407, 1.9407],\n",
            "         [1.4269, 1.3927, 1.3584,  ..., 2.0092, 1.9920, 2.0434],\n",
            "         ...,\n",
            "         [2.0263, 2.0605, 2.0434,  ..., 2.1290, 2.1290, 2.1119],\n",
            "         [2.0092, 2.0605, 2.0263,  ..., 2.1290, 2.1290, 2.1290],\n",
            "         [2.0263, 2.0777, 2.0434,  ..., 2.0092, 2.0434, 2.0948]],\n",
            "\n",
            "        [[0.4328, 0.4853, 0.4328,  ..., 1.4482, 1.4482, 1.4482],\n",
            "         [0.4678, 0.4328, 0.3978,  ..., 1.4657, 1.4657, 1.4832],\n",
            "         [0.4328, 0.3978, 0.3978,  ..., 1.4307, 1.4132, 1.5007],\n",
            "         ...,\n",
            "         [0.9055, 0.9405, 0.9755,  ..., 1.5357, 1.5357, 1.5357],\n",
            "         [0.9230, 0.9755, 0.9755,  ..., 1.5532, 1.5532, 1.5532],\n",
            "         [0.9405, 0.9930, 0.9580,  ..., 1.5357, 1.5532, 1.6057]],\n",
            "\n",
            "        [[0.2348, 0.2696, 0.1825,  ..., 1.2631, 1.2805, 1.3154],\n",
            "         [0.2696, 0.2522, 0.1999,  ..., 1.3328, 1.3502, 1.3677],\n",
            "         [0.2522, 0.2522, 0.2348,  ..., 1.2980, 1.3154, 1.4025],\n",
            "         ...,\n",
            "         [0.6879, 0.7402, 0.7751,  ..., 1.5245, 1.5420, 1.5420],\n",
            "         [0.7054, 0.7576, 0.7576,  ..., 1.5245, 1.5245, 1.5594],\n",
            "         [0.7228, 0.7751, 0.7751,  ..., 1.4374, 1.4722, 1.5420]]]), tensor(0))\n",
            "Successfully unpacked batch 88\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 88\n",
            "\n",
            "Batch 89 type: <class 'tuple'>\n",
            "Batch 89 content: (tensor([[[1.3755, 1.3755, 1.4269,  ..., 0.9646, 0.8789, 1.2214],\n",
            "         [1.3584, 1.3755, 1.3755,  ..., 1.0844, 0.7591, 0.7077],\n",
            "         [1.3927, 1.3927, 1.3927,  ..., 0.8618, 1.1529, 0.9303],\n",
            "         ...,\n",
            "         [2.2318, 2.2489, 2.2489,  ..., 2.1804, 2.2318, 2.2489],\n",
            "         [2.1633, 2.1804, 2.2147,  ..., 2.2147, 2.2147, 2.2318],\n",
            "         [2.2147, 2.2147, 2.2318,  ..., 2.2147, 2.2147, 2.1804]],\n",
            "\n",
            "        [[0.6779, 0.6779, 0.7304,  ..., 0.2577, 0.1352, 0.4853],\n",
            "         [0.6254, 0.6429, 0.6779,  ..., 0.3978, 0.1176, 0.0476],\n",
            "         [0.6254, 0.6254, 0.6429,  ..., 0.1176, 0.5378, 0.3978],\n",
            "         ...,\n",
            "         [1.5182, 1.5357, 1.6057,  ..., 1.4657, 1.5182, 1.5532],\n",
            "         [1.4132, 1.4832, 1.5357,  ..., 1.4657, 1.4832, 1.5357],\n",
            "         [1.5182, 1.5357, 1.5707,  ..., 1.4657, 1.4832, 1.4832]],\n",
            "\n",
            "        [[0.6531, 0.6531, 0.7054,  ..., 0.1825, 0.0779, 0.4614],\n",
            "         [0.6182, 0.6182, 0.6705,  ..., 0.3568, 0.1128, 0.0605],\n",
            "         [0.6008, 0.6008, 0.6531,  ..., 0.1825, 0.5834, 0.4091],\n",
            "         ...,\n",
            "         [1.4548, 1.4897, 1.5942,  ..., 1.3328, 1.3677, 1.4374],\n",
            "         [1.3502, 1.4374, 1.5071,  ..., 1.3677, 1.3677, 1.4374],\n",
            "         [1.4374, 1.5071, 1.5420,  ..., 1.4200, 1.4374, 1.4200]]]), tensor(0))\n",
            "Successfully unpacked batch 89\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 89\n",
            "\n",
            "Batch 90 type: <class 'tuple'>\n",
            "Batch 90 content: (tensor([[[-0.8849, -0.9020, -0.8507,  ...,  0.9474,  0.9132,  0.9646],\n",
            "         [-0.9192, -0.9877, -0.9877,  ...,  0.8789,  0.8618,  0.9474],\n",
            "         [-1.0048, -1.0733, -1.1247,  ...,  0.8789,  0.8961,  0.9817],\n",
            "         ...,\n",
            "         [ 2.1633,  2.1633,  2.1633,  ...,  2.2489,  2.2489,  2.2489],\n",
            "         [ 2.1633,  2.1462,  2.1119,  ...,  2.2489,  2.2489,  2.2489],\n",
            "         [ 2.0948,  2.0434,  2.0948,  ...,  2.2489,  2.2489,  2.2489]],\n",
            "\n",
            "        [[-1.3880, -1.4055, -1.3179,  ..., -0.0224, -0.1099, -0.0574],\n",
            "         [-1.4405, -1.4930, -1.4755,  ..., -0.0574, -0.1099, -0.0574],\n",
            "         [-1.5630, -1.5805, -1.5805,  ..., -0.0574, -0.0924, -0.0224],\n",
            "         ...,\n",
            "         [ 0.9230,  0.8880,  0.8704,  ...,  0.9755,  1.0280,  1.0455],\n",
            "         [ 0.8880,  0.8704,  0.8354,  ...,  0.9580,  1.0105,  1.0630],\n",
            "         [ 0.8354,  0.7829,  0.8179,  ...,  0.9230,  0.9930,  1.0105]],\n",
            "\n",
            "        [[-1.5256, -1.5779, -1.5430,  ..., -0.2707, -0.3404, -0.2881],\n",
            "         [-1.5604, -1.6127, -1.5953,  ..., -0.3055, -0.3578, -0.2532],\n",
            "         [-1.6650, -1.6650, -1.6650,  ..., -0.2707, -0.3055, -0.1835],\n",
            "         ...,\n",
            "         [ 0.3742,  0.4265,  0.4265,  ...,  0.4439,  0.4962,  0.5136],\n",
            "         [ 0.3568,  0.3568,  0.3219,  ...,  0.4788,  0.4788,  0.5485],\n",
            "         [ 0.2522,  0.1999,  0.2348,  ...,  0.5136,  0.5136,  0.4962]]]), tensor(0))\n",
            "Successfully unpacked batch 90\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 90\n",
            "\n",
            "Batch 91 type: <class 'tuple'>\n",
            "Batch 91 content: (tensor([[[1.2899, 1.1358, 1.1358,  ..., 1.7352, 1.7352, 1.7694],\n",
            "         [1.2899, 1.1187, 1.1529,  ..., 1.7009, 1.7694, 1.8037],\n",
            "         [1.2214, 1.1529, 1.2728,  ..., 1.7009, 1.7523, 1.7694],\n",
            "         ...,\n",
            "         [1.2899, 1.2557, 1.2557,  ..., 1.8037, 1.8208, 1.7865],\n",
            "         [1.3242, 1.2728, 1.2385,  ..., 1.8208, 1.8037, 1.7694],\n",
            "         [1.3584, 1.2899, 1.2557,  ..., 1.9064, 1.9064, 1.9407]],\n",
            "\n",
            "        [[0.7479, 0.6078, 0.6078,  ..., 1.2556, 1.2556, 1.2906],\n",
            "         [0.7304, 0.5728, 0.5903,  ..., 1.1331, 1.2381, 1.3081],\n",
            "         [0.6429, 0.5728, 0.6779,  ..., 1.0455, 1.1856, 1.2731],\n",
            "         ...,\n",
            "         [1.0105, 0.9405, 0.9230,  ..., 1.2031, 1.2206, 1.1856],\n",
            "         [1.0280, 0.9580, 0.9230,  ..., 1.2206, 1.2031, 1.2031],\n",
            "         [1.0805, 1.0105, 0.9755,  ..., 1.3081, 1.3256, 1.3782]],\n",
            "\n",
            "        [[0.8274, 0.6879, 0.6879,  ..., 1.2457, 1.2108, 1.2457],\n",
            "         [0.7751, 0.6008, 0.6182,  ..., 1.1759, 1.2631, 1.2980],\n",
            "         [0.6705, 0.6182, 0.7228,  ..., 1.1411, 1.2457, 1.2805],\n",
            "         ...,\n",
            "         [1.1411, 1.1062, 1.0888,  ..., 1.2631, 1.2631, 1.2108],\n",
            "         [1.1585, 1.0888, 1.0539,  ..., 1.2805, 1.2457, 1.2457],\n",
            "         [1.1934, 1.1062, 1.0714,  ..., 1.3677, 1.3851, 1.4374]]]), tensor(1))\n",
            "Successfully unpacked batch 91\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 91\n",
            "\n",
            "Batch 92 type: <class 'tuple'>\n",
            "Batch 92 content: (tensor([[[ 0.1083,  0.1597,  0.0912,  ..., -0.3883, -0.4568, -0.6109],\n",
            "         [ 0.1254,  0.1768,  0.1426,  ..., -0.3541, -0.4397, -0.5596],\n",
            "         [ 0.2282,  0.2796,  0.2624,  ..., -0.2856, -0.3541, -0.4397],\n",
            "         ...,\n",
            "         [ 0.3652,  0.3652,  0.3138,  ...,  0.7419,  0.6563,  0.6563],\n",
            "         [ 0.4166,  0.4337,  0.3309,  ...,  0.7419,  0.6563,  0.6392],\n",
            "         [ 0.2967,  0.3309,  0.2967,  ...,  0.7591,  0.7077,  0.6392]],\n",
            "\n",
            "        [[-0.0924, -0.0574, -0.0399,  ..., -0.4601, -0.5651, -0.7402],\n",
            "         [-0.1099, -0.0749, -0.0399,  ..., -0.4601, -0.5301, -0.6702],\n",
            "         [-0.0749, -0.0399, -0.0399,  ..., -0.4776, -0.5476, -0.6001],\n",
            "         ...,\n",
            "         [ 0.1001,  0.1176,  0.0826,  ...,  0.5553,  0.4678,  0.4853],\n",
            "         [ 0.2052,  0.2227,  0.1702,  ...,  0.5728,  0.4678,  0.4853],\n",
            "         [ 0.1702,  0.1877,  0.1352,  ...,  0.5903,  0.5553,  0.5203]],\n",
            "\n",
            "        [[ 0.0779,  0.1302,  0.1476,  ..., -0.1835, -0.3055, -0.5147],\n",
            "         [ 0.1302,  0.1999,  0.2348,  ..., -0.2184, -0.2881, -0.4450],\n",
            "         [ 0.1999,  0.2696,  0.2522,  ..., -0.1661, -0.2532, -0.3230],\n",
            "         ...,\n",
            "         [ 0.3393,  0.3916,  0.4091,  ...,  0.8274,  0.6879,  0.6356],\n",
            "         [ 0.4614,  0.5485,  0.5659,  ...,  0.7925,  0.6705,  0.6531],\n",
            "         [ 0.5136,  0.5659,  0.5659,  ...,  0.7576,  0.7054,  0.6879]]]), tensor(0))\n",
            "Successfully unpacked batch 92\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 92\n",
            "\n",
            "Batch 93 type: <class 'tuple'>\n",
            "Batch 93 content: (tensor([[[ 0.8276,  0.7762,  0.7762,  ..., -0.0116,  0.0398,  0.1254],\n",
            "         [ 0.8789,  0.8447,  0.8104,  ..., -0.1314, -0.0458,  0.0227],\n",
            "         [ 0.8789,  0.8618,  0.8447,  ..., -0.3369, -0.1828, -0.0972],\n",
            "         ...,\n",
            "         [ 0.9303,  0.9303,  0.8961,  ...,  0.0741,  0.0227,  0.0741],\n",
            "         [ 0.9474,  0.9303,  0.9132,  ...,  0.0227,  0.0056,  0.0569],\n",
            "         [ 0.9303,  0.9303,  0.9303,  ...,  0.0569,  0.1083,  0.0569]],\n",
            "\n",
            "        [[ 0.7829,  0.7129,  0.6954,  ..., -0.4076, -0.4076, -0.3550],\n",
            "         [ 0.7304,  0.7129,  0.7129,  ..., -0.4951, -0.4776, -0.4251],\n",
            "         [ 0.6954,  0.6779,  0.6954,  ..., -0.6352, -0.5476, -0.4951],\n",
            "         ...,\n",
            "         [ 0.4328,  0.4678,  0.4678,  ..., -0.3901, -0.4601, -0.4251],\n",
            "         [ 0.4503,  0.4853,  0.5028,  ..., -0.4251, -0.4601, -0.4076],\n",
            "         [ 0.4853,  0.5028,  0.5378,  ..., -0.4076, -0.3725, -0.4251]],\n",
            "\n",
            "        [[ 0.8448,  0.7751,  0.7751,  ..., -0.2881, -0.3230, -0.2532],\n",
            "         [ 0.8099,  0.7751,  0.7751,  ..., -0.4450, -0.4275, -0.3753],\n",
            "         [ 0.7925,  0.7751,  0.7751,  ..., -0.6018, -0.4450, -0.3753],\n",
            "         ...,\n",
            "         [ 0.4439,  0.4265,  0.4265,  ..., -0.2010, -0.3230, -0.2881],\n",
            "         [ 0.5311,  0.5311,  0.5136,  ..., -0.2881, -0.2881, -0.2184],\n",
            "         [ 0.5834,  0.5834,  0.5834,  ..., -0.3230, -0.2532, -0.2532]]]), tensor(0))\n",
            "Successfully unpacked batch 93\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 93\n",
            "\n",
            "Batch 94 type: <class 'tuple'>\n",
            "Batch 94 content: (tensor([[[ 1.2214,  1.2557,  1.2214,  ..., -1.6898, -1.5528, -1.5357],\n",
            "         [ 1.2728,  1.2557,  1.2557,  ..., -1.7240, -1.6727, -1.6555],\n",
            "         [ 1.2214,  1.2385,  1.2043,  ..., -1.7412, -1.6898, -1.7240],\n",
            "         ...,\n",
            "         [ 1.2385,  1.2385,  1.2214,  ..., -1.9467, -1.9638, -1.9638],\n",
            "         [ 1.2728,  1.2899,  1.2214,  ..., -1.9467, -1.9638, -1.9638],\n",
            "         [ 1.3070,  1.2899,  1.2385,  ..., -1.9809, -1.9809, -1.9980]],\n",
            "\n",
            "        [[ 0.5378,  0.5378,  0.4678,  ..., -1.7381, -1.7031, -1.7206],\n",
            "         [ 0.6078,  0.5728,  0.5378,  ..., -1.6681, -1.6856, -1.7556],\n",
            "         [ 0.4853,  0.5203,  0.5028,  ..., -1.6681, -1.6681, -1.7556],\n",
            "         ...,\n",
            "         [ 0.1527,  0.1527,  0.1877,  ..., -1.8957, -1.8782, -1.8782],\n",
            "         [ 0.1877,  0.2227,  0.1702,  ..., -1.8957, -1.8782, -1.8782],\n",
            "         [ 0.1877,  0.1877,  0.1702,  ..., -1.9307, -1.9132, -1.8957]],\n",
            "\n",
            "        [[ 0.4439,  0.4614,  0.3916,  ..., -1.6127, -1.5604, -1.5604],\n",
            "         [ 0.4962,  0.4962,  0.4614,  ..., -1.5779, -1.5604, -1.5779],\n",
            "         [ 0.3568,  0.4091,  0.4265,  ..., -1.5779, -1.5430, -1.5779],\n",
            "         ...,\n",
            "         [ 0.0605,  0.0431,  0.0256,  ..., -1.7347, -1.7347, -1.7347],\n",
            "         [ 0.1651,  0.1999,  0.1128,  ..., -1.7347, -1.7347, -1.7347],\n",
            "         [ 0.1825,  0.1999,  0.1476,  ..., -1.7696, -1.7522, -1.7522]]]), tensor(0))\n",
            "Successfully unpacked batch 94\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 94\n",
            "\n",
            "Batch 95 type: <class 'tuple'>\n",
            "Batch 95 content: (tensor([[[0.9474, 0.9988, 1.0502,  ..., 0.9474, 0.9817, 0.9988],\n",
            "         [0.9817, 0.9817, 1.0331,  ..., 0.9817, 1.0159, 0.9988],\n",
            "         [1.0502, 1.0502, 1.0673,  ..., 0.9988, 0.9988, 0.9646],\n",
            "         ...,\n",
            "         [1.3070, 1.3242, 1.3242,  ..., 1.4098, 1.4269, 1.4269],\n",
            "         [1.2899, 1.3070, 1.3242,  ..., 1.3584, 1.3927, 1.4612],\n",
            "         [1.2557, 1.2899, 1.2728,  ..., 1.2728, 1.3413, 1.4269]],\n",
            "\n",
            "        [[0.6078, 0.6954, 0.7304,  ..., 0.1702, 0.1877, 0.2227],\n",
            "         [0.5903, 0.6429, 0.6779,  ..., 0.1877, 0.2227, 0.2227],\n",
            "         [0.6254, 0.6429, 0.6779,  ..., 0.2577, 0.2577, 0.2227],\n",
            "         ...,\n",
            "         [0.5903, 0.5728, 0.6254,  ..., 0.7654, 0.8004, 0.8004],\n",
            "         [0.6078, 0.6078, 0.6254,  ..., 0.7654, 0.7654, 0.8179],\n",
            "         [0.6429, 0.6429, 0.5903,  ..., 0.6954, 0.7304, 0.7829]],\n",
            "\n",
            "        [[0.4788, 0.5834, 0.6531,  ..., 0.2173, 0.1999, 0.1999],\n",
            "         [0.4788, 0.5834, 0.6705,  ..., 0.2696, 0.2696, 0.2522],\n",
            "         [0.5311, 0.6356, 0.7228,  ..., 0.3045, 0.3045, 0.3045],\n",
            "         ...,\n",
            "         [0.6356, 0.6182, 0.6531,  ..., 0.8622, 0.9145, 0.9145],\n",
            "         [0.6879, 0.6705, 0.7054,  ..., 0.8622, 0.9145, 0.9668],\n",
            "         [0.7228, 0.7228, 0.6879,  ..., 0.8099, 0.8797, 0.9494]]]), tensor(0))\n",
            "Successfully unpacked batch 95\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 95\n",
            "\n",
            "Batch 96 type: <class 'tuple'>\n",
            "Batch 96 content: (tensor([[[ 0.8961,  0.8104,  0.8276,  ...,  0.1426,  0.1254,  0.1254],\n",
            "         [ 0.8618,  0.7762,  0.8276,  ...,  0.1426,  0.1426,  0.1254],\n",
            "         [ 0.8447,  0.8276,  0.7933,  ...,  0.1254,  0.1083,  0.0912],\n",
            "         ...,\n",
            "         [ 1.2557,  1.2557,  1.2043,  ...,  0.9132,  0.9646,  0.9474],\n",
            "         [ 1.2214,  1.1700,  1.1187,  ...,  0.9474,  1.0159,  0.9988],\n",
            "         [ 1.1358,  1.1358,  1.1015,  ...,  0.9817,  1.0502,  1.0673]],\n",
            "\n",
            "        [[ 0.2052,  0.1527,  0.2052,  ..., -0.4251, -0.4076, -0.4251],\n",
            "         [ 0.1527,  0.1176,  0.2052,  ..., -0.4426, -0.4251, -0.4076],\n",
            "         [ 0.2402,  0.2402,  0.2227,  ..., -0.4951, -0.4776, -0.4951],\n",
            "         ...,\n",
            "         [ 0.5028,  0.5028,  0.5028,  ...,  0.2052,  0.2752,  0.3102],\n",
            "         [ 0.5028,  0.4678,  0.4328,  ...,  0.2227,  0.2927,  0.3102],\n",
            "         [ 0.4328,  0.4328,  0.3978,  ...,  0.2402,  0.2752,  0.3277]],\n",
            "\n",
            "        [[ 0.1825,  0.1128,  0.1651,  ..., -0.5844, -0.6018, -0.6541],\n",
            "         [ 0.1476,  0.1128,  0.2173,  ..., -0.6018, -0.6193, -0.6367],\n",
            "         [ 0.1999,  0.2173,  0.1999,  ..., -0.6367, -0.6541, -0.6715],\n",
            "         ...,\n",
            "         [ 0.4962,  0.4962,  0.4439,  ...,  0.1825,  0.2522,  0.3045],\n",
            "         [ 0.4614,  0.4439,  0.3742,  ...,  0.1825,  0.2696,  0.3393],\n",
            "         [ 0.3916,  0.3916,  0.3568,  ...,  0.1825,  0.2696,  0.3393]]]), tensor(0))\n",
            "Successfully unpacked batch 96\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 96\n",
            "\n",
            "Batch 97 type: <class 'tuple'>\n",
            "Batch 97 content: (tensor([[[ 0.7077,  0.7248,  0.7248,  ..., -1.6555, -1.5357, -1.5014],\n",
            "         [ 0.8276,  0.7077,  0.5707,  ..., -1.7412, -1.6213, -1.4843],\n",
            "         [ 0.9646,  0.9132,  0.7419,  ..., -1.7412, -1.6727, -1.5357],\n",
            "         ...,\n",
            "         [ 1.8722,  1.8722,  1.8722,  ...,  1.4954,  1.4440,  1.5125],\n",
            "         [ 1.9235,  1.8893,  1.8893,  ...,  1.5982,  1.5468,  1.5639],\n",
            "         [ 2.0263,  1.9749,  1.9407,  ...,  1.6153,  1.5468,  1.5639]],\n",
            "\n",
            "        [[-0.3200, -0.3550, -0.3375,  ..., -1.6331, -1.4755, -1.4230],\n",
            "         [-0.2325, -0.3375, -0.4426,  ..., -1.7206, -1.5980, -1.4755],\n",
            "         [-0.1099, -0.1275, -0.2500,  ..., -1.7381, -1.7031, -1.5630],\n",
            "         ...,\n",
            "         [ 0.9930,  0.9755,  0.9580,  ...,  0.8529,  0.7479,  0.7479],\n",
            "         [ 1.0805,  0.9930,  0.9930,  ...,  0.9755,  0.8880,  0.8354],\n",
            "         [ 1.1506,  1.0980,  1.0630,  ...,  1.0280,  0.9055,  0.8880]],\n",
            "\n",
            "        [[-0.6367, -0.6715, -0.6541,  ..., -1.4907, -1.3513, -1.2990],\n",
            "         [-0.5147, -0.6890, -0.7761,  ..., -1.5779, -1.4733, -1.3687],\n",
            "         [-0.3404, -0.3578, -0.4798,  ..., -1.6127, -1.5779, -1.4559],\n",
            "         ...,\n",
            "         [ 0.7925,  0.7751,  0.8099,  ...,  0.7925,  0.7054,  0.6879],\n",
            "         [ 0.8448,  0.7925,  0.8099,  ...,  0.9319,  0.8099,  0.7576],\n",
            "         [ 0.9145,  0.8622,  0.8622,  ...,  0.9494,  0.7925,  0.7402]]]), tensor(0))\n",
            "Successfully unpacked batch 97\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 97\n",
            "\n",
            "Batch 98 type: <class 'tuple'>\n",
            "Batch 98 content: (tensor([[[ 0.6734,  0.6734,  0.6734,  ...,  0.8447,  0.8276,  0.7933],\n",
            "         [ 0.6906,  0.6049,  0.5536,  ...,  0.7933,  0.8447,  0.8618],\n",
            "         [ 0.7419,  0.6392,  0.5878,  ...,  0.7762,  0.8104,  0.8276],\n",
            "         ...,\n",
            "         [ 0.5878,  0.6392,  0.6906,  ...,  0.8104,  0.7077,  0.6906],\n",
            "         [ 0.6049,  0.6392,  0.6734,  ...,  0.7591,  0.7077,  0.6734],\n",
            "         [ 0.6221,  0.6221,  0.6221,  ...,  0.7933,  0.6734,  0.6563]],\n",
            "\n",
            "        [[-0.2325, -0.2500, -0.3025,  ..., -0.1275, -0.1099, -0.0924],\n",
            "         [-0.1800, -0.2675, -0.3550,  ..., -0.1275, -0.0574, -0.0574],\n",
            "         [-0.1625, -0.2325, -0.3200,  ..., -0.0924, -0.0574, -0.0749],\n",
            "         ...,\n",
            "         [-0.4426, -0.3901, -0.3550,  ..., -0.1275, -0.2325, -0.2325],\n",
            "         [-0.4251, -0.3901, -0.4076,  ..., -0.2325, -0.2675, -0.2500],\n",
            "         [-0.4076, -0.4251, -0.4951,  ..., -0.2675, -0.3901, -0.3725]],\n",
            "\n",
            "        [[-0.1661, -0.1835, -0.2358,  ..., -0.1835, -0.1835, -0.1312],\n",
            "         [-0.1835, -0.2532, -0.3404,  ..., -0.1661, -0.1487, -0.1138],\n",
            "         [-0.1835, -0.2881, -0.3578,  ..., -0.0615, -0.0964, -0.1312],\n",
            "         ...,\n",
            "         [-0.3230, -0.2881, -0.2532,  ..., -0.0964, -0.2010, -0.2010],\n",
            "         [-0.2881, -0.2532, -0.2707,  ..., -0.1661, -0.2184, -0.2358],\n",
            "         [-0.2358, -0.2184, -0.3055,  ..., -0.1661, -0.3055, -0.3404]]]), tensor(0))\n",
            "Successfully unpacked batch 98\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 98\n",
            "\n",
            "Batch 99 type: <class 'tuple'>\n",
            "Batch 99 content: (tensor([[[ 1.1700,  1.1700,  1.0844,  ...,  1.2728,  1.3070,  1.3242],\n",
            "         [ 1.1700,  1.1358,  1.1187,  ...,  1.3242,  1.3413,  1.3584],\n",
            "         [ 1.1529,  1.1700,  1.1700,  ...,  1.3584,  1.3584,  1.3755],\n",
            "         ...,\n",
            "         [ 0.9474,  0.8961,  0.8618,  ...,  1.0673,  1.1015,  1.0673],\n",
            "         [ 0.9817,  0.9474,  0.9132,  ...,  1.0844,  1.1015,  1.0673],\n",
            "         [ 0.9646,  0.9132,  0.8961,  ...,  1.0844,  1.1529,  1.1187]],\n",
            "\n",
            "        [[ 0.4853,  0.4853,  0.4153,  ...,  0.5728,  0.6429,  0.6779],\n",
            "         [ 0.5028,  0.4503,  0.4153,  ...,  0.5378,  0.6254,  0.6779],\n",
            "         [ 0.4678,  0.4328,  0.3978,  ...,  0.5378,  0.5728,  0.6429],\n",
            "         ...,\n",
            "         [ 0.1527,  0.1001,  0.0826,  ...,  0.3277,  0.3452,  0.3277],\n",
            "         [ 0.2052,  0.1702,  0.1001,  ...,  0.2402,  0.2577,  0.2577],\n",
            "         [ 0.1877,  0.1352,  0.1176,  ...,  0.1527,  0.2052,  0.2577]],\n",
            "\n",
            "        [[ 0.3916,  0.3219,  0.1999,  ...,  0.4091,  0.4788,  0.5136],\n",
            "         [ 0.3916,  0.2871,  0.2173,  ...,  0.4439,  0.5485,  0.5834],\n",
            "         [ 0.3045,  0.2522,  0.1476,  ...,  0.4962,  0.5136,  0.5659],\n",
            "         ...,\n",
            "         [-0.1138, -0.1661, -0.2184,  ..., -0.0790, -0.0267, -0.0267],\n",
            "         [-0.1487, -0.1835, -0.2184,  ..., -0.1138, -0.0441, -0.0441],\n",
            "         [-0.1661, -0.2358, -0.2532,  ..., -0.2010, -0.1138, -0.0790]]]), tensor(0))\n",
            "Successfully unpacked batch 99\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 99\n",
            "\n",
            "Batch 100 type: <class 'tuple'>\n",
            "Batch 100 content: (tensor([[[-0.4397, -0.3541, -0.1657,  ...,  0.0741,  0.0398, -0.0116],\n",
            "         [-0.5082, -0.3198, -0.2171,  ...,  0.0227,  0.0569,  0.0569],\n",
            "         [-0.5253, -0.3027, -0.1657,  ..., -0.0629, -0.0116,  0.0056],\n",
            "         ...,\n",
            "         [-0.3027, -0.2856, -0.3027,  ...,  0.4679,  0.3994,  0.3823],\n",
            "         [-0.2684, -0.2342, -0.2856,  ...,  0.4166,  0.4166,  0.4508],\n",
            "         [-0.1828, -0.1486, -0.2171,  ...,  0.3994,  0.4508,  0.5193]],\n",
            "\n",
            "        [[-0.8627, -0.8277, -0.6527,  ..., -0.6176, -0.6001, -0.6176],\n",
            "         [-0.9503, -0.8277, -0.6702,  ..., -0.5826, -0.5476, -0.5476],\n",
            "         [-1.0028, -0.8102, -0.6877,  ..., -0.5651, -0.5476, -0.5651],\n",
            "         ...,\n",
            "         [-0.6176, -0.5826, -0.5826,  ..., -0.2325, -0.2675, -0.2850],\n",
            "         [-0.6527, -0.6352, -0.6352,  ..., -0.2850, -0.3025, -0.2500],\n",
            "         [-0.6702, -0.6527, -0.6702,  ..., -0.2500, -0.3375, -0.3200]],\n",
            "\n",
            "        [[-1.0724, -1.0027, -0.8110,  ..., -0.6715, -0.6890, -0.7238],\n",
            "         [-1.1944, -1.0376, -0.8981,  ..., -0.6541, -0.6193, -0.6541],\n",
            "         [-1.2467, -1.0376, -0.9156,  ..., -0.7587, -0.7413, -0.7587],\n",
            "         ...,\n",
            "         [-0.6018, -0.5844, -0.5495,  ..., -0.6367, -0.6193, -0.6367],\n",
            "         [-0.5147, -0.5147, -0.4973,  ..., -0.7064, -0.6715, -0.6018],\n",
            "         [-0.4973, -0.4798, -0.4973,  ..., -0.7413, -0.7413, -0.6541]]]), tensor(0))\n",
            "Successfully unpacked batch 100\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 100\n",
            "\n",
            "Batch 101 type: <class 'tuple'>\n",
            "Batch 101 content: (tensor([[[ 0.2111,  0.1768,  0.1254,  ..., -1.4672, -1.5357, -1.5528],\n",
            "         [ 0.1426,  0.1083,  0.0912,  ..., -1.4329, -1.5185, -1.5528],\n",
            "         [ 0.1083,  0.0398,  0.0912,  ..., -1.3473, -1.4158, -1.4843],\n",
            "         ...,\n",
            "         [-0.3369, -0.3712, -0.4397,  ..., -0.0458, -0.0801, -0.1143],\n",
            "         [-0.3198, -0.3027, -0.3541,  ..., -0.0458, -0.0801, -0.1143],\n",
            "         [-0.2856, -0.2856, -0.3198,  ..., -0.0972, -0.0629, -0.0972]],\n",
            "\n",
            "        [[-0.4426, -0.4076, -0.4076,  ..., -1.6155, -1.6681, -1.6856],\n",
            "         [-0.4076, -0.3725, -0.3725,  ..., -1.5805, -1.6331, -1.6506],\n",
            "         [-0.3550, -0.3725, -0.3200,  ..., -1.5630, -1.5805, -1.5980],\n",
            "         ...,\n",
            "         [-0.6352, -0.6527, -0.7052,  ..., -0.6877, -0.6877, -0.6877],\n",
            "         [-0.6702, -0.6527, -0.6527,  ..., -0.6702, -0.7052, -0.6877],\n",
            "         [-0.7052, -0.7227, -0.7052,  ..., -0.7227, -0.6877, -0.6877]],\n",
            "\n",
            "        [[-0.3578, -0.3578, -0.4101,  ..., -1.4907, -1.5256, -1.5430],\n",
            "         [-0.3578, -0.3753, -0.4101,  ..., -1.4384, -1.4559, -1.4559],\n",
            "         [-0.3230, -0.3578, -0.3753,  ..., -1.4559, -1.4559, -1.4733],\n",
            "         ...,\n",
            "         [-0.6367, -0.6890, -0.7761,  ..., -0.6890, -0.7413, -0.7587],\n",
            "         [-0.6541, -0.6541, -0.7413,  ..., -0.7238, -0.7587, -0.7587],\n",
            "         [-0.6715, -0.7238, -0.8110,  ..., -0.7936, -0.7413, -0.7413]]]), tensor(0))\n",
            "Successfully unpacked batch 101\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 101\n",
            "\n",
            "Batch 102 type: <class 'tuple'>\n",
            "Batch 102 content: (tensor([[[ 1.0502,  1.0502,  1.0502,  ..., -0.3541, -0.3541, -0.4054],\n",
            "         [ 1.0844,  1.1015,  1.0844,  ..., -0.4911, -0.4739, -0.4911],\n",
            "         [ 1.0844,  1.0673,  1.0502,  ..., -0.4397, -0.4568, -0.4911],\n",
            "         ...,\n",
            "         [ 0.8447,  0.8961,  0.9817,  ...,  0.4508,  0.4679,  0.5022],\n",
            "         [ 0.8618,  0.8961,  0.9646,  ...,  0.4679,  0.4851,  0.5022],\n",
            "         [ 0.7762,  0.8447,  0.9303,  ...,  0.5193,  0.5022,  0.5022]],\n",
            "\n",
            "        [[-0.1450, -0.0924, -0.0049,  ..., -0.9853, -0.9678, -0.9853],\n",
            "         [-0.0924, -0.0224,  0.0301,  ..., -1.0553, -1.0028, -0.9853],\n",
            "         [-0.0574, -0.0049,  0.0301,  ..., -1.0553, -1.0028, -0.9853],\n",
            "         ...,\n",
            "         [-0.3200, -0.3375, -0.3025,  ..., -0.6877, -0.7052, -0.6702],\n",
            "         [-0.3025, -0.3200, -0.2850,  ..., -0.6877, -0.6702, -0.6527],\n",
            "         [-0.4776, -0.3901, -0.3200,  ..., -0.6527, -0.7052, -0.7227]],\n",
            "\n",
            "        [[-0.2881, -0.2881, -0.3055,  ..., -1.2119, -1.2467, -1.2990],\n",
            "         [-0.2010, -0.1835, -0.2010,  ..., -1.3164, -1.3164, -1.3513],\n",
            "         [-0.2532, -0.2184, -0.2010,  ..., -1.3339, -1.2990, -1.3164],\n",
            "         ...,\n",
            "         [-0.7587, -0.7587, -0.6715,  ..., -0.9504, -0.9156, -0.8807],\n",
            "         [-0.7587, -0.7238, -0.6367,  ..., -0.9156, -0.8807, -0.8807],\n",
            "         [-0.9156, -0.7936, -0.6715,  ..., -0.8458, -0.8633, -0.8807]]]), tensor(0))\n",
            "Successfully unpacked batch 102\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 102\n",
            "\n",
            "Batch 103 type: <class 'tuple'>\n",
            "Batch 103 content: (tensor([[[ 1.0502,  0.9988,  1.0502,  ...,  1.5468,  1.6667,  1.6667],\n",
            "         [ 1.0159,  1.0159,  1.0502,  ...,  1.5468,  1.5982,  1.6153],\n",
            "         [ 0.9988,  0.9988,  1.0159,  ...,  1.5468,  1.5810,  1.5810],\n",
            "         ...,\n",
            "         [ 1.0331,  0.9817,  1.0502,  ...,  0.9474,  0.9474,  0.9303],\n",
            "         [ 1.1187,  0.9988,  1.0331,  ...,  0.9474,  0.9132,  0.8447],\n",
            "         [ 1.2214,  1.1015,  1.0844,  ...,  0.9474,  0.8618,  0.7933]],\n",
            "\n",
            "        [[ 0.0301, -0.0399,  0.0301,  ...,  0.3627,  0.4678,  0.4678],\n",
            "         [-0.0049, -0.0574, -0.0224,  ...,  0.4503,  0.4853,  0.4503],\n",
            "         [-0.0399, -0.0749, -0.0749,  ...,  0.4503,  0.5028,  0.4853],\n",
            "         ...,\n",
            "         [ 0.4503,  0.4328,  0.4853,  ..., -0.2850, -0.3025, -0.3375],\n",
            "         [ 0.5028,  0.3803,  0.4153,  ..., -0.3025, -0.3550, -0.4426],\n",
            "         [ 0.5728,  0.4503,  0.4153,  ..., -0.2675, -0.3375, -0.4601]],\n",
            "\n",
            "        [[-0.2184, -0.2881, -0.2184,  ..., -0.0615,  0.1128,  0.1302],\n",
            "         [-0.2532, -0.3055, -0.3230,  ..., -0.0615,  0.0082,  0.0256],\n",
            "         [-0.2881, -0.3230, -0.3753,  ..., -0.0267,  0.0431,  0.0605],\n",
            "         ...,\n",
            "         [ 0.0256, -0.0092,  0.0779,  ..., -0.4101, -0.3927, -0.4275],\n",
            "         [ 0.0953, -0.0615,  0.0082,  ..., -0.5147, -0.4973, -0.5495],\n",
            "         [ 0.1999,  0.1128,  0.0953,  ..., -0.4798, -0.5147, -0.5670]]]), tensor(0))\n",
            "Successfully unpacked batch 103\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 103\n",
            "\n",
            "Batch 104 type: <class 'tuple'>\n",
            "Batch 104 content: (tensor([[[ 1.3413,  1.4098,  1.4440,  ...,  0.9988,  0.9988,  0.9474],\n",
            "         [ 1.3242,  1.3927,  1.4440,  ...,  0.8618,  0.7933,  0.8961],\n",
            "         [ 1.3584,  1.3755,  1.4269,  ...,  0.9474,  1.0502,  1.0844],\n",
            "         ...,\n",
            "         [ 1.3755,  1.3927,  1.4269,  ...,  1.6838,  1.6838,  1.6495],\n",
            "         [ 1.3584,  1.3755,  1.3755,  ...,  1.6838,  1.6838,  1.6667],\n",
            "         [ 1.3584,  1.3584,  1.3413,  ...,  1.6324,  1.6324,  1.6324]],\n",
            "\n",
            "        [[ 0.1527,  0.2052,  0.2052,  ..., -0.0924, -0.0399, -0.0749],\n",
            "         [ 0.1527,  0.1877,  0.2052,  ..., -0.1800, -0.2150, -0.1275],\n",
            "         [ 0.1527,  0.1527,  0.1702,  ..., -0.0574,  0.0826,  0.1001],\n",
            "         ...,\n",
            "         [-0.0399, -0.0224, -0.0399,  ...,  0.6078,  0.6604,  0.6604],\n",
            "         [-0.0224, -0.0399, -0.0574,  ...,  0.5728,  0.6254,  0.6078],\n",
            "         [-0.0224, -0.0574, -0.1099,  ...,  0.5028,  0.5378,  0.5553]],\n",
            "\n",
            "        [[ 0.0082,  0.0431,  0.0605,  ..., -0.3404, -0.2707, -0.3055],\n",
            "         [-0.0092,  0.0256,  0.0605,  ..., -0.5147, -0.5147, -0.3927],\n",
            "         [ 0.0082, -0.0092,  0.0082,  ..., -0.3578, -0.2184, -0.2184],\n",
            "         ...,\n",
            "         [-0.4275, -0.3753, -0.3753,  ...,  0.1999,  0.2173,  0.1999],\n",
            "         [-0.4101, -0.4101, -0.4101,  ...,  0.1302,  0.1476,  0.1302],\n",
            "         [-0.3927, -0.4275, -0.4798,  ...,  0.0605,  0.0431,  0.0605]]]), tensor(0))\n",
            "Successfully unpacked batch 104\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 104\n",
            "\n",
            "Batch 105 type: <class 'tuple'>\n",
            "Batch 105 content: (tensor([[[ 0.6049,  0.1768,  0.2796,  ...,  1.1529,  1.0159,  0.9303],\n",
            "         [ 0.3138,  0.2967,  0.6221,  ...,  1.1015,  1.0673,  1.0159],\n",
            "         [ 0.4851,  0.7591,  1.1358,  ...,  1.0844,  1.0844,  1.0331],\n",
            "         ...,\n",
            "         [ 2.1119,  2.1119,  2.1290,  ...,  2.2318,  2.2318,  2.1975],\n",
            "         [ 2.1119,  2.1119,  2.1119,  ...,  2.2318,  2.2318,  2.2147],\n",
            "         [ 2.0777,  2.0948,  2.0948,  ...,  2.2147,  2.1975,  2.2147]],\n",
            "\n",
            "        [[ 0.1001, -0.3375, -0.2150,  ...,  0.4328,  0.2927,  0.2227],\n",
            "         [-0.1099, -0.1275,  0.2052,  ...,  0.3102,  0.2927,  0.2577],\n",
            "         [ 0.1176,  0.3978,  0.7479,  ...,  0.2752,  0.2927,  0.2402],\n",
            "         ...,\n",
            "         [ 1.4482,  1.4657,  1.4832,  ...,  1.5007,  1.5357,  1.5007],\n",
            "         [ 1.4482,  1.4482,  1.4482,  ...,  1.5007,  1.5007,  1.4832],\n",
            "         [ 1.4132,  1.4482,  1.4307,  ...,  1.4832,  1.4657,  1.5182]],\n",
            "\n",
            "        [[ 0.1302, -0.3055, -0.1312,  ...,  0.3568,  0.2348,  0.1825],\n",
            "         [-0.0615, -0.0441,  0.3219,  ...,  0.3219,  0.2871,  0.2348],\n",
            "         [ 0.1825,  0.4788,  0.8448,  ...,  0.2696,  0.2696,  0.1999],\n",
            "         ...,\n",
            "         [ 1.2805,  1.2980,  1.2980,  ...,  1.4897,  1.5071,  1.4722],\n",
            "         [ 1.2805,  1.2805,  1.2805,  ...,  1.5071,  1.4897,  1.4548],\n",
            "         [ 1.2631,  1.2980,  1.2631,  ...,  1.4722,  1.4200,  1.4548]]]), tensor(0))\n",
            "Successfully unpacked batch 105\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 105\n",
            "\n",
            "Batch 106 type: <class 'tuple'>\n",
            "Batch 106 content: (tensor([[[ 0.7591,  0.7419,  0.5022,  ..., -1.2103, -1.2274, -1.2788],\n",
            "         [ 0.5536,  0.5022,  0.3652,  ..., -1.2617, -1.2788, -1.3130],\n",
            "         [ 0.5022,  0.4337,  0.4166,  ..., -1.2959, -1.3987, -1.3815],\n",
            "         ...,\n",
            "         [ 1.5468,  1.5297,  1.5982,  ...,  1.2214,  1.2557,  1.3242],\n",
            "         [ 1.4954,  1.4440,  1.5468,  ...,  1.2385,  1.2557,  1.3242],\n",
            "         [ 1.2728,  1.3413,  1.4269,  ...,  1.3070,  1.2899,  1.3584]],\n",
            "\n",
            "        [[ 0.1176,  0.0826, -0.2150,  ..., -1.4405, -1.4580, -1.4755],\n",
            "         [-0.0924, -0.1450, -0.3375,  ..., -1.4755, -1.5105, -1.5105],\n",
            "         [-0.1625, -0.2150, -0.2150,  ..., -1.4755, -1.5630, -1.5805],\n",
            "         ...,\n",
            "         [ 0.9405,  0.9580,  1.1155,  ...,  0.2752,  0.3277,  0.3978],\n",
            "         [ 0.9230,  0.8704,  1.0455,  ...,  0.2752,  0.2927,  0.3627],\n",
            "         [ 0.5378,  0.6779,  0.8354,  ...,  0.3452,  0.3277,  0.3978]],\n",
            "\n",
            "        [[ 0.0082, -0.0092, -0.3578,  ..., -1.4559, -1.4733, -1.4559],\n",
            "         [-0.1835, -0.2358, -0.4275,  ..., -1.5256, -1.5081, -1.4733],\n",
            "         [-0.2707, -0.2707, -0.2707,  ..., -1.5779, -1.6127, -1.5953],\n",
            "         ...,\n",
            "         [ 0.5311,  0.5834,  0.7925,  ..., -0.2010, -0.1312, -0.0790],\n",
            "         [ 0.5485,  0.5311,  0.7228,  ..., -0.1661, -0.1487, -0.0964],\n",
            "         [ 0.1651,  0.2522,  0.4265,  ..., -0.0964, -0.1138, -0.0615]]]), tensor(0))\n",
            "Successfully unpacked batch 106\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 106\n",
            "\n",
            "Batch 107 type: <class 'tuple'>\n",
            "Batch 107 content: (tensor([[[-1.3987, -1.4158, -1.4329,  ..., -1.3644, -1.2959, -1.2788],\n",
            "         [-1.4843, -1.4329, -1.3644,  ..., -1.3302, -1.2788, -1.2788],\n",
            "         [-1.2788, -1.1418, -1.0562,  ..., -1.2959, -1.2959, -1.3302],\n",
            "         ...,\n",
            "         [ 0.2967,  0.2967,  0.3138,  ..., -0.5938, -0.5938, -0.5938],\n",
            "         [ 0.3994,  0.3309,  0.3309,  ..., -0.5596, -0.5767, -0.6109],\n",
            "         [ 0.4508,  0.3994,  0.3481,  ..., -0.4911, -0.4739, -0.5596]],\n",
            "\n",
            "        [[-1.3179, -1.3704, -1.4230,  ..., -1.3179, -1.2479, -1.2304],\n",
            "         [-1.4580, -1.4230, -1.3704,  ..., -1.2654, -1.2129, -1.2304],\n",
            "         [-1.2829, -1.1429, -1.0378,  ..., -1.2304, -1.2129, -1.2654],\n",
            "         ...,\n",
            "         [-0.0924, -0.1099, -0.1099,  ..., -0.9678, -0.9328, -0.9153],\n",
            "         [-0.1099, -0.1625, -0.1625,  ..., -0.9328, -0.8803, -0.8978],\n",
            "         [-0.1625, -0.2150, -0.2500,  ..., -0.8452, -0.8102, -0.8627]],\n",
            "\n",
            "        [[-1.2467, -1.2990, -1.3164,  ..., -0.9156, -0.8458, -0.8284],\n",
            "         [-1.3687, -1.2990, -1.2467,  ..., -0.8458, -0.7761, -0.7761],\n",
            "         [-1.1944, -1.0201, -0.9156,  ..., -0.8110, -0.7587, -0.7761],\n",
            "         ...,\n",
            "         [ 0.0431,  0.0431,  0.0605,  ..., -0.8110, -0.7936, -0.7761],\n",
            "         [ 0.0953,  0.0431,  0.0256,  ..., -0.7761, -0.7413, -0.7761],\n",
            "         [ 0.0779,  0.0256, -0.0267,  ..., -0.6541, -0.6193, -0.7064]]]), tensor(0))\n",
            "Successfully unpacked batch 107\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 107\n",
            "\n",
            "Batch 108 type: <class 'tuple'>\n",
            "Batch 108 content: (tensor([[[ 0.1939,  0.2111,  0.3309,  ..., -1.4158, -1.2788, -1.1247],\n",
            "         [ 0.2111,  0.1083,  0.1254,  ..., -1.2274, -1.1760, -1.1932],\n",
            "         [ 0.0912,  0.1254,  0.1939,  ..., -1.1589, -1.0219, -1.0048],\n",
            "         ...,\n",
            "         [ 0.0398,  0.0056,  0.0227,  ..., -0.2856, -0.3027, -0.3712],\n",
            "         [ 0.0227,  0.0741,  0.0912,  ..., -0.3369, -0.4054, -0.4397],\n",
            "         [ 0.0227,  0.0912,  0.0912,  ..., -0.3541, -0.4226, -0.4911]],\n",
            "\n",
            "        [[-0.3025, -0.2500, -0.1275,  ..., -1.5280, -1.4930, -1.3880],\n",
            "         [-0.3025, -0.3550, -0.3550,  ..., -1.3704, -1.4055, -1.4755],\n",
            "         [-0.4251, -0.3550, -0.3025,  ..., -1.3704, -1.2654, -1.3004],\n",
            "         ...,\n",
            "         [-0.4951, -0.5476, -0.5651,  ..., -0.7752, -0.7927, -0.8452],\n",
            "         [-0.5301, -0.5126, -0.5301,  ..., -0.7402, -0.8277, -0.8803],\n",
            "         [-0.4951, -0.4601, -0.5126,  ..., -0.7052, -0.7927, -0.9153]],\n",
            "\n",
            "        [[-0.2358, -0.2010, -0.0615,  ..., -1.4733, -1.4036, -1.2816],\n",
            "         [-0.2184, -0.2881, -0.2881,  ..., -1.3861, -1.4210, -1.4559],\n",
            "         [-0.3055, -0.2358, -0.1835,  ..., -1.3687, -1.2816, -1.2816],\n",
            "         ...,\n",
            "         [-0.4275, -0.4798, -0.4798,  ..., -0.8110, -0.8110, -0.8110],\n",
            "         [-0.4973, -0.4450, -0.4624,  ..., -0.8110, -0.8458, -0.8633],\n",
            "         [-0.5670, -0.5321, -0.5670,  ..., -0.7761, -0.8284, -0.9156]]]), tensor(0))\n",
            "Successfully unpacked batch 108\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 108\n",
            "\n",
            "Batch 109 type: <class 'tuple'>\n",
            "Batch 109 content: (tensor([[[ 0.4508,  0.4679,  0.5022,  ..., -1.9638, -1.9638, -1.9638],\n",
            "         [ 0.4679,  0.5022,  0.5364,  ..., -1.9809, -2.0152, -1.9638],\n",
            "         [ 0.5536,  0.5364,  0.5364,  ..., -1.9809, -2.0152, -2.0152],\n",
            "         ...,\n",
            "         [ 0.4337,  0.3994,  0.3309,  ..., -1.6384, -1.5699, -1.5699],\n",
            "         [ 0.2624,  0.2282,  0.2111,  ..., -1.6042, -1.5185, -1.5357],\n",
            "         [ 0.1768,  0.1768,  0.1597,  ..., -1.5528, -1.4672, -1.4843]],\n",
            "\n",
            "        [[-0.5476, -0.5476, -0.5126,  ..., -1.8431, -1.8431, -1.8431],\n",
            "         [-0.6176, -0.5651, -0.5301,  ..., -1.8606, -1.8957, -1.8606],\n",
            "         [-0.5826, -0.5651, -0.5476,  ..., -1.8782, -1.9132, -1.9132],\n",
            "         ...,\n",
            "         [-0.6527, -0.6352, -0.6877,  ..., -1.6506, -1.6155, -1.6155],\n",
            "         [-0.7227, -0.7227, -0.7927,  ..., -1.6681, -1.6331, -1.6331],\n",
            "         [-0.7402, -0.7752, -0.8277,  ..., -1.6506, -1.6155, -1.6331]],\n",
            "\n",
            "        [[-0.8458, -0.7587, -0.6715,  ..., -1.6999, -1.6999, -1.6999],\n",
            "         [-0.9330, -0.7936, -0.6890,  ..., -1.7347, -1.7522, -1.7173],\n",
            "         [-0.8807, -0.8110, -0.7413,  ..., -1.7696, -1.7870, -1.7696],\n",
            "         ...,\n",
            "         [-0.8633, -0.8284, -0.8633,  ..., -1.5430, -1.5256, -1.5604],\n",
            "         [-0.9678, -0.9853, -0.9678,  ..., -1.5779, -1.5256, -1.5779],\n",
            "         [-1.0201, -1.0550, -1.0550,  ..., -1.5953, -1.5430, -1.5604]]]), tensor(0))\n",
            "Successfully unpacked batch 109\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 109\n",
            "\n",
            "Batch 110 type: <class 'tuple'>\n",
            "Batch 110 content: (tensor([[[ 0.2453,  0.2453,  0.2967,  ...,  1.3755,  1.4098,  1.3584],\n",
            "         [ 0.1939,  0.1597,  0.1939,  ...,  1.3584,  1.3755,  1.3755],\n",
            "         [ 0.1426,  0.1083,  0.1083,  ...,  1.3927,  1.4098,  1.4098],\n",
            "         ...,\n",
            "         [ 0.9988,  1.0159,  1.0844,  ...,  1.6667,  1.5982,  1.6153],\n",
            "         [ 1.0502,  1.0331,  1.0502,  ...,  1.5982,  1.5468,  1.5982],\n",
            "         [ 1.0502,  1.0673,  1.0673,  ...,  1.5639,  1.5639,  1.6153]],\n",
            "\n",
            "        [[-0.4426, -0.4951, -0.4776,  ...,  0.4153,  0.4503,  0.3803],\n",
            "         [-0.4426, -0.4951, -0.4951,  ...,  0.4328,  0.4328,  0.4328],\n",
            "         [-0.4776, -0.5126, -0.5476,  ...,  0.5028,  0.4678,  0.4503],\n",
            "         ...,\n",
            "         [-0.0224, -0.0399, -0.0399,  ...,  0.5378,  0.4853,  0.5028],\n",
            "         [ 0.0126, -0.0399, -0.0574,  ...,  0.5378,  0.4678,  0.4678],\n",
            "         [-0.0224, -0.0399, -0.0574,  ...,  0.5203,  0.4853,  0.5203]],\n",
            "\n",
            "        [[-0.4101, -0.4973, -0.5495,  ...,  0.3742,  0.3742,  0.2696],\n",
            "         [-0.4624, -0.5670, -0.6193,  ...,  0.3568,  0.3568,  0.3393],\n",
            "         [-0.6541, -0.7238, -0.7587,  ...,  0.3045,  0.3219,  0.3219],\n",
            "         ...,\n",
            "         [-0.2532, -0.2532, -0.2010,  ...,  0.3393,  0.2348,  0.2348],\n",
            "         [-0.1835, -0.2358, -0.2532,  ...,  0.3045,  0.1999,  0.1999],\n",
            "         [-0.1835, -0.2184, -0.2532,  ...,  0.2871,  0.2696,  0.3045]]]), tensor(0))\n",
            "Successfully unpacked batch 110\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 110\n",
            "\n",
            "Batch 111 type: <class 'tuple'>\n",
            "Batch 111 content: (tensor([[[ 1.3755,  1.3070,  1.3413,  ...,  0.4851,  0.4851,  0.6392],\n",
            "         [ 1.4269,  1.3242,  1.3070,  ...,  0.4508,  0.3994,  0.4679],\n",
            "         [ 1.4098,  1.3242,  1.2557,  ...,  0.4679,  0.4166,  0.3481],\n",
            "         ...,\n",
            "         [ 1.5982,  1.5810,  1.5639,  ...,  1.4440,  1.4269,  1.4098],\n",
            "         [ 1.6324,  1.5810,  1.5639,  ...,  1.4440,  1.4612,  1.4440],\n",
            "         [ 1.6324,  1.5468,  1.5125,  ...,  1.4783,  1.4612,  1.4783]],\n",
            "\n",
            "        [[ 0.4503,  0.4328,  0.4678,  ..., -0.3025, -0.2500, -0.0749],\n",
            "         [ 0.5203,  0.4503,  0.4328,  ..., -0.2675, -0.3200, -0.2675],\n",
            "         [ 0.5203,  0.4678,  0.3978,  ..., -0.2850, -0.3375, -0.4251],\n",
            "         ...,\n",
            "         [ 0.4503,  0.4328,  0.4328,  ...,  0.4678,  0.4678,  0.4153],\n",
            "         [ 0.4853,  0.4328,  0.4328,  ...,  0.5378,  0.4853,  0.4503],\n",
            "         [ 0.4678,  0.4153,  0.3627,  ...,  0.5203,  0.4853,  0.4853]],\n",
            "\n",
            "        [[ 0.3045,  0.2871,  0.2696,  ..., -0.5844, -0.5844, -0.4973],\n",
            "         [ 0.4091,  0.2696,  0.1825,  ..., -0.5670, -0.6541, -0.6367],\n",
            "         [ 0.4265,  0.3219,  0.1999,  ..., -0.5670, -0.6367, -0.7587],\n",
            "         ...,\n",
            "         [ 0.1651,  0.1651,  0.1651,  ...,  0.1476,  0.1302,  0.0431],\n",
            "         [ 0.2696,  0.1999,  0.1825,  ...,  0.2173,  0.1999,  0.1302],\n",
            "         [ 0.1999,  0.1302,  0.0953,  ...,  0.2696,  0.2348,  0.2173]]]), tensor(0))\n",
            "Successfully unpacked batch 111\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 111\n",
            "\n",
            "Batch 112 type: <class 'tuple'>\n",
            "Batch 112 content: (tensor([[[-0.1828, -0.1486, -0.1486,  ...,  0.7933,  0.8276,  0.7933],\n",
            "         [-0.2171, -0.1486, -0.1657,  ...,  0.7077,  0.7248,  0.7933],\n",
            "         [-0.2684, -0.2171, -0.1828,  ...,  0.6392,  0.6563,  0.6563],\n",
            "         ...,\n",
            "         [-1.6727, -1.6213, -1.5870,  ...,  0.8961,  0.9817,  1.0673],\n",
            "         [-1.6898, -1.6384, -1.5870,  ...,  0.9646,  0.9988,  1.0331],\n",
            "         [-1.6555, -1.6727, -1.6555,  ...,  0.9646,  1.0159,  1.0159]],\n",
            "\n",
            "        [[-0.8452, -0.8452, -0.8803,  ..., -0.1975, -0.1975, -0.2675],\n",
            "         [-0.9153, -0.8277, -0.8277,  ..., -0.2325, -0.2500, -0.2150],\n",
            "         [-0.9853, -0.9153, -0.8277,  ..., -0.2675, -0.3025, -0.3550],\n",
            "         ...,\n",
            "         [-1.7556, -1.7381, -1.7206,  ..., -0.2325, -0.2325, -0.2325],\n",
            "         [-1.7381, -1.7381, -1.7206,  ..., -0.1625, -0.2150, -0.2500],\n",
            "         [-1.7031, -1.7381, -1.7556,  ..., -0.1800, -0.1800, -0.2325]],\n",
            "\n",
            "        [[-0.8458, -0.8458, -0.8633,  ..., -0.3927, -0.4101, -0.4624],\n",
            "         [-0.8633, -0.8110, -0.8284,  ..., -0.4450, -0.4798, -0.4275],\n",
            "         [-0.8981, -0.8633, -0.8284,  ..., -0.4973, -0.4973, -0.5321],\n",
            "         ...,\n",
            "         [-1.6476, -1.6127, -1.6127,  ..., -0.3753, -0.3927, -0.3927],\n",
            "         [-1.6302, -1.6127, -1.5953,  ..., -0.3230, -0.3753, -0.4101],\n",
            "         [-1.6127, -1.6302, -1.6476,  ..., -0.3753, -0.3578, -0.4101]]]), tensor(0))\n",
            "Successfully unpacked batch 112\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 112\n",
            "\n",
            "Batch 113 type: <class 'tuple'>\n",
            "Batch 113 content: (tensor([[[ 0.9646,  0.8447,  0.9303,  ...,  0.3309,  0.4508,  0.5022],\n",
            "         [ 1.0331,  0.8789,  0.8618,  ...,  0.0398,  0.1083,  0.2282],\n",
            "         [ 1.1015,  1.0159,  0.9646,  ...,  0.0569,  0.0741,  0.1083],\n",
            "         ...,\n",
            "         [ 1.8208,  1.8037,  1.8037,  ...,  2.0434,  2.0777,  2.1119],\n",
            "         [ 1.8550,  1.7865,  1.7865,  ...,  2.0092,  2.0263,  2.0605],\n",
            "         [ 1.9064,  1.8037,  1.7523,  ...,  1.9920,  1.9920,  2.0263]],\n",
            "\n",
            "        [[-0.1450, -0.2850, -0.2850,  ..., -0.5476, -0.4601, -0.4076],\n",
            "         [-0.0399, -0.2325, -0.2850,  ..., -0.8277, -0.7752, -0.6001],\n",
            "         [ 0.0301, -0.0924, -0.2150,  ..., -0.8627, -0.7577, -0.6352],\n",
            "         ...,\n",
            "         [ 0.6779,  0.6254,  0.5728,  ...,  0.8880,  0.9055,  0.9230],\n",
            "         [ 0.7129,  0.6078,  0.5903,  ...,  0.8354,  0.8354,  0.8529],\n",
            "         [ 0.7129,  0.6254,  0.5903,  ...,  0.8354,  0.8354,  0.8354]],\n",
            "\n",
            "        [[-0.4798, -0.6018, -0.5147,  ..., -0.7413, -0.6193, -0.5844],\n",
            "         [-0.3927, -0.5321, -0.5147,  ..., -1.0027, -1.0201, -0.8807],\n",
            "         [-0.2532, -0.3578, -0.4101,  ..., -1.0550, -1.0376, -0.9330],\n",
            "         ...,\n",
            "         [ 0.3045,  0.2522,  0.1825,  ...,  0.4614,  0.4614,  0.4788],\n",
            "         [ 0.3742,  0.2871,  0.2522,  ...,  0.3916,  0.3916,  0.4091],\n",
            "         [ 0.4091,  0.3045,  0.2522,  ...,  0.4091,  0.3742,  0.3742]]]), tensor(0))\n",
            "Successfully unpacked batch 113\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 113\n",
            "\n",
            "Batch 114 type: <class 'tuple'>\n",
            "Batch 114 content: (tensor([[[ 0.0741,  0.0227,  0.0227,  ..., -0.4568, -0.5082, -0.5596],\n",
            "         [ 0.0227, -0.0458, -0.0287,  ..., -0.4739, -0.5767, -0.6452],\n",
            "         [ 0.0741,  0.0227,  0.0227,  ..., -0.4226, -0.5253, -0.6109],\n",
            "         ...,\n",
            "         [ 0.1768,  0.2282,  0.1426,  ...,  0.1768,  0.1597,  0.2282],\n",
            "         [ 0.1768,  0.1939,  0.1083,  ...,  0.1597,  0.1426,  0.1939],\n",
            "         [ 0.2111,  0.1768,  0.0912,  ...,  0.2111,  0.1939,  0.1768]],\n",
            "\n",
            "        [[-0.1450, -0.1625, -0.1625,  ..., -0.5826, -0.6702, -0.7227],\n",
            "         [-0.1099, -0.1275, -0.0924,  ..., -0.6527, -0.7227, -0.7577],\n",
            "         [-0.1275, -0.1099, -0.0924,  ..., -0.6877, -0.7402, -0.7752],\n",
            "         ...,\n",
            "         [-0.0924, -0.0749, -0.1975,  ..., -0.1099, -0.0924, -0.0749],\n",
            "         [-0.1099, -0.1099, -0.2325,  ..., -0.0574, -0.0574, -0.0399],\n",
            "         [-0.1275, -0.1450, -0.2150,  ..., -0.0049, -0.0574, -0.0749]],\n",
            "\n",
            "        [[-0.1138, -0.0964, -0.0441,  ..., -0.4798, -0.5495, -0.6018],\n",
            "         [-0.0267, -0.0615, -0.0441,  ..., -0.4973, -0.5670, -0.6018],\n",
            "         [-0.0092, -0.0267, -0.0267,  ..., -0.4624, -0.5321, -0.5495],\n",
            "         ...,\n",
            "         [ 0.1476,  0.1825,  0.0431,  ...,  0.1825,  0.1825,  0.1999],\n",
            "         [ 0.0953,  0.0779, -0.0267,  ...,  0.2173,  0.1999,  0.2173],\n",
            "         [ 0.0779,  0.0605, -0.0092,  ...,  0.2522,  0.2173,  0.1999]]]), tensor(0))\n",
            "Successfully unpacked batch 114\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 114\n",
            "\n",
            "Batch 115 type: <class 'tuple'>\n",
            "Batch 115 content: (tensor([[[ 0.9132,  0.9817,  0.9817,  ...,  0.8276,  0.9132,  0.9132],\n",
            "         [ 0.9303,  1.0331,  1.0331,  ...,  0.8276,  0.8961,  0.8961],\n",
            "         [ 1.0159,  1.0331,  1.0844,  ...,  0.8276,  0.8447,  0.8789],\n",
            "         ...,\n",
            "         [ 1.0673,  0.9817,  0.9132,  ...,  1.3242,  1.2728,  1.2899],\n",
            "         [ 1.1015,  1.0502,  1.0159,  ...,  1.2899,  1.2728,  1.3070],\n",
            "         [ 1.1015,  1.1187,  1.1187,  ...,  1.2899,  1.2899,  1.2899]],\n",
            "\n",
            "        [[ 0.2752,  0.3277,  0.3102,  ..., -0.0049,  0.0651,  0.0476],\n",
            "         [ 0.2577,  0.3452,  0.3627,  ...,  0.0476,  0.0826,  0.0826],\n",
            "         [ 0.3102,  0.3452,  0.3978,  ...,  0.0301,  0.0301,  0.0826],\n",
            "         ...,\n",
            "         [ 0.3452,  0.2927,  0.2402,  ...,  0.3978,  0.3277,  0.3452],\n",
            "         [ 0.3452,  0.3102,  0.2752,  ...,  0.3627,  0.3452,  0.3627],\n",
            "         [ 0.2927,  0.3102,  0.3102,  ...,  0.3452,  0.3452,  0.3627]],\n",
            "\n",
            "        [[ 0.1128,  0.1651,  0.1999,  ...,  0.0256,  0.0953,  0.0779],\n",
            "         [ 0.0779,  0.1999,  0.2348,  ...,  0.0256,  0.0779,  0.0779],\n",
            "         [ 0.1302,  0.1999,  0.2696,  ..., -0.0441, -0.0441, -0.0092],\n",
            "         ...,\n",
            "         [-0.0267, -0.0615, -0.1138,  ..., -0.0441, -0.1487, -0.1487],\n",
            "         [ 0.0082, -0.0441, -0.0790,  ..., -0.0790, -0.1312, -0.1312],\n",
            "         [ 0.0431,  0.0605,  0.0082,  ..., -0.0790, -0.0964, -0.1312]]]), tensor(0))\n",
            "Successfully unpacked batch 115\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 115\n",
            "\n",
            "Batch 116 type: <class 'tuple'>\n",
            "Batch 116 content: (tensor([[[ 0.8276,  0.7591,  0.6563,  ...,  1.5810,  1.6153,  1.5982],\n",
            "         [ 0.7933,  0.7419,  0.6734,  ...,  1.5468,  1.5639,  1.5639],\n",
            "         [ 0.8104,  0.7591,  0.7077,  ...,  1.5297,  1.5468,  1.5639],\n",
            "         ...,\n",
            "         [ 1.9235,  1.9235,  1.9578,  ...,  2.1119,  2.1119,  2.1119],\n",
            "         [ 1.8893,  1.9064,  1.9749,  ...,  2.1290,  2.1119,  2.1119],\n",
            "         [ 1.9407,  1.9407,  1.9407,  ...,  2.1119,  2.1290,  2.0948]],\n",
            "\n",
            "        [[ 0.0126, -0.0224, -0.0574,  ...,  0.7129,  0.7654,  0.7304],\n",
            "         [-0.0574, -0.0574, -0.0749,  ...,  0.6954,  0.7129,  0.7129],\n",
            "         [-0.0924, -0.1099, -0.1275,  ...,  0.6604,  0.6429,  0.6429],\n",
            "         ...,\n",
            "         [ 0.8004,  0.8179,  0.8880,  ...,  1.0455,  1.0980,  1.1331],\n",
            "         [ 0.7479,  0.7654,  0.8529,  ...,  1.1155,  1.1155,  1.1155],\n",
            "         [ 0.7479,  0.7479,  0.8179,  ...,  1.1331,  1.1506,  1.0980]],\n",
            "\n",
            "        [[-0.0441, -0.1312, -0.2358,  ...,  0.2348,  0.2871,  0.2522],\n",
            "         [-0.1138, -0.1487, -0.2184,  ...,  0.2173,  0.2522,  0.2522],\n",
            "         [-0.1661, -0.1835, -0.2184,  ...,  0.1999,  0.2173,  0.2173],\n",
            "         ...,\n",
            "         [ 0.2173,  0.2173,  0.2871,  ...,  0.5485,  0.6008,  0.6182],\n",
            "         [ 0.2173,  0.1999,  0.2871,  ...,  0.6182,  0.6356,  0.6008],\n",
            "         [ 0.3045,  0.2871,  0.3219,  ...,  0.6182,  0.6356,  0.5834]]]), tensor(0))\n",
            "Successfully unpacked batch 116\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 116\n",
            "\n",
            "Batch 117 type: <class 'tuple'>\n",
            "Batch 117 content: (tensor([[[-1.7754, -1.7412, -1.7240,  ...,  1.1015,  1.1187,  1.1529],\n",
            "         [-1.7754, -1.7240, -1.6727,  ...,  1.0673,  1.1358,  1.1872],\n",
            "         [-1.8268, -1.7412, -1.6898,  ...,  1.0159,  1.0844,  1.1529],\n",
            "         ...,\n",
            "         [ 0.2624,  0.2796,  0.2624,  ...,  1.0159,  0.9817,  0.9817],\n",
            "         [ 0.1426,  0.1768,  0.2624,  ...,  0.9817,  0.9474,  0.9474],\n",
            "         [ 0.0569,  0.1083,  0.1939,  ...,  1.0159,  0.9646,  0.9646]],\n",
            "\n",
            "        [[-1.8256, -1.7906, -1.7206,  ..., -0.0224, -0.0399, -0.0399],\n",
            "         [-1.8256, -1.7906, -1.7381,  ..., -0.0224, -0.0049,  0.0126],\n",
            "         [-1.8431, -1.7731, -1.7381,  ..., -0.0399, -0.0399, -0.0399],\n",
            "         ...,\n",
            "         [-0.6176, -0.5826, -0.5126,  ..., -0.2325, -0.3025, -0.3550],\n",
            "         [-0.6176, -0.5826, -0.4951,  ..., -0.2150, -0.2850, -0.3200],\n",
            "         [-0.5651, -0.5301, -0.4601,  ..., -0.1800, -0.2850, -0.3025]],\n",
            "\n",
            "        [[-1.7173, -1.6999, -1.6824,  ..., -0.0441, -0.0790, -0.0964],\n",
            "         [-1.6999, -1.6650, -1.6127,  ..., -0.0790, -0.0441, -0.0441],\n",
            "         [-1.7173, -1.6824, -1.6476,  ..., -0.0964, -0.0790, -0.0964],\n",
            "         ...,\n",
            "         [-0.5844, -0.5147, -0.4624,  ..., -0.4973, -0.5147, -0.5495],\n",
            "         [-0.5844, -0.4973, -0.4275,  ..., -0.5495, -0.5844, -0.5844],\n",
            "         [-0.5844, -0.5321, -0.4275,  ..., -0.5147, -0.5844, -0.6018]]]), tensor(1))\n",
            "Successfully unpacked batch 117\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 117\n",
            "\n",
            "Batch 118 type: <class 'tuple'>\n",
            "Batch 118 content: (tensor([[[-1.5014, -1.4672, -1.4329,  ...,  0.5022,  0.4679,  0.3994],\n",
            "         [-1.5357, -1.5357, -1.5528,  ...,  0.4851,  0.4508,  0.4337],\n",
            "         [-1.5185, -1.5357, -1.5528,  ...,  0.4508,  0.3994,  0.3823],\n",
            "         ...,\n",
            "         [-0.1486, -0.1314,  0.0569,  ...,  0.9303,  0.8618,  0.8276],\n",
            "         [-0.0116, -0.0287,  0.1254,  ...,  0.9303,  0.8961,  0.8789],\n",
            "         [ 0.0912,  0.0741,  0.0912,  ...,  0.8961,  0.8961,  0.8789]],\n",
            "\n",
            "        [[-1.6856, -1.6506, -1.6331,  ..., -0.3200, -0.3725, -0.3901],\n",
            "         [-1.6681, -1.6681, -1.7206,  ..., -0.3725, -0.4076, -0.4076],\n",
            "         [-1.6331, -1.6506, -1.7031,  ..., -0.4251, -0.4426, -0.4426],\n",
            "         ...,\n",
            "         [-0.5651, -0.5301, -0.2675,  ...,  0.1352,  0.1001,  0.0826],\n",
            "         [-0.5301, -0.4951, -0.2325,  ...,  0.1176,  0.1176,  0.1176],\n",
            "         [-0.4776, -0.4601, -0.3375,  ...,  0.1001,  0.1001,  0.1352]],\n",
            "\n",
            "        [[-1.6302, -1.5779, -1.5081,  ..., -0.4624, -0.4798, -0.5321],\n",
            "         [-1.6650, -1.6302, -1.6302,  ..., -0.4798, -0.4798, -0.5321],\n",
            "         [-1.6302, -1.6302, -1.6650,  ..., -0.4973, -0.4973, -0.4973],\n",
            "         ...,\n",
            "         [-0.6541, -0.6018, -0.3404,  ..., -0.0615, -0.1312, -0.2010],\n",
            "         [-0.6018, -0.5844, -0.3578,  ..., -0.0267, -0.0964, -0.1661],\n",
            "         [-0.4798, -0.4798, -0.4101,  ..., -0.1312, -0.1661, -0.1661]]]), tensor(1))\n",
            "Successfully unpacked batch 118\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 118\n",
            "\n",
            "Batch 119 type: <class 'tuple'>\n",
            "Batch 119 content: (tensor([[[ 0.3994,  0.3823,  0.3481,  ...,  0.1083,  0.1083,  0.0912],\n",
            "         [ 0.4508,  0.4166,  0.3823,  ...,  0.0569,  0.0398,  0.0912],\n",
            "         [ 0.4166,  0.4166,  0.4337,  ...,  0.0569,  0.0569,  0.0912],\n",
            "         ...,\n",
            "         [ 0.3823,  0.3823,  0.3823,  ...,  0.0398,  0.1254,  0.1426],\n",
            "         [ 0.3994,  0.4166,  0.4166,  ..., -0.1828, -0.1143,  0.0398],\n",
            "         [ 0.4166,  0.4508,  0.4508,  ..., -0.2342, -0.3541, -0.2684]],\n",
            "\n",
            "        [[-0.1975, -0.2150, -0.2500,  ..., -0.4776, -0.4951, -0.5126],\n",
            "         [-0.1975, -0.1975, -0.2325,  ..., -0.4951, -0.5301, -0.4951],\n",
            "         [-0.2850, -0.2850, -0.2500,  ..., -0.4951, -0.5301, -0.4951],\n",
            "         ...,\n",
            "         [-0.2850, -0.2850, -0.2325,  ..., -0.2850, -0.1975, -0.2150],\n",
            "         [-0.2850, -0.2850, -0.2675,  ..., -0.4601, -0.4251, -0.3200],\n",
            "         [-0.2500, -0.2500, -0.2500,  ..., -0.4776, -0.6702, -0.6877]],\n",
            "\n",
            "        [[-0.2532, -0.2532, -0.2707,  ..., -0.4798, -0.4450, -0.4798],\n",
            "         [-0.2358, -0.2184, -0.2532,  ..., -0.4973, -0.4973, -0.4798],\n",
            "         [-0.2881, -0.2532, -0.2358,  ..., -0.5495, -0.5495, -0.5147],\n",
            "         ...,\n",
            "         [-0.3404, -0.3404, -0.2881,  ..., -0.0964,  0.0256,  0.0082],\n",
            "         [-0.3055, -0.2881, -0.2881,  ..., -0.2881, -0.2184, -0.0964],\n",
            "         [-0.2532, -0.2184, -0.2532,  ..., -0.3404, -0.4798, -0.4624]]]), tensor(1))\n",
            "Successfully unpacked batch 119\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 119\n",
            "\n",
            "Batch 120 type: <class 'tuple'>\n",
            "Batch 120 content: (tensor([[[ 0.2453,  0.1939,  0.1083,  ...,  0.5022,  0.5022,  0.4851],\n",
            "         [ 0.2967,  0.2453,  0.1426,  ...,  0.5022,  0.4679,  0.4679],\n",
            "         [ 0.3138,  0.2796,  0.1768,  ...,  0.5364,  0.5193,  0.5193],\n",
            "         ...,\n",
            "         [ 0.2453,  0.2624,  0.2796,  ...,  0.6049,  0.5878,  0.5707],\n",
            "         [ 0.2282,  0.1939,  0.1768,  ...,  0.5707,  0.5707,  0.5707],\n",
            "         [ 0.1426,  0.1426,  0.1254,  ...,  0.5364,  0.5536,  0.5193]],\n",
            "\n",
            "        [[-0.1800, -0.2500, -0.3725,  ..., -0.0049, -0.0574, -0.0924],\n",
            "         [-0.1625, -0.2850, -0.4251,  ...,  0.0126, -0.0574, -0.0749],\n",
            "         [-0.1975, -0.2675, -0.4251,  ..., -0.0399, -0.0924, -0.0749],\n",
            "         ...,\n",
            "         [-0.2850, -0.2850, -0.1975,  ..., -0.1625, -0.1275, -0.1275],\n",
            "         [-0.2500, -0.3025, -0.2850,  ..., -0.1450, -0.1275, -0.1099],\n",
            "         [-0.2675, -0.3025, -0.3375,  ..., -0.1450, -0.1800, -0.2150]],\n",
            "\n",
            "        [[-0.1661, -0.2532, -0.4101,  ..., -0.1138, -0.1661, -0.1835],\n",
            "         [-0.1661, -0.2881, -0.4624,  ..., -0.0790, -0.1487, -0.1835],\n",
            "         [-0.2184, -0.3230, -0.5147,  ..., -0.0092, -0.0790, -0.1138],\n",
            "         ...,\n",
            "         [-0.1312, -0.1487, -0.1138,  ..., -0.1661, -0.1661, -0.1835],\n",
            "         [-0.0441, -0.0964, -0.1138,  ..., -0.1835, -0.1487, -0.1487],\n",
            "         [-0.1138, -0.1312, -0.1835,  ..., -0.2010, -0.1835, -0.2184]]]), tensor(1))\n",
            "Successfully unpacked batch 120\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 120\n",
            "\n",
            "Batch 121 type: <class 'tuple'>\n",
            "Batch 121 content: (tensor([[[ 0.7077,  0.6906,  0.6734,  ...,  0.8789,  0.8789,  0.8961],\n",
            "         [ 0.7419,  0.6906,  0.6734,  ...,  0.8961,  0.8447,  0.8276],\n",
            "         [ 0.7591,  0.7077,  0.6734,  ...,  0.8961,  0.8618,  0.8104],\n",
            "         ...,\n",
            "         [ 0.8104,  0.7762,  0.7933,  ...,  0.6563,  0.6392,  0.6563],\n",
            "         [ 0.7933,  0.7419,  0.7248,  ...,  0.6563,  0.6392,  0.6734],\n",
            "         [ 0.7591,  0.7248,  0.7077,  ...,  0.7248,  0.6906,  0.6906]],\n",
            "\n",
            "        [[ 0.1176,  0.1001,  0.0826,  ..., -0.1450, -0.1450, -0.1275],\n",
            "         [ 0.1352,  0.0651,  0.0301,  ..., -0.1275, -0.1625, -0.1800],\n",
            "         [ 0.1527,  0.0476, -0.0049,  ..., -0.1275, -0.1450, -0.1800],\n",
            "         ...,\n",
            "         [ 0.0301, -0.0224, -0.0399,  ..., -0.4076, -0.4601, -0.4426],\n",
            "         [ 0.0826,  0.0301, -0.0224,  ..., -0.3375, -0.4076, -0.3901],\n",
            "         [ 0.1001,  0.0651,  0.0301,  ..., -0.2500, -0.3375, -0.3725]],\n",
            "\n",
            "        [[ 0.0779,  0.0605,  0.0779,  ..., -0.3753, -0.3404, -0.2881],\n",
            "         [ 0.1302,  0.0605,  0.0256,  ..., -0.3753, -0.3753, -0.3578],\n",
            "         [ 0.1128,  0.0431,  0.0082,  ..., -0.3753, -0.3753, -0.3927],\n",
            "         ...,\n",
            "         [-0.0441, -0.1312, -0.1835,  ..., -0.6367, -0.6541, -0.6367],\n",
            "         [-0.0615, -0.1312, -0.1487,  ..., -0.6193, -0.6715, -0.6367],\n",
            "         [-0.0441, -0.0790, -0.0790,  ..., -0.5670, -0.6193, -0.6367]]]), tensor(0))\n",
            "Successfully unpacked batch 121\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 121\n",
            "\n",
            "Batch 122 type: <class 'tuple'>\n",
            "Batch 122 content: (tensor([[[ 1.1872,  1.1872,  1.2214,  ...,  0.5022,  0.5536,  0.5536],\n",
            "         [ 1.1358,  1.1529,  1.2214,  ...,  0.4851,  0.5193,  0.5193],\n",
            "         [ 1.1358,  1.1872,  1.2728,  ...,  0.4337,  0.4679,  0.4508],\n",
            "         ...,\n",
            "         [ 1.5982,  1.5810,  1.5468,  ...,  0.8961,  0.9132,  0.8961],\n",
            "         [ 1.5810,  1.5982,  1.5468,  ...,  0.9474,  0.9132,  0.8961],\n",
            "         [ 1.5468,  1.5639,  1.5125,  ...,  0.8789,  0.8789,  0.8961]],\n",
            "\n",
            "        [[ 0.3627,  0.3277,  0.2927,  ..., -0.3200, -0.3200, -0.3375],\n",
            "         [ 0.3102,  0.2927,  0.3102,  ..., -0.3200, -0.3025, -0.3375],\n",
            "         [ 0.2752,  0.2927,  0.3627,  ..., -0.3375, -0.3025, -0.3375],\n",
            "         ...,\n",
            "         [ 0.5028,  0.4853,  0.4503,  ...,  0.0826,  0.1001,  0.0826],\n",
            "         [ 0.4678,  0.4678,  0.4328,  ...,  0.1527,  0.1176,  0.1001],\n",
            "         [ 0.4678,  0.5028,  0.4503,  ...,  0.1352,  0.1352,  0.1352]],\n",
            "\n",
            "        [[-0.0441, -0.0615, -0.0267,  ..., -0.6715, -0.6541, -0.6541],\n",
            "         [-0.0615, -0.0964, -0.0441,  ..., -0.5844, -0.5844, -0.6018],\n",
            "         [-0.0267, -0.0267,  0.0256,  ..., -0.6193, -0.5670, -0.5670],\n",
            "         ...,\n",
            "         [ 0.1999,  0.1999,  0.1999,  ..., -0.2184, -0.2184, -0.2532],\n",
            "         [ 0.2696,  0.2696,  0.2348,  ..., -0.1835, -0.2010, -0.2358],\n",
            "         [ 0.2173,  0.2348,  0.1999,  ..., -0.2358, -0.2532, -0.2707]]]), tensor(0))\n",
            "Successfully unpacked batch 122\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 122\n",
            "\n",
            "Batch 123 type: <class 'tuple'>\n",
            "Batch 123 content: (tensor([[[ 0.0912,  0.1426,  0.3138,  ..., -0.9020, -0.9192, -0.9020],\n",
            "         [ 0.2796,  0.3138,  0.4851,  ..., -0.9877, -1.0048, -0.9877],\n",
            "         [ 0.3309,  0.3823,  0.4508,  ..., -0.9705, -0.9877, -0.9705],\n",
            "         ...,\n",
            "         [-0.4739, -0.3712, -0.3712,  ..., -0.4568, -0.3883, -0.4226],\n",
            "         [-0.4054, -0.3369, -0.4397,  ..., -0.3541, -0.2513, -0.3369],\n",
            "         [-0.4054, -0.3712, -0.4054,  ..., -0.2856, -0.1999, -0.3027]],\n",
            "\n",
            "        [[ 0.2402,  0.2752,  0.5028,  ..., -1.3529, -1.4055, -1.4230],\n",
            "         [ 0.3978,  0.4503,  0.6779,  ..., -1.3529, -1.3880, -1.4230],\n",
            "         [ 0.4153,  0.4503,  0.5728,  ..., -1.3529, -1.3704, -1.3704],\n",
            "         ...,\n",
            "         [-0.6352, -0.5301, -0.5301,  ..., -0.9678, -0.8452, -0.8277],\n",
            "         [-0.5301, -0.4426, -0.5301,  ..., -0.8452, -0.7052, -0.7227],\n",
            "         [-0.4426, -0.4251, -0.4776,  ..., -0.6176, -0.4951, -0.5651]],\n",
            "\n",
            "        [[ 0.6879,  0.7576,  0.9668,  ..., -1.3687, -1.4559, -1.4733],\n",
            "         [ 0.8797,  0.9494,  1.1759,  ..., -1.3687, -1.4384, -1.4384],\n",
            "         [ 0.9145,  0.9668,  1.0714,  ..., -1.3687, -1.4036, -1.4036],\n",
            "         ...,\n",
            "         [-0.2184, -0.0964, -0.1487,  ..., -0.8110, -0.6890, -0.7064],\n",
            "         [-0.1138, -0.0441, -0.1661,  ..., -0.6018, -0.4624, -0.5147],\n",
            "         [-0.0964, -0.0964, -0.1312,  ..., -0.3753, -0.2707, -0.3578]]]), tensor(0))\n",
            "Successfully unpacked batch 123\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 123\n",
            "\n",
            "Batch 124 type: <class 'tuple'>\n",
            "Batch 124 content: (tensor([[[ 0.9646,  0.7933,  0.4679,  ...,  0.8276,  0.8789,  0.8618],\n",
            "         [ 1.0673,  0.6906,  0.2796,  ...,  0.9132,  0.8789,  0.8447],\n",
            "         [ 0.6221,  0.2453,  0.0912,  ...,  0.8961,  0.8618,  0.8789],\n",
            "         ...,\n",
            "         [ 1.4269,  1.4612,  1.4098,  ...,  1.5468,  1.4783,  1.4440],\n",
            "         [ 1.4269,  1.4440,  1.4440,  ...,  1.5297,  1.4954,  1.4783],\n",
            "         [ 1.4440,  1.4440,  1.4440,  ...,  1.4269,  1.4269,  1.4440]],\n",
            "\n",
            "        [[ 0.8354,  0.6078,  0.2577,  ...,  0.1176,  0.1702,  0.1527],\n",
            "         [ 0.9230,  0.5028,  0.0651,  ...,  0.1527,  0.1001,  0.0651],\n",
            "         [ 0.4853,  0.0651, -0.1099,  ...,  0.1352,  0.1001,  0.1001],\n",
            "         ...,\n",
            "         [ 1.3256,  1.3431,  1.3081,  ...,  0.7479,  0.6604,  0.5903],\n",
            "         [ 1.2556,  1.2556,  1.2731,  ...,  0.7479,  0.6954,  0.6604],\n",
            "         [ 1.1856,  1.1856,  1.2381,  ...,  0.6604,  0.6254,  0.6078]],\n",
            "\n",
            "        [[ 1.1237,  0.8622,  0.4614,  ...,  0.3045,  0.3568,  0.3742],\n",
            "         [ 1.2282,  0.7576,  0.2871,  ...,  0.3219,  0.2871,  0.2696],\n",
            "         [ 0.7925,  0.3393,  0.1476,  ...,  0.2871,  0.2522,  0.2696],\n",
            "         ...,\n",
            "         [ 1.6640,  1.6814,  1.6465,  ...,  1.0714,  1.0365,  0.9494],\n",
            "         [ 1.5594,  1.5768,  1.6117,  ...,  1.0714,  1.0539,  1.0191],\n",
            "         [ 1.4548,  1.4897,  1.5768,  ...,  0.9842,  0.9668,  0.9668]]]), tensor(1))\n",
            "Successfully unpacked batch 124\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 124\n",
            "\n",
            "Batch 125 type: <class 'tuple'>\n",
            "Batch 125 content: (tensor([[[1.2728, 1.2899, 1.3242,  ..., 1.5982, 1.6324, 1.6495],\n",
            "         [1.2728, 1.2899, 1.2728,  ..., 1.6153, 1.5982, 1.6153],\n",
            "         [1.3070, 1.3242, 1.2899,  ..., 1.5125, 1.5297, 1.5639],\n",
            "         ...,\n",
            "         [1.6324, 1.6495, 1.6667,  ..., 1.8037, 1.7865, 1.8037],\n",
            "         [1.6838, 1.6838, 1.6667,  ..., 1.8722, 1.8208, 1.8037],\n",
            "         [1.6667, 1.6838, 1.6838,  ..., 1.8722, 1.8550, 1.8550]],\n",
            "\n",
            "        [[0.9055, 0.9055, 0.8704,  ..., 1.3431, 1.3431, 1.3606],\n",
            "         [0.8704, 0.8704, 0.8179,  ..., 1.3081, 1.3256, 1.3431],\n",
            "         [0.9055, 0.8880, 0.8704,  ..., 1.1681, 1.2381, 1.2906],\n",
            "         ...,\n",
            "         [1.3431, 1.3431, 1.3256,  ..., 1.6232, 1.6232, 1.6057],\n",
            "         [1.3431, 1.3256, 1.3081,  ..., 1.6583, 1.6057, 1.5707],\n",
            "         [1.3081, 1.3256, 1.3256,  ..., 1.5707, 1.5532, 1.5707]],\n",
            "\n",
            "        [[1.0191, 1.0017, 0.9842,  ..., 1.5071, 1.5245, 1.5594],\n",
            "         [1.0539, 1.0191, 0.9668,  ..., 1.4722, 1.4722, 1.5071],\n",
            "         [1.0888, 1.0539, 1.0017,  ..., 1.3502, 1.4025, 1.4200],\n",
            "         ...,\n",
            "         [1.5594, 1.5942, 1.5942,  ..., 1.6988, 1.6814, 1.6814],\n",
            "         [1.5594, 1.5594, 1.5420,  ..., 1.7685, 1.7163, 1.6988],\n",
            "         [1.4897, 1.5245, 1.5420,  ..., 1.7337, 1.7163, 1.7163]]]), tensor(1))\n",
            "Successfully unpacked batch 125\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 125\n",
            "\n",
            "Batch 126 type: <class 'tuple'>\n",
            "Batch 126 content: (tensor([[[-0.3198, -0.2513, -0.1828,  ...,  0.7933,  0.7933,  0.7248],\n",
            "         [-0.1999, -0.1486, -0.0972,  ...,  0.7762,  0.8276,  0.7077],\n",
            "         [-0.0801, -0.0972, -0.1486,  ...,  0.8104,  0.8104,  0.6392],\n",
            "         ...,\n",
            "         [ 0.6049,  0.6392,  0.6734,  ...,  0.4166,  0.4337,  0.4679],\n",
            "         [ 0.6563,  0.6906,  0.6734,  ...,  0.3994,  0.4337,  0.4508],\n",
            "         [ 0.7419,  0.7077,  0.6563,  ...,  0.4508,  0.4679,  0.4337]],\n",
            "\n",
            "        [[-0.6527, -0.5126, -0.3725,  ...,  0.4678,  0.4678,  0.3627],\n",
            "         [-0.4951, -0.4251, -0.3200,  ...,  0.3978,  0.4503,  0.2927],\n",
            "         [-0.4251, -0.4251, -0.4951,  ...,  0.3627,  0.3452,  0.1702],\n",
            "         ...,\n",
            "         [ 0.2752,  0.3102,  0.3102,  ..., -0.1800, -0.1450, -0.0749],\n",
            "         [ 0.2577,  0.2752,  0.2577,  ..., -0.1975, -0.1450, -0.0924],\n",
            "         [ 0.2752,  0.2577,  0.2227,  ..., -0.2325, -0.1975, -0.1975]],\n",
            "\n",
            "        [[-0.4798, -0.3230, -0.2184,  ...,  0.4788,  0.4614,  0.3742],\n",
            "         [-0.3230, -0.2358, -0.1312,  ...,  0.4614,  0.4788,  0.3045],\n",
            "         [-0.2881, -0.2881, -0.3404,  ...,  0.4962,  0.4439,  0.2522],\n",
            "         ...,\n",
            "         [ 0.1302,  0.1825,  0.1999,  ..., -0.2010, -0.2358, -0.1835],\n",
            "         [ 0.1302,  0.1651,  0.1302,  ..., -0.1661, -0.1661, -0.1835],\n",
            "         [ 0.1999,  0.1651,  0.1128,  ..., -0.2010, -0.1661, -0.2010]]]), tensor(1))\n",
            "Successfully unpacked batch 126\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 126\n",
            "\n",
            "Batch 127 type: <class 'tuple'>\n",
            "Batch 127 content: (tensor([[[-0.9705, -0.9534, -0.9363,  ..., -0.2342, -0.1828, -0.1486],\n",
            "         [-0.9192, -0.9363, -0.8335,  ..., -0.2684, -0.2342, -0.1828],\n",
            "         [-0.5082, -0.5082, -0.5082,  ..., -0.2856, -0.2513, -0.1828],\n",
            "         ...,\n",
            "         [-0.0629, -0.0458, -0.0801,  ..., -0.5424, -0.5596, -0.5253],\n",
            "         [-0.0629, -0.0629, -0.0629,  ..., -0.4054, -0.5082, -0.5424],\n",
            "         [-0.0116,  0.0398, -0.0458,  ..., -0.3541, -0.4226, -0.3541]],\n",
            "\n",
            "        [[-1.1779, -1.1078, -1.0378,  ..., -0.3725, -0.3901, -0.3725],\n",
            "         [-1.1078, -1.0728, -0.9153,  ..., -0.4076, -0.4251, -0.3725],\n",
            "         [-0.7752, -0.6702, -0.6176,  ..., -0.4251, -0.4426, -0.4076],\n",
            "         ...,\n",
            "         [-0.4776, -0.4251, -0.3901,  ..., -0.8452, -0.7927, -0.7577],\n",
            "         [-0.4426, -0.4251, -0.3901,  ..., -0.7052, -0.7402, -0.7402],\n",
            "         [-0.3375, -0.2675, -0.3550,  ..., -0.6702, -0.6527, -0.5826]],\n",
            "\n",
            "        [[-1.0898, -1.0201, -0.9330,  ..., -0.2010, -0.2184, -0.2184],\n",
            "         [-1.0027, -0.9853, -0.8458,  ..., -0.2707, -0.2881, -0.2532],\n",
            "         [-0.6018, -0.5495, -0.4798,  ..., -0.2707, -0.3055, -0.2707],\n",
            "         ...,\n",
            "         [-0.4101, -0.3753, -0.3578,  ..., -0.5670, -0.4973, -0.4101],\n",
            "         [-0.3927, -0.3404, -0.2707,  ..., -0.4101, -0.4275, -0.3578],\n",
            "         [-0.3927, -0.3055, -0.3230,  ..., -0.3753, -0.3230, -0.2010]]]), tensor(2))\n",
            "Successfully unpacked batch 127\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 127\n",
            "\n",
            "Batch 128 type: <class 'tuple'>\n",
            "Batch 128 content: (tensor([[[ 0.5022,  0.5536,  0.6392,  ...,  0.9988,  0.9646,  0.9303],\n",
            "         [ 0.4508,  0.5022,  0.5364,  ...,  0.9646,  0.9303,  0.9303],\n",
            "         [ 0.4166,  0.4166,  0.4337,  ...,  0.9646,  0.9474,  0.9474],\n",
            "         ...,\n",
            "         [ 0.4508,  0.4337,  0.3823,  ...,  0.9817,  1.0159,  0.9817],\n",
            "         [ 0.4166,  0.3652,  0.3309,  ...,  0.9817,  1.0159,  1.0159],\n",
            "         [ 0.3994,  0.3994,  0.3994,  ...,  0.9988,  1.0502,  1.0502]],\n",
            "\n",
            "        [[-0.4951, -0.4426, -0.3550,  ...,  0.9230,  0.9055,  0.8880],\n",
            "         [-0.4251, -0.3725, -0.3550,  ...,  0.9055,  0.8880,  0.8880],\n",
            "         [-0.3725, -0.3725, -0.3901,  ...,  0.9230,  0.9055,  0.9230],\n",
            "         ...,\n",
            "         [-0.3901, -0.3901, -0.4776,  ...,  0.8704,  0.9055,  0.9230],\n",
            "         [-0.4426, -0.4776, -0.4951,  ...,  0.8704,  0.9055,  0.9405],\n",
            "         [-0.5476, -0.5826, -0.5301,  ...,  0.8529,  0.9230,  0.9405]],\n",
            "\n",
            "        [[-0.5670, -0.5147, -0.3927,  ...,  1.0888,  1.0714,  1.0539],\n",
            "         [-0.4973, -0.4275, -0.3927,  ...,  1.0714,  1.0539,  1.0365],\n",
            "         [-0.4624, -0.4101, -0.4275,  ...,  1.0714,  1.0539,  1.0539],\n",
            "         ...,\n",
            "         [-0.5670, -0.5321, -0.4973,  ...,  1.0017,  1.0191,  1.0365],\n",
            "         [-0.5495, -0.5844, -0.5321,  ...,  0.9842,  1.0017,  1.0365],\n",
            "         [-0.6367, -0.6367, -0.6018,  ...,  0.9494,  1.0017,  1.0017]]]), tensor(0))\n",
            "Successfully unpacked batch 128\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 128\n",
            "\n",
            "Batch 129 type: <class 'tuple'>\n",
            "Batch 129 content: (tensor([[[ 0.5878,  0.6734,  0.7077,  ...,  1.5639,  1.5639,  1.5468],\n",
            "         [ 0.6563,  0.6734,  0.6563,  ...,  1.5810,  1.5982,  1.5297],\n",
            "         [ 0.6392,  0.5193,  0.3994,  ...,  1.5810,  1.5810,  1.5639],\n",
            "         ...,\n",
            "         [ 1.1015,  1.1015,  1.1358,  ...,  1.0673,  1.0673,  1.0331],\n",
            "         [ 1.0844,  1.0673,  1.0844,  ...,  1.1015,  1.1187,  1.0844],\n",
            "         [ 1.1015,  1.0844,  1.1015,  ...,  1.1015,  1.0844,  1.1015]],\n",
            "\n",
            "        [[-0.3200, -0.1625, -0.1099,  ...,  0.8529,  0.8354,  0.7654],\n",
            "         [-0.3025, -0.2150, -0.1975,  ...,  0.8179,  0.8354,  0.7479],\n",
            "         [-0.3550, -0.4426, -0.5301,  ...,  0.7654,  0.8179,  0.7829],\n",
            "         ...,\n",
            "         [ 0.2227,  0.2227,  0.2052,  ..., -0.0749, -0.0224, -0.0399],\n",
            "         [ 0.2052,  0.1877,  0.2052,  ..., -0.0224,  0.0126, -0.0049],\n",
            "         [ 0.1702,  0.1702,  0.2227,  ...,  0.0126,  0.0301,  0.0301]],\n",
            "\n",
            "        [[-0.7413, -0.5670, -0.4798,  ...,  0.4091,  0.4091,  0.3742],\n",
            "         [-0.6890, -0.5844, -0.5495,  ...,  0.4439,  0.4614,  0.3916],\n",
            "         [-0.7238, -0.7761, -0.8458,  ...,  0.4788,  0.5136,  0.4614],\n",
            "         ...,\n",
            "         [-0.2010, -0.1661, -0.1312,  ..., -0.3404, -0.2881, -0.3055],\n",
            "         [-0.1835, -0.2010, -0.1487,  ..., -0.2707, -0.2010, -0.2358],\n",
            "         [-0.1835, -0.1835, -0.1487,  ..., -0.3404, -0.2881, -0.2707]]]), tensor(1))\n",
            "Successfully unpacked batch 129\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 129\n",
            "\n",
            "Batch 130 type: <class 'tuple'>\n",
            "Batch 130 content: (tensor([[[ 0.5536,  0.3994,  0.3309,  ...,  0.8789,  0.7762,  0.7419],\n",
            "         [ 0.0741,  0.1768,  0.2967,  ...,  0.8618,  0.7762,  0.7419],\n",
            "         [ 0.0569,  0.1426,  0.2282,  ...,  0.8447,  0.7933,  0.8276],\n",
            "         ...,\n",
            "         [ 0.7248,  0.7591,  0.7419,  ...,  1.0159,  0.9474,  1.0331],\n",
            "         [ 0.7419,  0.7419,  0.7077,  ...,  0.9646,  0.9474,  1.0502],\n",
            "         [ 0.7933,  0.7248,  0.6906,  ...,  1.0502,  1.0159,  1.0844]],\n",
            "\n",
            "        [[-0.2850, -0.4426, -0.5126,  ...,  0.1702,  0.0476, -0.0224],\n",
            "         [-0.7227, -0.6527, -0.5476,  ...,  0.2052,  0.0651, -0.0399],\n",
            "         [-0.7402, -0.6702, -0.6352,  ...,  0.1702,  0.0651,  0.0301],\n",
            "         ...,\n",
            "         [-0.1800, -0.1450, -0.1625,  ..., -0.0749, -0.1450, -0.0749],\n",
            "         [-0.1625, -0.1800, -0.1975,  ..., -0.0924, -0.1450, -0.0924],\n",
            "         [-0.1450, -0.1975, -0.2150,  ..., -0.0574, -0.1275, -0.0749]],\n",
            "\n",
            "        [[-0.6193, -0.7587, -0.8110,  ..., -0.0964, -0.2532, -0.3404],\n",
            "         [-1.0201, -0.9156, -0.7761,  ..., -0.1312, -0.2707, -0.3404],\n",
            "         [-1.0027, -0.9504, -0.8981,  ..., -0.1835, -0.2532, -0.2184],\n",
            "         ...,\n",
            "         [-0.5147, -0.4798, -0.5321,  ..., -0.5844, -0.6367, -0.5495],\n",
            "         [-0.4973, -0.4973, -0.5495,  ..., -0.6018, -0.6541, -0.5670],\n",
            "         [-0.5147, -0.5147, -0.5321,  ..., -0.5321, -0.5670, -0.4798]]]), tensor(0))\n",
            "Successfully unpacked batch 130\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 130\n",
            "\n",
            "Batch 131 type: <class 'tuple'>\n",
            "Batch 131 content: (tensor([[[-0.3369, -0.6965, -0.6452,  ...,  1.3755,  1.5639,  1.6667],\n",
            "         [-0.4054, -0.7650, -0.8164,  ...,  1.3413,  1.4440,  1.6324],\n",
            "         [-0.5082, -0.8849, -1.1418,  ...,  1.4440,  1.3927,  1.5810],\n",
            "         ...,\n",
            "         [ 1.8379,  1.8208,  1.7694,  ...,  1.7694,  1.7865,  1.8379],\n",
            "         [ 1.8208,  1.7694,  1.7352,  ...,  1.7865,  1.7009,  1.7694],\n",
            "         [ 1.8037,  1.7523,  1.7352,  ...,  1.8893,  1.8550,  1.8037]],\n",
            "\n",
            "        [[-0.5651, -0.9853, -0.9853,  ...,  0.7304,  0.9230,  1.0105],\n",
            "         [-0.6527, -1.0378, -1.0903,  ...,  0.6779,  0.7829,  0.9755],\n",
            "         [-0.8452, -1.1954, -1.4230,  ...,  0.7829,  0.7304,  0.9230],\n",
            "         ...,\n",
            "         [ 1.0105,  1.0105,  1.0280,  ...,  1.1856,  1.2031,  1.2206],\n",
            "         [ 1.0455,  1.0455,  1.0455,  ...,  1.1856,  1.0805,  1.1331],\n",
            "         [ 1.0630,  1.0280,  1.0630,  ...,  1.2906,  1.2556,  1.1856]],\n",
            "\n",
            "        [[-0.5844, -0.9330, -0.9330,  ...,  0.5311,  0.7054,  0.7925],\n",
            "         [-0.6715, -1.0201, -1.0550,  ...,  0.4091,  0.4962,  0.6705],\n",
            "         [-0.8284, -1.1770, -1.3861,  ...,  0.5485,  0.4614,  0.6356],\n",
            "         ...,\n",
            "         [ 0.9319,  0.9145,  0.8797,  ...,  0.9842,  1.0017,  1.0191],\n",
            "         [ 0.9145,  0.8797,  0.8448,  ...,  1.0017,  0.8797,  0.9494],\n",
            "         [ 0.8971,  0.8797,  0.8797,  ...,  1.0714,  1.0365,  0.9842]]]), tensor(0))\n",
            "Successfully unpacked batch 131\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 131\n",
            "\n",
            "Batch 132 type: <class 'tuple'>\n",
            "Batch 132 content: (tensor([[[-0.0287,  0.0741,  0.1083,  ...,  0.2967,  0.3994,  0.4166],\n",
            "         [-0.1999, -0.0972,  0.0398,  ...,  0.3652,  0.4166,  0.4679],\n",
            "         [-0.2513, -0.0801,  0.0398,  ...,  0.4679,  0.4679,  0.5193],\n",
            "         ...,\n",
            "         [ 0.5193,  0.5536,  0.6906,  ...,  0.4337,  0.4508,  0.4508],\n",
            "         [ 0.6906,  0.7248,  0.8276,  ...,  0.4851,  0.5193,  0.4679],\n",
            "         [ 0.7762,  0.7248,  0.7419,  ...,  0.4508,  0.4679,  0.4337]],\n",
            "\n",
            "        [[-0.1625, -0.0924, -0.0399,  ..., -0.5301, -0.4601, -0.3901],\n",
            "         [-0.3025, -0.1975, -0.0574,  ..., -0.4776, -0.4601, -0.3901],\n",
            "         [-0.3025, -0.1450, -0.0049,  ..., -0.3725, -0.4076, -0.3550],\n",
            "         ...,\n",
            "         [ 0.6078,  0.6078,  0.7129,  ..., -0.5301, -0.5476, -0.5126],\n",
            "         [ 0.7129,  0.7304,  0.8004,  ..., -0.4776, -0.5301, -0.5476],\n",
            "         [ 0.7479,  0.6779,  0.6954,  ..., -0.4076, -0.4426, -0.4776]],\n",
            "\n",
            "        [[ 0.0082,  0.1128,  0.1651,  ..., -0.6541, -0.5147, -0.4450],\n",
            "         [-0.0615,  0.0431,  0.1825,  ..., -0.4973, -0.4275, -0.3404],\n",
            "         [-0.0615,  0.0953,  0.2522,  ..., -0.2707, -0.2881, -0.2881],\n",
            "         ...,\n",
            "         [ 0.8797,  0.9145,  1.0539,  ..., -0.2532, -0.3055, -0.2881],\n",
            "         [ 1.0191,  1.0365,  1.1237,  ..., -0.2184, -0.2707, -0.3230],\n",
            "         [ 1.0539,  1.0017,  1.0191,  ..., -0.2184, -0.2707, -0.3404]]]), tensor(2))\n",
            "Successfully unpacked batch 132\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 132\n",
            "\n",
            "Batch 133 type: <class 'tuple'>\n",
            "Batch 133 content: (tensor([[[ 0.2282,  0.1939,  0.2111,  ...,  0.0227, -0.0287, -0.0972],\n",
            "         [ 0.2282,  0.1939,  0.2111,  ...,  0.1768,  0.1254,  0.0741],\n",
            "         [ 0.2282,  0.2111,  0.2111,  ...,  0.2282,  0.1254,  0.0741],\n",
            "         ...,\n",
            "         [ 1.7865,  1.7694,  1.7523,  ...,  1.9578,  1.9235,  1.9407],\n",
            "         [ 1.7865,  1.7694,  1.7352,  ...,  1.9749,  1.9407,  1.9407],\n",
            "         [ 1.8550,  1.7865,  1.7352,  ...,  1.9920,  1.9578,  1.9407]],\n",
            "\n",
            "        [[-0.4951, -0.4951, -0.4601,  ..., -0.7052, -0.7577, -0.8452],\n",
            "         [-0.5126, -0.5301, -0.4951,  ..., -0.5476, -0.6176, -0.7052],\n",
            "         [-0.5126, -0.5476, -0.5126,  ..., -0.5126, -0.6176, -0.6877],\n",
            "         ...,\n",
            "         [ 0.6429,  0.6078,  0.5728,  ...,  0.9755,  0.9580,  0.9405],\n",
            "         [ 0.6779,  0.6254,  0.5903,  ...,  0.9930,  0.9755,  0.9580],\n",
            "         [ 0.6779,  0.6078,  0.6078,  ...,  0.9405,  0.9580,  0.9405]],\n",
            "\n",
            "        [[-0.5844, -0.6367, -0.6367,  ..., -0.8981, -0.9504, -1.0724],\n",
            "         [-0.6367, -0.6541, -0.6018,  ..., -0.7413, -0.8284, -0.9330],\n",
            "         [-0.6715, -0.6541, -0.6018,  ..., -0.6541, -0.8110, -0.9330],\n",
            "         ...,\n",
            "         [ 0.1999,  0.1302,  0.1128,  ...,  0.3393,  0.3219,  0.3393],\n",
            "         [ 0.2522,  0.1825,  0.1302,  ...,  0.3568,  0.3393,  0.3393],\n",
            "         [ 0.2696,  0.1651,  0.1302,  ...,  0.3742,  0.3742,  0.3568]]]), tensor(2))\n",
            "Successfully unpacked batch 133\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 133\n",
            "\n",
            "Batch 134 type: <class 'tuple'>\n",
            "Batch 134 content: (tensor([[[-0.3369, -0.4226, -0.5082,  ...,  0.1939,  0.4679,  0.5878],\n",
            "         [-0.4568, -0.5253, -0.5767,  ...,  0.6906,  0.6906,  0.6906],\n",
            "         [-0.4911, -0.5082, -0.5082,  ...,  0.7248,  0.5193,  0.4166],\n",
            "         ...,\n",
            "         [-0.7137, -0.6965, -0.6109,  ...,  0.9988,  0.9817,  1.0159],\n",
            "         [-0.6452, -0.6794, -0.6452,  ...,  1.0844,  1.0331,  1.0502],\n",
            "         [-0.6794, -0.7308, -0.7137,  ...,  1.1015,  1.1015,  1.1187]],\n",
            "\n",
            "        [[-0.5476, -0.5651, -0.6527,  ...,  0.1001,  0.3102,  0.3978],\n",
            "         [-0.6702, -0.7227, -0.7752,  ...,  0.6254,  0.5553,  0.5028],\n",
            "         [-0.7577, -0.7577, -0.7752,  ...,  0.7479,  0.4503,  0.3277],\n",
            "         ...,\n",
            "         [-0.9678, -0.9503, -0.8452,  ...,  0.6779,  0.6604,  0.6954],\n",
            "         [-0.9853, -1.0028, -0.9503,  ...,  0.7654,  0.7304,  0.7654],\n",
            "         [-1.0028, -1.0378, -1.0728,  ...,  0.7829,  0.8004,  0.8529]],\n",
            "\n",
            "        [[-0.4275, -0.5147, -0.6018,  ...,  0.2173,  0.4614,  0.5485],\n",
            "         [-0.6541, -0.6890, -0.7238,  ...,  0.6879,  0.6008,  0.5659],\n",
            "         [-0.8110, -0.8110, -0.8110,  ...,  0.8448,  0.5485,  0.4091],\n",
            "         ...,\n",
            "         [-0.8981, -0.8458, -0.7761,  ...,  0.7576,  0.7576,  0.8448],\n",
            "         [-0.8807, -0.8633, -0.7936,  ...,  0.8448,  0.8448,  0.9145],\n",
            "         [-0.8807, -0.9156, -0.8807,  ...,  0.8797,  0.9494,  1.0191]]]), tensor(0))\n",
            "Successfully unpacked batch 134\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 134\n",
            "\n",
            "Batch 135 type: <class 'tuple'>\n",
            "Batch 135 content: (tensor([[[-0.0458, -0.0629, -0.1314,  ..., -0.7822, -0.6452, -0.4911],\n",
            "         [-0.0629, -0.0458, -0.0972,  ..., -0.9363, -0.7308, -0.5424],\n",
            "         [-0.0458,  0.0056,  0.0398,  ..., -1.0390, -0.8849, -0.6965],\n",
            "         ...,\n",
            "         [ 0.1597,  0.1597,  0.1083,  ..., -0.1657, -0.0801, -0.0629],\n",
            "         [ 0.2111,  0.2282,  0.1939,  ..., -0.1314,  0.0056,  0.0569],\n",
            "         [ 0.2111,  0.2453,  0.2282,  ..., -0.1314, -0.0287,  0.0056]],\n",
            "\n",
            "        [[-0.4251, -0.4426, -0.5126,  ..., -1.1954, -1.0378, -0.8978],\n",
            "         [-0.4776, -0.4601, -0.4951,  ..., -1.2829, -1.0903, -0.8978],\n",
            "         [-0.4951, -0.4426, -0.4251,  ..., -1.3529, -1.1954, -0.9678],\n",
            "         ...,\n",
            "         [-0.3901, -0.3725, -0.3725,  ..., -0.3725, -0.3200, -0.3375],\n",
            "         [-0.3725, -0.3375, -0.3200,  ..., -0.3200, -0.1800, -0.1625],\n",
            "         [-0.3200, -0.3025, -0.3200,  ..., -0.3025, -0.1800, -0.1800]],\n",
            "\n",
            "        [[-0.3578, -0.3927, -0.4624,  ..., -1.0027, -0.8807, -0.7761],\n",
            "         [-0.4275, -0.4101, -0.4275,  ..., -1.0550, -0.8981, -0.7413],\n",
            "         [-0.4450, -0.4275, -0.4101,  ..., -1.1770, -1.0201, -0.8110],\n",
            "         ...,\n",
            "         [-0.3230, -0.2707, -0.2707,  ..., -0.1138, -0.0441, -0.0615],\n",
            "         [-0.3230, -0.2707, -0.2707,  ..., -0.0441,  0.0953,  0.1128],\n",
            "         [-0.2532, -0.2184, -0.2707,  ..., -0.0441,  0.0779,  0.0779]]]), tensor(0))\n",
            "Successfully unpacked batch 135\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 135\n",
            "\n",
            "Batch 136 type: <class 'tuple'>\n",
            "Batch 136 content: (tensor([[[ 1.5639,  1.5639,  1.5639,  ..., -1.4672, -1.3815, -1.3815],\n",
            "         [ 1.5810,  1.5639,  1.5468,  ..., -1.3987, -1.3473, -1.3473],\n",
            "         [ 1.4954,  1.4954,  1.5125,  ..., -1.4500, -1.3987, -1.3815],\n",
            "         ...,\n",
            "         [ 1.6838,  1.6667,  1.6324,  ...,  1.2385,  1.3242,  1.3755],\n",
            "         [ 1.7180,  1.6667,  1.6324,  ...,  1.3242,  1.3755,  1.4269],\n",
            "         [ 1.7523,  1.7180,  1.7180,  ...,  1.3070,  1.3927,  1.4612]],\n",
            "\n",
            "        [[ 0.6429,  0.6954,  0.6779,  ..., -1.6331, -1.5980, -1.6155],\n",
            "         [ 0.6429,  0.6604,  0.6604,  ..., -1.5980, -1.5980, -1.5980],\n",
            "         [ 0.5903,  0.6254,  0.6779,  ..., -1.6681, -1.6331, -1.6155],\n",
            "         ...,\n",
            "         [ 0.7654,  0.7654,  0.7129,  ...,  0.2927,  0.2577,  0.2227],\n",
            "         [ 0.7129,  0.7129,  0.6254,  ...,  0.3627,  0.3102,  0.2927],\n",
            "         [ 0.7304,  0.7129,  0.7129,  ...,  0.3803,  0.3803,  0.3978]],\n",
            "\n",
            "        [[ 0.5834,  0.6182,  0.6356,  ..., -1.6476, -1.5953, -1.5953],\n",
            "         [ 0.5136,  0.5485,  0.6008,  ..., -1.5953, -1.5430, -1.5081],\n",
            "         [ 0.4265,  0.5136,  0.6008,  ..., -1.5256, -1.4907, -1.5081],\n",
            "         ...,\n",
            "         [ 0.7402,  0.7054,  0.6182,  ...,  0.2173,  0.1476,  0.0953],\n",
            "         [ 0.7228,  0.6531,  0.5659,  ...,  0.2696,  0.1825,  0.1476],\n",
            "         [ 0.7402,  0.6879,  0.6356,  ...,  0.2522,  0.2348,  0.2348]]]), tensor(0))\n",
            "Successfully unpacked batch 136\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 136\n",
            "\n",
            "Batch 137 type: <class 'tuple'>\n",
            "Batch 137 content: (tensor([[[-0.9705, -0.7822, -0.5082,  ...,  1.2557,  1.1700,  1.2385],\n",
            "         [-0.9705, -0.8164, -0.5938,  ...,  1.2557,  1.2728,  1.2899],\n",
            "         [-1.0562, -0.8335, -0.5424,  ...,  1.3070,  1.3242,  1.3070],\n",
            "         ...,\n",
            "         [ 0.3994,  0.4508,  0.4679,  ...,  1.9235,  1.9235,  1.9064],\n",
            "         [ 0.4679,  0.5193,  0.5022,  ...,  1.9064,  1.8722,  1.8722],\n",
            "         [ 0.5364,  0.5536,  0.5536,  ...,  1.8893,  1.8893,  1.8893]],\n",
            "\n",
            "        [[-1.1954, -0.9853, -0.7402,  ...,  0.3627,  0.2402,  0.2577],\n",
            "         [-1.1779, -1.0203, -0.7752,  ...,  0.2927,  0.2752,  0.2577],\n",
            "         [-1.2129, -1.0028, -0.7752,  ...,  0.3277,  0.3102,  0.2927],\n",
            "         ...,\n",
            "         [-0.3375, -0.2850, -0.2850,  ...,  0.6078,  0.6078,  0.6078],\n",
            "         [-0.2500, -0.2150, -0.2850,  ...,  0.6429,  0.6429,  0.6429],\n",
            "         [-0.1099, -0.1099, -0.1450,  ...,  0.6779,  0.6779,  0.6604]],\n",
            "\n",
            "        [[-1.1944, -1.0376, -0.8110,  ...,  0.0256, -0.0790,  0.0082],\n",
            "         [-1.1596, -1.0201, -0.8458,  ...,  0.0605,  0.0605,  0.0605],\n",
            "         [-1.1944, -1.0201, -0.8110,  ...,  0.0779,  0.0953,  0.0779],\n",
            "         ...,\n",
            "         [-0.5321, -0.5147, -0.5321,  ...,  0.3742,  0.3916,  0.3916],\n",
            "         [-0.4450, -0.4101, -0.4624,  ...,  0.3742,  0.4091,  0.4265],\n",
            "         [-0.3404, -0.3230, -0.3230,  ...,  0.3742,  0.4614,  0.4614]]]), tensor(0))\n",
            "Successfully unpacked batch 137\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 137\n",
            "\n",
            "Batch 138 type: <class 'tuple'>\n",
            "Batch 138 content: (tensor([[[2.2489, 2.2489, 2.2489,  ..., 1.8379, 1.8379, 1.7694],\n",
            "         [2.2489, 2.2489, 2.2489,  ..., 1.8037, 1.8208, 1.8208],\n",
            "         [2.2489, 2.2489, 2.2489,  ..., 1.8208, 1.8893, 1.9407],\n",
            "         ...,\n",
            "         [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
            "         [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
            "         [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
            "\n",
            "        [[1.1155, 1.1681, 1.1856,  ..., 0.5903, 0.6078, 0.5378],\n",
            "         [1.0980, 1.1155, 1.1681,  ..., 0.5028, 0.5728, 0.6078],\n",
            "         [1.0980, 1.1155, 1.1155,  ..., 0.5378, 0.6604, 0.7829],\n",
            "         ...,\n",
            "         [1.1856, 1.1155, 1.0280,  ..., 1.0455, 1.0980, 1.0980],\n",
            "         [1.2206, 1.2206, 1.1856,  ..., 1.0105, 1.1155, 1.1155],\n",
            "         [1.2206, 1.2206, 1.1506,  ..., 1.0105, 1.0630, 1.0805]],\n",
            "\n",
            "        [[0.4962, 0.5485, 0.5311,  ..., 0.2348, 0.2522, 0.2348],\n",
            "         [0.4962, 0.4962, 0.5136,  ..., 0.1651, 0.2173, 0.2522],\n",
            "         [0.4962, 0.4788, 0.4614,  ..., 0.1825, 0.3393, 0.4439],\n",
            "         ...,\n",
            "         [0.4962, 0.4439, 0.3916,  ..., 0.3742, 0.3742, 0.3742],\n",
            "         [0.5485, 0.5485, 0.5136,  ..., 0.3045, 0.3742, 0.3916],\n",
            "         [0.5485, 0.5136, 0.4439,  ..., 0.3045, 0.3393, 0.3568]]]), tensor(0))\n",
            "Successfully unpacked batch 138\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 138\n",
            "\n",
            "Batch 139 type: <class 'tuple'>\n",
            "Batch 139 content: (tensor([[[ 1.3070,  1.2728,  1.2385,  ...,  1.3413,  1.4612,  1.4954],\n",
            "         [ 1.3584,  1.2899,  1.2214,  ...,  1.5810,  1.6667,  1.6667],\n",
            "         [ 1.3584,  1.3242,  1.2728,  ...,  1.9578,  2.0092,  1.9578],\n",
            "         ...,\n",
            "         [ 1.9578,  1.9920,  2.0263,  ...,  1.9407,  1.8893,  1.8722],\n",
            "         [ 1.9578,  1.9749,  1.9407,  ...,  1.8893,  1.8379,  1.8550],\n",
            "         [ 1.9749,  1.9920,  1.9578,  ...,  1.8550,  1.8722,  1.9235]],\n",
            "\n",
            "        [[ 0.3102,  0.2577,  0.2402,  ...,  0.6779,  0.7829,  0.8004],\n",
            "         [ 0.2752,  0.2227,  0.1702,  ...,  0.8529,  0.9405,  0.9580],\n",
            "         [ 0.2752,  0.2577,  0.2227,  ...,  1.2206,  1.3081,  1.3081],\n",
            "         ...,\n",
            "         [ 1.4132,  1.4657,  1.4657,  ...,  1.4832,  1.4482,  1.4132],\n",
            "         [ 1.3782,  1.4132,  1.3782,  ...,  1.4657,  1.3957,  1.3957],\n",
            "         [ 1.3256,  1.3782,  1.3606,  ...,  1.3782,  1.3606,  1.3957]],\n",
            "\n",
            "        [[ 0.0953,  0.0082, -0.0615,  ...,  0.5136,  0.6182,  0.6531],\n",
            "         [ 0.0431, -0.0615, -0.1661,  ...,  0.7228,  0.8274,  0.8448],\n",
            "         [-0.0267, -0.0790, -0.1487,  ...,  1.1062,  1.1934,  1.1411],\n",
            "         ...,\n",
            "         [ 1.0888,  1.1411,  1.2282,  ...,  1.1934,  1.0714,  0.9842],\n",
            "         [ 1.0539,  1.1237,  1.1237,  ...,  1.1585,  1.0191,  0.9842],\n",
            "         [ 1.0539,  1.1062,  1.1062,  ...,  1.0539,  1.0539,  1.0888]]]), tensor(0))\n",
            "Successfully unpacked batch 139\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 139\n",
            "\n",
            "Batch 140 type: <class 'tuple'>\n",
            "Batch 140 content: (tensor([[[ 1.1872,  1.1872,  1.1700,  ...,  1.1872,  1.2385,  1.2557],\n",
            "         [ 1.2385,  1.2385,  1.1872,  ...,  1.2043,  1.2214,  1.2385],\n",
            "         [ 1.2728,  1.2557,  1.2214,  ...,  1.2043,  1.2385,  1.2728],\n",
            "         ...,\n",
            "         [ 1.4098,  1.4269,  1.4269,  ...,  1.3584,  1.3242,  1.3413],\n",
            "         [ 1.3927,  1.3927,  1.4440,  ...,  1.3755,  1.3755,  1.3927],\n",
            "         [ 1.3927,  1.4098,  1.4612,  ...,  1.4269,  1.4440,  1.4440]],\n",
            "\n",
            "        [[ 0.5728,  0.5728,  0.5903,  ...,  0.6604,  0.7129,  0.7304],\n",
            "         [ 0.5728,  0.6254,  0.6254,  ...,  0.6779,  0.6779,  0.6779],\n",
            "         [ 0.5553,  0.5903,  0.5903,  ...,  0.6604,  0.6779,  0.6604],\n",
            "         ...,\n",
            "         [ 0.7304,  0.7129,  0.7129,  ...,  0.4678,  0.4328,  0.4503],\n",
            "         [ 0.7654,  0.7304,  0.7654,  ...,  0.4678,  0.4678,  0.4853],\n",
            "         [ 0.7654,  0.7654,  0.7479,  ...,  0.4153,  0.4503,  0.4853]],\n",
            "\n",
            "        [[ 0.5485,  0.5659,  0.5659,  ...,  0.6356,  0.6879,  0.6879],\n",
            "         [ 0.5485,  0.5834,  0.5659,  ...,  0.6879,  0.6879,  0.6879],\n",
            "         [ 0.5659,  0.5834,  0.5834,  ...,  0.6705,  0.6879,  0.6879],\n",
            "         ...,\n",
            "         [ 0.4788,  0.4614,  0.4439,  ...,  0.0256,  0.0082,  0.0256],\n",
            "         [ 0.4788,  0.4265,  0.4439,  ..., -0.0092,  0.0082,  0.0256],\n",
            "         [ 0.4091,  0.3742,  0.3742,  ...,  0.0256,  0.0605,  0.0779]]]), tensor(1))\n",
            "Successfully unpacked batch 140\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 140\n",
            "\n",
            "Batch 141 type: <class 'tuple'>\n",
            "Batch 141 content: (tensor([[[1.1015, 1.0673, 1.0502,  ..., 1.0844, 1.1529, 1.1700],\n",
            "         [1.1529, 1.1187, 1.1700,  ..., 1.0844, 1.1015, 1.1015],\n",
            "         [1.2043, 1.1700, 1.1700,  ..., 1.0844, 1.1015, 1.0844],\n",
            "         ...,\n",
            "         [1.6667, 1.6838, 1.6667,  ..., 1.4269, 1.4269, 1.4098],\n",
            "         [1.6667, 1.6838, 1.6495,  ..., 1.4269, 1.4269, 1.4269],\n",
            "         [1.5982, 1.6495, 1.6667,  ..., 1.3927, 1.4269, 1.4269]],\n",
            "\n",
            "        [[0.6429, 0.5903, 0.5378,  ..., 0.5903, 0.6954, 0.7304],\n",
            "         [0.6078, 0.5728, 0.5903,  ..., 0.6254, 0.6954, 0.7479],\n",
            "         [0.6254, 0.5728, 0.5728,  ..., 0.6604, 0.6779, 0.6604],\n",
            "         ...,\n",
            "         [0.7304, 0.7304, 0.7479,  ..., 0.7304, 0.7129, 0.6779],\n",
            "         [0.7129, 0.7129, 0.7129,  ..., 0.7479, 0.7304, 0.7129],\n",
            "         [0.6604, 0.6954, 0.6954,  ..., 0.6954, 0.7129, 0.7129]],\n",
            "\n",
            "        [[0.5485, 0.5311, 0.4962,  ..., 0.5136, 0.6008, 0.6182],\n",
            "         [0.5485, 0.4962, 0.5311,  ..., 0.5659, 0.6182, 0.6531],\n",
            "         [0.5834, 0.5485, 0.5311,  ..., 0.5659, 0.5834, 0.5834],\n",
            "         ...,\n",
            "         [0.4614, 0.4091, 0.3568,  ..., 0.3568, 0.3742, 0.3568],\n",
            "         [0.4091, 0.3742, 0.3045,  ..., 0.3045, 0.3219, 0.3219],\n",
            "         [0.3393, 0.3568, 0.3393,  ..., 0.2696, 0.3045, 0.3045]]]), tensor(1))\n",
            "Successfully unpacked batch 141\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 141\n",
            "\n",
            "Batch 142 type: <class 'tuple'>\n",
            "Batch 142 content: (tensor([[[-0.6452, -0.5082, -0.6109,  ...,  0.3309,  0.3481,  0.2282],\n",
            "         [-0.7137, -0.7308, -0.6109,  ...,  0.4337,  0.3994,  0.2282],\n",
            "         [-0.6794, -0.6109, -0.4911,  ...,  0.3481,  0.3652,  0.1768],\n",
            "         ...,\n",
            "         [ 1.3413,  1.3755,  1.3242,  ...,  0.8961,  0.8961,  0.8789],\n",
            "         [ 1.2728,  1.2899,  1.3242,  ...,  0.9303,  0.8961,  0.8618],\n",
            "         [ 1.2728,  1.2728,  1.2385,  ...,  0.9132,  0.9132,  0.8618]],\n",
            "\n",
            "        [[-0.7402, -0.6176, -0.7752,  ...,  0.0826,  0.1527,  0.0651],\n",
            "         [-0.9328, -0.9328, -0.8277,  ...,  0.1702,  0.2052,  0.0476],\n",
            "         [-0.8978, -0.7577, -0.6352,  ...,  0.1176,  0.1527, -0.0574],\n",
            "         ...,\n",
            "         [ 0.6429,  0.6604,  0.6254,  ...,  0.1702,  0.1702,  0.2052],\n",
            "         [ 0.6429,  0.6429,  0.6604,  ...,  0.1877,  0.1702,  0.1702],\n",
            "         [ 0.6779,  0.6429,  0.6078,  ...,  0.2052,  0.2577,  0.2227]],\n",
            "\n",
            "        [[-0.7587, -0.5844, -0.6541,  ...,  0.1302,  0.2173,  0.1476],\n",
            "         [-0.9504, -0.9504, -0.8284,  ...,  0.1999,  0.2522,  0.1476],\n",
            "         [-0.8633, -0.7936, -0.6890,  ...,  0.1476,  0.2348,  0.0431],\n",
            "         ...,\n",
            "         [ 0.4614,  0.4788,  0.4265,  ...,  0.2173,  0.1999,  0.1999],\n",
            "         [ 0.4265,  0.4439,  0.4614,  ...,  0.2173,  0.1651,  0.1825],\n",
            "         [ 0.4962,  0.4788,  0.4439,  ...,  0.1999,  0.2173,  0.2173]]]), tensor(0))\n",
            "Successfully unpacked batch 142\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 142\n",
            "\n",
            "Batch 143 type: <class 'tuple'>\n",
            "Batch 143 content: (tensor([[[ 0.6221,  0.6221,  0.6221,  ...,  1.3070,  1.3413,  1.3242],\n",
            "         [ 0.6221,  0.5878,  0.5878,  ...,  1.3242,  1.3413,  1.3584],\n",
            "         [ 0.6734,  0.6392,  0.6049,  ...,  1.3413,  1.3413,  1.3755],\n",
            "         ...,\n",
            "         [ 0.8276,  0.8104,  0.8618,  ...,  1.3413,  1.3413,  1.3584],\n",
            "         [ 0.9132,  0.8618,  0.8961,  ...,  1.3755,  1.3584,  1.3584],\n",
            "         [ 0.9817,  0.9474,  0.9132,  ...,  1.3755,  1.4098,  1.3755]],\n",
            "\n",
            "        [[-0.1800, -0.1625, -0.1450,  ...,  1.3782,  1.4132,  1.3782],\n",
            "         [-0.2150, -0.1975, -0.2150,  ...,  1.3957,  1.3957,  1.3782],\n",
            "         [-0.2150, -0.2325, -0.2850,  ...,  1.4132,  1.4132,  1.3957],\n",
            "         ...,\n",
            "         [ 0.0301,  0.0301,  0.0476,  ...,  1.3957,  1.3782,  1.3957],\n",
            "         [ 0.0476,  0.0651,  0.1352,  ...,  1.4132,  1.3957,  1.3957],\n",
            "         [ 0.1001,  0.1001,  0.1352,  ...,  1.3782,  1.4132,  1.4132]],\n",
            "\n",
            "        [[-0.2010, -0.1661, -0.1487,  ...,  1.5245,  1.5594,  1.5420],\n",
            "         [-0.1661, -0.1661, -0.2010,  ...,  1.5594,  1.5594,  1.5420],\n",
            "         [-0.1312, -0.1835, -0.2532,  ...,  1.5594,  1.5594,  1.5245],\n",
            "         ...,\n",
            "         [ 0.0082, -0.0267,  0.0082,  ...,  1.4200,  1.3851,  1.4025],\n",
            "         [-0.0441, -0.0441,  0.0779,  ...,  1.4200,  1.3851,  1.4025],\n",
            "         [ 0.0605,  0.0256,  0.0953,  ...,  1.4548,  1.4548,  1.4548]]]), tensor(0))\n",
            "Successfully unpacked batch 143\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 143\n",
            "\n",
            "Batch 144 type: <class 'tuple'>\n",
            "Batch 144 content: (tensor([[[1.1187, 1.0844, 1.0159,  ..., 1.6667, 1.5982, 1.5982],\n",
            "         [1.1872, 1.1529, 1.0673,  ..., 1.6838, 1.5982, 1.6495],\n",
            "         [1.2214, 1.1529, 1.1187,  ..., 1.6667, 1.6324, 1.6324],\n",
            "         ...,\n",
            "         [1.2557, 1.2899, 1.3584,  ..., 1.5810, 1.6495, 1.7009],\n",
            "         [1.2728, 1.3755, 1.4269,  ..., 1.6495, 1.6667, 1.6838],\n",
            "         [1.3070, 1.4269, 1.4783,  ..., 1.5810, 1.6153, 1.7009]],\n",
            "\n",
            "        [[0.6254, 0.6078, 0.5553,  ..., 0.6954, 0.6254, 0.5903],\n",
            "         [0.5903, 0.6078, 0.5903,  ..., 0.7304, 0.6429, 0.6604],\n",
            "         [0.5728, 0.5728, 0.6254,  ..., 0.7304, 0.7129, 0.6779],\n",
            "         ...,\n",
            "         [0.5378, 0.5728, 0.6429,  ..., 0.3978, 0.4153, 0.4678],\n",
            "         [0.5378, 0.6078, 0.6779,  ..., 0.4153, 0.4328, 0.4678],\n",
            "         [0.5553, 0.6604, 0.7129,  ..., 0.4328, 0.4503, 0.5203]],\n",
            "\n",
            "        [[0.6705, 0.6531, 0.5834,  ..., 0.5311, 0.4091, 0.3742],\n",
            "         [0.6705, 0.6531, 0.6182,  ..., 0.5311, 0.4091, 0.4091],\n",
            "         [0.5834, 0.5659, 0.5834,  ..., 0.5136, 0.4614, 0.4265],\n",
            "         ...,\n",
            "         [0.5659, 0.5659, 0.6182,  ..., 0.2522, 0.3045, 0.3568],\n",
            "         [0.6008, 0.6705, 0.7054,  ..., 0.2696, 0.3045, 0.3568],\n",
            "         [0.6356, 0.7402, 0.8099,  ..., 0.3045, 0.3393, 0.4265]]]), tensor(0))\n",
            "Successfully unpacked batch 144\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 144\n",
            "\n",
            "Batch 145 type: <class 'tuple'>\n",
            "Batch 145 content: (tensor([[[ 1.9064,  1.9749,  1.9235,  ...,  0.9132,  0.9303,  0.9474],\n",
            "         [ 1.8722,  1.9235,  1.9578,  ...,  0.9303,  0.9303,  0.9303],\n",
            "         [ 1.8379,  1.8722,  1.9578,  ...,  0.9303,  0.8618,  0.8789],\n",
            "         ...,\n",
            "         [ 1.5810,  1.5982,  1.6495,  ...,  0.8789,  0.9303,  0.9646],\n",
            "         [ 1.5982,  1.5810,  1.6153,  ...,  0.8447,  0.8961,  0.9303],\n",
            "         [ 1.5810,  1.5810,  1.6153,  ...,  0.8961,  0.8789,  0.8961]],\n",
            "\n",
            "        [[ 1.2381,  1.3431,  1.3256,  ...,  0.8704,  0.8880,  0.8880],\n",
            "         [ 1.2206,  1.3081,  1.3782,  ...,  0.8354,  0.8704,  0.8880],\n",
            "         [ 1.1856,  1.2556,  1.3782,  ...,  0.8004,  0.8004,  0.8704],\n",
            "         ...,\n",
            "         [ 0.2752,  0.3102,  0.3627,  ...,  0.8529,  0.8704,  0.8880],\n",
            "         [ 0.2927,  0.2752,  0.3102,  ...,  0.8704,  0.8704,  0.9055],\n",
            "         [ 0.2927,  0.2927,  0.3277,  ...,  0.9405,  0.9055,  0.8880]],\n",
            "\n",
            "        [[ 1.2457,  1.3328,  1.3154,  ...,  0.9319,  0.8971,  0.8971],\n",
            "         [ 1.1934,  1.2805,  1.3677,  ...,  0.8971,  0.8971,  0.9319],\n",
            "         [ 1.1411,  1.1934,  1.3328,  ...,  0.8797,  0.8622,  0.8971],\n",
            "         ...,\n",
            "         [-0.1312, -0.1138, -0.0790,  ...,  0.8622,  0.8622,  0.8971],\n",
            "         [-0.0964, -0.1138, -0.0964,  ...,  0.8448,  0.8971,  0.9319],\n",
            "         [-0.0615, -0.0441, -0.0267,  ...,  0.9145,  0.9319,  0.9319]]]), tensor(0))\n",
            "Successfully unpacked batch 145\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 145\n",
            "\n",
            "Batch 146 type: <class 'tuple'>\n",
            "Batch 146 content: (tensor([[[ 1.9407,  1.8722,  1.7865,  ...,  1.9407,  1.8722,  1.8208],\n",
            "         [ 1.9235,  1.8550,  1.7694,  ...,  1.9064,  1.8037,  1.7694],\n",
            "         [ 1.9064,  1.8550,  1.7865,  ...,  1.8379,  1.8893,  1.9235],\n",
            "         ...,\n",
            "         [ 2.0263,  2.0434,  2.0777,  ...,  1.7352,  1.8722,  1.8893],\n",
            "         [ 2.0434,  2.0434,  2.0777,  ...,  1.8379,  1.9235,  1.9064],\n",
            "         [ 2.0263,  2.0434,  2.0605,  ...,  1.8893,  1.9749,  1.9920]],\n",
            "\n",
            "        [[ 0.7479,  0.6779,  0.5553,  ...,  0.6078,  0.5903,  0.5903],\n",
            "         [ 0.7654,  0.7129,  0.5903,  ...,  0.5553,  0.5378,  0.5553],\n",
            "         [ 0.7654,  0.6954,  0.6254,  ...,  0.5028,  0.6078,  0.6954],\n",
            "         ...,\n",
            "         [ 0.7479,  0.7479,  0.7129,  ...,  0.3803,  0.5728,  0.5728],\n",
            "         [ 0.7654,  0.7129,  0.7129,  ...,  0.4853,  0.5728,  0.5203],\n",
            "         [ 0.7304,  0.6954,  0.6779,  ...,  0.5378,  0.5903,  0.5728]],\n",
            "\n",
            "        [[ 0.0082, -0.0615, -0.1835,  ...,  0.1999,  0.1476,  0.1302],\n",
            "         [-0.0267, -0.1312, -0.2881,  ...,  0.1999,  0.1476,  0.1476],\n",
            "         [-0.0267, -0.0964, -0.2184,  ...,  0.1128,  0.1999,  0.3045],\n",
            "         ...,\n",
            "         [ 0.0256,  0.0082,  0.0082,  ..., -0.1835,  0.0082,  0.0082],\n",
            "         [-0.0092, -0.0267, -0.0092,  ..., -0.0615,  0.0256, -0.0267],\n",
            "         [-0.0441, -0.0790, -0.0441,  ...,  0.0082,  0.0431, -0.0092]]]), tensor(0))\n",
            "Successfully unpacked batch 146\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 146\n",
            "\n",
            "Batch 147 type: <class 'tuple'>\n",
            "Batch 147 content: (tensor([[[-1.6384, -1.6384, -1.4500,  ...,  0.7762,  0.7762,  0.7419],\n",
            "         [-1.4843, -1.7069, -1.5699,  ...,  0.7591,  0.7248,  0.7077],\n",
            "         [-1.4329, -1.6727, -1.6384,  ...,  0.7077,  0.7248,  0.6906],\n",
            "         ...,\n",
            "         [-1.0733, -1.0904, -1.0904,  ...,  0.9132,  0.8961,  0.9132],\n",
            "         [-1.0733, -1.0390, -1.0562,  ...,  0.8789,  0.8618,  0.8789],\n",
            "         [-1.1075, -1.0390, -1.0390,  ...,  0.9474,  0.8961,  0.9132]],\n",
            "\n",
            "        [[-1.5280, -1.5280, -1.3354,  ...,  0.6779,  0.6604,  0.6779],\n",
            "         [-1.3880, -1.5630, -1.4405,  ...,  0.6779,  0.6604,  0.6779],\n",
            "         [-1.2654, -1.4930, -1.4580,  ...,  0.6779,  0.6954,  0.6954],\n",
            "         ...,\n",
            "         [-1.1253, -1.1253, -1.1429,  ...,  0.8354,  0.8004,  0.8179],\n",
            "         [-1.1429, -1.1429, -1.1779,  ...,  0.8529,  0.8179,  0.8354],\n",
            "         [-1.2479, -1.2129, -1.2479,  ...,  0.8179,  0.7829,  0.8179]],\n",
            "\n",
            "        [[-1.4210, -1.4036, -1.2293,  ...,  0.7576,  0.7402,  0.7228],\n",
            "         [-1.2990, -1.4907, -1.3687,  ...,  0.7228,  0.6705,  0.6879],\n",
            "         [-1.1944, -1.4384, -1.4036,  ...,  0.6879,  0.7054,  0.7228],\n",
            "         ...,\n",
            "         [-1.2293, -1.2467, -1.2467,  ...,  0.8971,  0.8797,  0.9145],\n",
            "         [-1.2119, -1.2467, -1.2816,  ...,  0.9145,  0.8797,  0.8971],\n",
            "         [-1.2816, -1.2641, -1.2816,  ...,  0.8797,  0.8622,  0.8797]]]), tensor(3))\n",
            "Successfully unpacked batch 147\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 147\n",
            "\n",
            "Batch 148 type: <class 'tuple'>\n",
            "Batch 148 content: (tensor([[[ 0.3481,  0.3994,  0.3481,  ...,  0.1939,  0.1768,  0.2111],\n",
            "         [ 0.3481,  0.3138,  0.2967,  ...,  0.1597,  0.1426,  0.1768],\n",
            "         [ 0.2796,  0.2282,  0.2453,  ...,  0.1083,  0.0912,  0.1597],\n",
            "         ...,\n",
            "         [ 0.1597,  0.1939,  0.2111,  ...,  0.6049,  0.6049,  0.6392],\n",
            "         [ 0.3481,  0.3481,  0.3138,  ...,  0.6563,  0.6221,  0.6221],\n",
            "         [ 0.4679,  0.4679,  0.4508,  ...,  0.6906,  0.6906,  0.6906]],\n",
            "\n",
            "        [[ 0.1176,  0.1176,  0.0651,  ..., -0.0049, -0.0224,  0.0126],\n",
            "         [ 0.1001,  0.0476,  0.0476,  ..., -0.0049, -0.0399, -0.0049],\n",
            "         [ 0.0476,  0.0126,  0.0826,  ..., -0.0749, -0.1099, -0.0924],\n",
            "         ...,\n",
            "         [-0.0924, -0.0399,  0.0301,  ...,  0.3978,  0.3803,  0.3627],\n",
            "         [-0.0224,  0.0476,  0.1001,  ...,  0.4153,  0.3803,  0.3452],\n",
            "         [ 0.1001,  0.1527,  0.2052,  ...,  0.4153,  0.4153,  0.3627]],\n",
            "\n",
            "        [[ 0.2348,  0.2696,  0.2173,  ...,  0.1825,  0.1476,  0.1651],\n",
            "         [ 0.2696,  0.2522,  0.2522,  ...,  0.1999,  0.1651,  0.1825],\n",
            "         [ 0.2522,  0.2348,  0.3045,  ...,  0.0953,  0.0953,  0.1128],\n",
            "         ...,\n",
            "         [-0.3055, -0.2358, -0.1661,  ...,  0.4788,  0.4962,  0.4614],\n",
            "         [-0.2184, -0.1312, -0.0441,  ...,  0.4962,  0.4788,  0.4091],\n",
            "         [-0.0615, -0.0441,  0.0605,  ...,  0.4788,  0.4788,  0.4439]]]), tensor(1))\n",
            "Successfully unpacked batch 148\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 148\n",
            "\n",
            "Batch 149 type: <class 'tuple'>\n",
            "Batch 149 content: (tensor([[[-0.0458, -0.0972, -0.1828,  ..., -0.3883, -0.3541, -0.3541],\n",
            "         [-0.1486, -0.1657, -0.1657,  ..., -0.4397, -0.3712, -0.3712],\n",
            "         [-0.1486, -0.1828, -0.1486,  ..., -0.6794, -0.6794, -0.6452],\n",
            "         ...,\n",
            "         [-0.2856, -0.3369, -0.3198,  ...,  0.1597,  0.1597,  0.1597],\n",
            "         [-0.2856, -0.3027, -0.3027,  ...,  0.2111,  0.1768,  0.1939],\n",
            "         [-0.2856, -0.3198, -0.3027,  ...,  0.2453,  0.2282,  0.2624]],\n",
            "\n",
            "        [[-0.3200, -0.3725, -0.3725,  ..., -0.4776, -0.3901, -0.3025],\n",
            "         [-0.3375, -0.3375, -0.3550,  ..., -0.4951, -0.3725, -0.3375],\n",
            "         [-0.3725, -0.3550, -0.3375,  ..., -0.7052, -0.7052, -0.6527],\n",
            "         ...,\n",
            "         [-0.4951, -0.4951, -0.4776,  ...,  0.2227,  0.2577,  0.2752],\n",
            "         [-0.4951, -0.5126, -0.5126,  ...,  0.2402,  0.2402,  0.2577],\n",
            "         [-0.4251, -0.4776, -0.4951,  ...,  0.2927,  0.2577,  0.2577]],\n",
            "\n",
            "        [[-0.1835, -0.2184, -0.2358,  ..., -0.2532, -0.1487, -0.0615],\n",
            "         [-0.2358, -0.1661, -0.1661,  ..., -0.2707, -0.1487, -0.0964],\n",
            "         [-0.3404, -0.2707, -0.2184,  ..., -0.4798, -0.4798, -0.4450],\n",
            "         ...,\n",
            "         [-0.1835, -0.2010, -0.2010,  ...,  0.5311,  0.5659,  0.5659],\n",
            "         [-0.1835, -0.1835, -0.2184,  ...,  0.6182,  0.6182,  0.6008],\n",
            "         [-0.1138, -0.1138, -0.1835,  ...,  0.6356,  0.6008,  0.5659]]]), tensor(0))\n",
            "Successfully unpacked batch 149\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 149\n",
            "\n",
            "Batch 150 type: <class 'tuple'>\n",
            "Batch 150 content: (tensor([[[ 0.3309,  0.3138,  0.3481,  ..., -0.3027, -0.3027, -0.2856],\n",
            "         [ 0.3309,  0.3309,  0.3138,  ..., -0.2684, -0.2856, -0.2342],\n",
            "         [ 0.3652,  0.3138,  0.2967,  ..., -0.2342, -0.3027, -0.3027],\n",
            "         ...,\n",
            "         [ 0.3823,  0.3652,  0.3652,  ...,  0.2624,  0.1083, -0.0116],\n",
            "         [ 0.3994,  0.4337,  0.4337,  ...,  0.3481,  0.1939,  0.0398],\n",
            "         [ 0.3994,  0.4679,  0.4679,  ...,  0.3138,  0.2282,  0.0912]],\n",
            "\n",
            "        [[-0.1099, -0.1450, -0.1099,  ..., -0.3550, -0.3725, -0.3725],\n",
            "         [-0.0574, -0.0749, -0.0924,  ..., -0.3725, -0.3550, -0.2850],\n",
            "         [-0.0749, -0.0924, -0.0924,  ..., -0.3901, -0.4251, -0.3725],\n",
            "         ...,\n",
            "         [-0.0924, -0.1099, -0.0924,  ...,  0.0651, -0.1275, -0.2325],\n",
            "         [-0.1450, -0.1275, -0.1099,  ...,  0.2052, -0.0049, -0.1625],\n",
            "         [-0.1800, -0.1450, -0.1450,  ...,  0.1352, -0.0399, -0.1625]],\n",
            "\n",
            "        [[-0.0441, -0.0441,  0.0082,  ..., -0.2358, -0.2010, -0.1661],\n",
            "         [-0.0092,  0.0082,  0.0256,  ..., -0.2010, -0.1835, -0.0964],\n",
            "         [-0.0092, -0.0267, -0.0441,  ..., -0.2707, -0.3055, -0.2707],\n",
            "         ...,\n",
            "         [-0.0615, -0.0790, -0.0441,  ...,  0.4265,  0.1999,  0.0605],\n",
            "         [-0.0615, -0.0092,  0.0256,  ...,  0.5136,  0.2522,  0.0779],\n",
            "         [-0.0615, -0.0092, -0.0092,  ...,  0.4091,  0.2173,  0.0431]]]), tensor(0))\n",
            "Successfully unpacked batch 150\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 150\n",
            "\n",
            "Batch 151 type: <class 'tuple'>\n",
            "Batch 151 content: (tensor([[[ 1.1872,  1.1015,  0.9817,  ..., -1.6042, -1.5699, -1.5699],\n",
            "         [ 1.0844,  1.0159,  0.9474,  ..., -1.6384, -1.6042, -1.5870],\n",
            "         [ 0.9988,  0.9988,  0.9646,  ..., -1.6213, -1.5870, -1.5699],\n",
            "         ...,\n",
            "         [ 0.9474,  0.9646,  0.9988,  ...,  0.7419,  0.5878,  0.6221],\n",
            "         [ 0.9474,  0.9474,  0.9817,  ...,  0.6906,  0.5707,  0.5707],\n",
            "         [ 0.9474,  0.9646,  0.9474,  ...,  0.7077,  0.5707,  0.5022]],\n",
            "\n",
            "        [[ 0.2577,  0.1702,  0.0476,  ..., -1.5980, -1.5805, -1.5805],\n",
            "         [ 0.2577,  0.1702,  0.0301,  ..., -1.6331, -1.6155, -1.6155],\n",
            "         [ 0.2052,  0.1877,  0.1527,  ..., -1.6506, -1.5980, -1.5980],\n",
            "         ...,\n",
            "         [-0.0049, -0.0049,  0.0301,  ...,  0.0301, -0.1625, -0.1625],\n",
            "         [ 0.0126, -0.0049,  0.0126,  ...,  0.0126, -0.1800, -0.2325],\n",
            "         [ 0.0651,  0.0476, -0.0224,  ..., -0.0049, -0.1625, -0.2675]],\n",
            "\n",
            "        [[ 0.2696,  0.1651,  0.0605,  ..., -1.6127, -1.6127, -1.6127],\n",
            "         [ 0.2173,  0.1476,  0.0605,  ..., -1.6127, -1.5953, -1.5779],\n",
            "         [ 0.1999,  0.1999,  0.1476,  ..., -1.5953, -1.5430, -1.5256],\n",
            "         ...,\n",
            "         [ 0.2173,  0.2173,  0.2173,  ...,  0.1302, -0.0615, -0.0441],\n",
            "         [ 0.1825,  0.1302,  0.0779,  ...,  0.0953, -0.1138, -0.1661],\n",
            "         [ 0.1825,  0.1651,  0.0953,  ...,  0.0953, -0.1138, -0.2358]]]), tensor(0))\n",
            "Successfully unpacked batch 151\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 151\n",
            "\n",
            "Batch 152 type: <class 'tuple'>\n",
            "Batch 152 content: (tensor([[[ 0.4508,  0.4337,  0.2967,  ...,  0.9817,  1.0331,  1.0502],\n",
            "         [ 0.4851,  0.4337,  0.2796,  ...,  0.8789,  0.9474,  0.9646],\n",
            "         [ 0.5022,  0.3823,  0.2111,  ...,  0.9132,  0.9474,  0.9303],\n",
            "         ...,\n",
            "         [ 1.2214,  1.2557,  1.3070,  ...,  1.1529,  1.1358,  1.1187],\n",
            "         [ 1.1872,  1.2385,  1.2728,  ...,  1.2385,  1.1872,  1.1700],\n",
            "         [ 1.2557,  1.2043,  1.2214,  ...,  1.1872,  1.1529,  1.1700]],\n",
            "\n",
            "        [[-0.3375, -0.3375, -0.4426,  ...,  0.0301,  0.0476,  0.0126],\n",
            "         [-0.3375, -0.3725, -0.5126,  ..., -0.0574, -0.0224, -0.0224],\n",
            "         [-0.3200, -0.4601, -0.6001,  ..., -0.0399, -0.0399, -0.0749],\n",
            "         ...,\n",
            "         [ 0.4503,  0.4503,  0.4503,  ..., -0.0749, -0.1099, -0.0924],\n",
            "         [ 0.4328,  0.4678,  0.4153,  ..., -0.0924, -0.1450, -0.1275],\n",
            "         [ 0.5378,  0.4503,  0.3803,  ..., -0.0749, -0.1099, -0.0924]],\n",
            "\n",
            "        [[-0.4798, -0.5147, -0.6193,  ..., -0.1312, -0.1312, -0.1661],\n",
            "         [-0.4798, -0.4798, -0.6193,  ..., -0.2358, -0.2358, -0.2532],\n",
            "         [-0.4101, -0.4798, -0.6018,  ..., -0.1835, -0.1835, -0.2532],\n",
            "         ...,\n",
            "         [ 0.1476,  0.1476,  0.1476,  ..., -0.1138, -0.2010, -0.2532],\n",
            "         [ 0.1825,  0.1651,  0.1476,  ..., -0.1487, -0.2532, -0.3055],\n",
            "         [ 0.2871,  0.1999,  0.1476,  ..., -0.2358, -0.2707, -0.3055]]]), tensor(0))\n",
            "Successfully unpacked batch 152\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 152\n",
            "\n",
            "Batch 153 type: <class 'tuple'>\n",
            "Batch 153 content: (tensor([[[ 0.6221,  0.5364,  0.5536,  ..., -0.8507, -0.7993, -0.8507],\n",
            "         [ 0.5022,  0.4679,  0.5193,  ..., -0.9534, -0.9363, -0.9705],\n",
            "         [ 0.4679,  0.5022,  0.5022,  ..., -1.1418, -1.1075, -1.0904],\n",
            "         ...,\n",
            "         [ 1.4612,  1.5297,  1.5810,  ...,  1.7694,  1.7180,  1.6838],\n",
            "         [ 1.5125,  1.5982,  1.6495,  ...,  1.7523,  1.6838,  1.6495],\n",
            "         [ 1.5468,  1.5982,  1.6324,  ...,  1.7694,  1.7352,  1.7009]],\n",
            "\n",
            "        [[-0.2325, -0.3200, -0.3025,  ..., -1.3529, -1.3354, -1.3354],\n",
            "         [-0.3200, -0.3901, -0.3025,  ..., -1.4230, -1.4230, -1.4230],\n",
            "         [-0.3025, -0.3375, -0.2675,  ..., -1.4930, -1.4930, -1.4755],\n",
            "         ...,\n",
            "         [ 0.1352,  0.1877,  0.2227,  ...,  0.6779,  0.6429,  0.6078],\n",
            "         [ 0.1352,  0.1702,  0.2227,  ...,  0.6779,  0.6078,  0.5553],\n",
            "         [ 0.1176,  0.1527,  0.1877,  ...,  0.6954,  0.6254,  0.5728]],\n",
            "\n",
            "        [[-0.3055, -0.4275, -0.3927,  ..., -1.4559, -1.4210, -1.4210],\n",
            "         [-0.3927, -0.4450, -0.3753,  ..., -1.4559, -1.4036, -1.4210],\n",
            "         [-0.3404, -0.3578, -0.3230,  ..., -1.4559, -1.4384, -1.4384],\n",
            "         ...,\n",
            "         [-0.2184, -0.1661, -0.1487,  ...,  0.1476,  0.0953,  0.0256],\n",
            "         [-0.1835, -0.1312, -0.0790,  ...,  0.1999,  0.0953,  0.0431],\n",
            "         [-0.1487, -0.0964, -0.0441,  ...,  0.2696,  0.2173,  0.1302]]]), tensor(0))\n",
            "Successfully unpacked batch 153\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 153\n",
            "\n",
            "Batch 154 type: <class 'tuple'>\n",
            "Batch 154 content: (tensor([[[ 1.6324,  1.6153,  1.5468,  ..., -1.7754, -1.7754, -1.8782],\n",
            "         [ 1.6495,  1.6324,  1.5810,  ..., -1.8097, -1.7925, -1.8782],\n",
            "         [ 1.6324,  1.6324,  1.5810,  ..., -1.8782, -1.8610, -1.8953],\n",
            "         ...,\n",
            "         [ 2.2489,  2.2489,  2.2489,  ...,  1.3927,  1.3242,  1.2557],\n",
            "         [ 2.2489,  2.2489,  2.2489,  ...,  1.4269,  1.3584,  1.3584],\n",
            "         [ 2.2489,  2.2489,  2.2489,  ...,  1.4783,  1.4269,  1.3755]],\n",
            "\n",
            "        [[ 0.4328,  0.4328,  0.3803,  ..., -1.7731, -1.7731, -1.8606],\n",
            "         [ 0.4503,  0.4328,  0.4153,  ..., -1.8256, -1.8081, -1.8606],\n",
            "         [ 0.3978,  0.3978,  0.3627,  ..., -1.8431, -1.8431, -1.8606],\n",
            "         ...,\n",
            "         [ 1.4832,  1.4482,  1.3957,  ...,  0.2402,  0.1702,  0.0651],\n",
            "         [ 1.5532,  1.4657,  1.4307,  ...,  0.2577,  0.1877,  0.1702],\n",
            "         [ 1.5532,  1.5007,  1.4657,  ...,  0.2927,  0.2402,  0.1702]],\n",
            "\n",
            "        [[ 0.2696,  0.2522,  0.1999,  ..., -1.6127, -1.6302, -1.7696],\n",
            "         [ 0.2871,  0.2696,  0.2522,  ..., -1.6824, -1.6824, -1.7347],\n",
            "         [ 0.2173,  0.2173,  0.2173,  ..., -1.7173, -1.7347, -1.7173],\n",
            "         ...,\n",
            "         [ 1.1062,  1.0365,  0.9668,  ..., -0.2707, -0.3404, -0.3753],\n",
            "         [ 1.1062,  1.0365,  1.0017,  ..., -0.2358, -0.2881, -0.2707],\n",
            "         [ 1.1062,  1.0539,  1.0365,  ..., -0.1835, -0.2532, -0.2881]]]), tensor(0))\n",
            "Successfully unpacked batch 154\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 154\n",
            "\n",
            "Batch 155 type: <class 'tuple'>\n",
            "Batch 155 content: (tensor([[[-0.9705, -0.6623, -0.7650,  ...,  0.0056,  0.0227,  0.0227],\n",
            "         [-1.2274, -1.2788, -1.3473,  ..., -0.0458, -0.0287, -0.0287],\n",
            "         [-1.2959, -1.3302, -1.3644,  ..., -0.0629, -0.0458, -0.0116],\n",
            "         ...,\n",
            "         [ 0.8104,  0.7591,  0.6906,  ...,  1.4783,  1.4783,  1.4440],\n",
            "         [ 0.7933,  0.7419,  0.6563,  ...,  1.4954,  1.4440,  1.4098],\n",
            "         [ 0.7591,  0.7419,  0.6221,  ...,  1.4783,  1.4440,  1.4440]],\n",
            "\n",
            "        [[-1.1779, -0.7577, -0.8102,  ..., -0.4951, -0.4776, -0.4776],\n",
            "         [-1.4405, -1.4405, -1.4580,  ..., -0.4776, -0.4776, -0.4951],\n",
            "         [-1.5280, -1.5455, -1.5630,  ..., -0.4776, -0.4776, -0.4426],\n",
            "         ...,\n",
            "         [ 0.1001,  0.0301, -0.0399,  ...,  0.3803,  0.3452,  0.3627],\n",
            "         [ 0.0826,  0.0301, -0.0749,  ...,  0.4503,  0.3452,  0.3277],\n",
            "         [ 0.0826,  0.0301, -0.1099,  ...,  0.4678,  0.3627,  0.3277]],\n",
            "\n",
            "        [[-1.0898, -0.6367, -0.6541,  ..., -0.4624, -0.4275, -0.4275],\n",
            "         [-1.3861, -1.3339, -1.3339,  ..., -0.4624, -0.4450, -0.4275],\n",
            "         [-1.5779, -1.5430, -1.5256,  ..., -0.4450, -0.4450, -0.4101],\n",
            "         ...,\n",
            "         [-0.2881, -0.3055, -0.3230,  ..., -0.0441, -0.1312, -0.1661],\n",
            "         [-0.2358, -0.2707, -0.2881,  ..., -0.0267, -0.1835, -0.2358],\n",
            "         [-0.2010, -0.2184, -0.2881,  ..., -0.0615, -0.1835, -0.2010]]]), tensor(0))\n",
            "Successfully unpacked batch 155\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 155\n",
            "\n",
            "Batch 156 type: <class 'tuple'>\n",
            "Batch 156 content: (tensor([[[-0.0458, -0.0458, -0.1486,  ..., -0.2856, -0.3198, -0.4911],\n",
            "         [-0.0458, -0.0458, -0.1143,  ..., -0.2513, -0.2856, -0.4054],\n",
            "         [-0.0629, -0.0629, -0.1314,  ..., -0.3027, -0.3198, -0.4226],\n",
            "         ...,\n",
            "         [ 0.2282,  0.2453,  0.2111,  ..., -0.3712, -0.3883, -0.3883],\n",
            "         [ 0.1939,  0.2111,  0.2111,  ..., -0.3883, -0.3883, -0.3712],\n",
            "         [ 0.2282,  0.2453,  0.2453,  ..., -0.4226, -0.4226, -0.3541]],\n",
            "\n",
            "        [[-0.4951, -0.4601, -0.5126,  ..., -0.4951, -0.5651, -0.7752],\n",
            "         [-0.4426, -0.4076, -0.4076,  ..., -0.4951, -0.5476, -0.7227],\n",
            "         [-0.4601, -0.3901, -0.4076,  ..., -0.5476, -0.5476, -0.6877],\n",
            "         ...,\n",
            "         [-0.4076, -0.4251, -0.4601,  ..., -0.7577, -0.7927, -0.8277],\n",
            "         [-0.4251, -0.4426, -0.4601,  ..., -0.8627, -0.8978, -0.8803],\n",
            "         [-0.4076, -0.4076, -0.4076,  ..., -0.8978, -0.9328, -0.8978]],\n",
            "\n",
            "        [[-0.3753, -0.3404, -0.3927,  ..., -0.4275, -0.4624, -0.6541],\n",
            "         [-0.3753, -0.3230, -0.3578,  ..., -0.4275, -0.4624, -0.6193],\n",
            "         [-0.4101, -0.3404, -0.3404,  ..., -0.4798, -0.4798, -0.6193],\n",
            "         ...,\n",
            "         [-0.4450, -0.4624, -0.4973,  ..., -1.0027, -1.0550, -1.0898],\n",
            "         [-0.4798, -0.4798, -0.4973,  ..., -1.0550, -1.1421, -1.1247],\n",
            "         [-0.4624, -0.4624, -0.4450,  ..., -1.0898, -1.1770, -1.1247]]]), tensor(0))\n",
            "Successfully unpacked batch 156\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 156\n",
            "\n",
            "Batch 157 type: <class 'tuple'>\n",
            "Batch 157 content: (tensor([[[-0.9534, -0.9705, -0.9877,  ..., -1.1247, -1.1760, -1.1247],\n",
            "         [-0.9534, -0.9363, -0.9020,  ..., -1.0733, -1.1418, -1.1075],\n",
            "         [-0.9192, -0.9020, -0.8678,  ..., -0.9877, -1.0219, -1.0219],\n",
            "         ...,\n",
            "         [-1.2274, -1.2274, -1.2445,  ..., -0.2171, -0.2171, -0.1657],\n",
            "         [-1.3130, -1.2617, -1.2617,  ..., -0.2856, -0.2342, -0.1314],\n",
            "         [-1.3302, -1.2959, -1.3130,  ..., -0.2856, -0.2171, -0.1657]],\n",
            "\n",
            "        [[-1.1954, -1.2304, -1.2479,  ..., -1.2479, -1.2479, -1.2129],\n",
            "         [-1.1954, -1.2129, -1.2129,  ..., -1.1604, -1.2304, -1.2129],\n",
            "         [-1.1954, -1.1954, -1.1954,  ..., -1.1779, -1.2129, -1.2304],\n",
            "         ...,\n",
            "         [-1.3529, -1.3529, -1.4230,  ..., -0.6352, -0.6702, -0.6176],\n",
            "         [-1.3354, -1.3179, -1.3880,  ..., -0.6176, -0.6352, -0.6001],\n",
            "         [-1.3529, -1.3354, -1.3880,  ..., -0.6176, -0.5826, -0.5651]],\n",
            "\n",
            "        [[-1.1596, -1.1944, -1.1770,  ..., -1.1596, -1.2119, -1.1770],\n",
            "         [-1.1596, -1.1770, -1.1247,  ..., -1.1247, -1.2119, -1.1944],\n",
            "         [-1.1247, -1.1247, -1.0898,  ..., -1.1247, -1.1596, -1.1596],\n",
            "         ...,\n",
            "         [-1.2293, -1.2293, -1.3164,  ..., -0.7413, -0.7761, -0.7238],\n",
            "         [-1.3339, -1.3164, -1.3513,  ..., -0.7761, -0.7587, -0.7064],\n",
            "         [-1.2816, -1.2990, -1.3513,  ..., -0.7413, -0.7413, -0.7413]]]), tensor(0))\n",
            "Successfully unpacked batch 157\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 157\n",
            "\n",
            "Batch 158 type: <class 'tuple'>\n",
            "Batch 158 content: (tensor([[[-0.6281, -0.5424, -0.5253,  ...,  1.2728,  1.2728,  1.2899],\n",
            "         [-0.5938, -0.5082, -0.5082,  ...,  1.2728,  1.2557,  1.2385],\n",
            "         [-0.5596, -0.4739, -0.4739,  ...,  1.2557,  1.2385,  1.2557],\n",
            "         ...,\n",
            "         [ 0.3481,  0.3994,  0.4679,  ...,  1.1015,  1.0844,  1.1358],\n",
            "         [ 0.3309,  0.3823,  0.4337,  ...,  1.1187,  1.1187,  1.1187],\n",
            "         [ 0.3309,  0.3309,  0.3138,  ...,  1.1529,  1.1872,  1.1358]],\n",
            "\n",
            "        [[-1.1779, -1.1253, -1.1078,  ...,  0.1176,  0.1352,  0.1702],\n",
            "         [-1.2129, -1.1604, -1.1253,  ...,  0.1176,  0.0826,  0.0651],\n",
            "         [-1.2129, -1.1429, -1.0903,  ...,  0.1001,  0.0651,  0.0826],\n",
            "         ...,\n",
            "         [-0.6877, -0.6527, -0.6001,  ..., -0.0399, -0.0224,  0.0476],\n",
            "         [-0.7052, -0.6702, -0.6001,  ..., -0.0224, -0.0049,  0.0126],\n",
            "         [-0.6527, -0.6702, -0.6877,  ..., -0.0224,  0.0301, -0.0224]],\n",
            "\n",
            "        [[-1.4559, -1.3687, -1.3339,  ..., -0.0267, -0.0092, -0.0267],\n",
            "         [-1.4733, -1.3861, -1.3339,  ..., -0.0615, -0.1138, -0.1487],\n",
            "         [-1.4384, -1.3513, -1.3339,  ..., -0.0964, -0.1835, -0.2184],\n",
            "         ...,\n",
            "         [-0.8981, -0.9156, -0.9156,  ..., -0.2358, -0.2707, -0.2532],\n",
            "         [-0.9678, -0.9678, -0.9504,  ..., -0.2358, -0.2358, -0.2532],\n",
            "         [-1.0027, -1.0550, -1.1073,  ..., -0.2184, -0.1487, -0.2184]]]), tensor(0))\n",
            "Successfully unpacked batch 158\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 158\n",
            "\n",
            "Batch 159 type: <class 'tuple'>\n",
            "Batch 159 content: (tensor([[[ 0.5536,  0.5878,  0.6049,  ...,  1.1187,  1.1015,  1.1529],\n",
            "         [ 0.5878,  0.5707,  0.6049,  ...,  1.1700,  1.1700,  1.2043],\n",
            "         [ 0.6221,  0.5878,  0.5707,  ...,  1.1700,  1.1358,  1.1700],\n",
            "         ...,\n",
            "         [ 1.1187,  1.1187,  1.1187,  ...,  1.3070,  1.3413,  1.3584],\n",
            "         [ 1.1700,  1.1700,  1.2043,  ...,  1.2899,  1.3413,  1.3584],\n",
            "         [ 1.1187,  1.1187,  1.1529,  ...,  1.3070,  1.3413,  1.3413]],\n",
            "\n",
            "        [[-0.3200, -0.2675, -0.1975,  ...,  0.1176,  0.1352,  0.1877],\n",
            "         [-0.2325, -0.2500, -0.1975,  ...,  0.1352,  0.1352,  0.1877],\n",
            "         [-0.1800, -0.2150, -0.2150,  ...,  0.1527,  0.1176,  0.1702],\n",
            "         ...,\n",
            "         [ 0.3102,  0.3277,  0.3102,  ...,  0.2577,  0.2927,  0.2752],\n",
            "         [ 0.3452,  0.3803,  0.4153,  ...,  0.2227,  0.2752,  0.2752],\n",
            "         [ 0.3277,  0.3627,  0.3803,  ...,  0.2052,  0.2402,  0.2402]],\n",
            "\n",
            "        [[-0.7761, -0.7761, -0.7587,  ..., -0.1138, -0.0790, -0.0092],\n",
            "         [-0.6541, -0.7064, -0.7064,  ..., -0.0964, -0.0441,  0.0431],\n",
            "         [-0.5844, -0.6541, -0.6715,  ..., -0.0964, -0.0615, -0.0092],\n",
            "         ...,\n",
            "         [-0.1138, -0.1312, -0.1835,  ..., -0.2184, -0.1312, -0.1138],\n",
            "         [-0.1312, -0.1312, -0.1312,  ..., -0.2010, -0.1138, -0.0790],\n",
            "         [-0.1661, -0.1835, -0.2010,  ..., -0.1835, -0.1312, -0.1138]]]), tensor(0))\n",
            "Successfully unpacked batch 159\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 159\n",
            "\n",
            "Batch 160 type: <class 'tuple'>\n",
            "Batch 160 content: (tensor([[[ 1.2214,  1.1872,  1.2043,  ...,  0.9474,  0.9646,  0.9474],\n",
            "         [ 1.2043,  1.2043,  1.1700,  ...,  0.8789,  0.9303,  0.9132],\n",
            "         [ 1.1700,  1.1529,  1.1529,  ...,  0.8276,  0.8618,  0.8447],\n",
            "         ...,\n",
            "         [ 1.7694,  1.7352,  1.7180,  ...,  1.6324,  1.5810,  1.5468],\n",
            "         [ 1.7694,  1.7352,  1.7865,  ...,  1.6153,  1.5468,  1.5125],\n",
            "         [ 1.8037,  1.7865,  1.8208,  ...,  1.5639,  1.4783,  1.4612]],\n",
            "\n",
            "        [[ 0.1176,  0.0651,  0.0301,  ...,  0.0301,  0.0301,  0.0301],\n",
            "         [ 0.1001,  0.0476, -0.0049,  ..., -0.0399,  0.0301,  0.0126],\n",
            "         [ 0.1001,  0.0301, -0.0049,  ..., -0.0574, -0.0049, -0.0224],\n",
            "         ...,\n",
            "         [ 0.7129,  0.6779,  0.6779,  ...,  0.6078,  0.5728,  0.5553],\n",
            "         [ 0.6954,  0.6604,  0.7129,  ...,  0.6429,  0.6078,  0.5903],\n",
            "         [ 0.6954,  0.6604,  0.6779,  ...,  0.6254,  0.6078,  0.6254]],\n",
            "\n",
            "        [[-0.0267, -0.0441, -0.0441,  ..., -0.1312, -0.1835, -0.2010],\n",
            "         [-0.0267, -0.0441, -0.0615,  ..., -0.1835, -0.1661, -0.2010],\n",
            "         [-0.0267, -0.0790, -0.0790,  ..., -0.2184, -0.1661, -0.2010],\n",
            "         ...,\n",
            "         [ 0.3742,  0.3742,  0.3916,  ...,  0.3219,  0.2348,  0.2173],\n",
            "         [ 0.3742,  0.3568,  0.4265,  ...,  0.3219,  0.2348,  0.2173],\n",
            "         [ 0.3742,  0.3393,  0.3916,  ...,  0.3219,  0.2871,  0.3045]]]), tensor(0))\n",
            "Successfully unpacked batch 160\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 160\n",
            "\n",
            "Batch 161 type: <class 'tuple'>\n",
            "Batch 161 content: (tensor([[[ 1.7352,  1.4783,  1.2214,  ...,  0.3138,  0.3994,  0.5364],\n",
            "         [ 1.3070,  1.1872,  0.8961,  ...,  0.3823,  0.4337,  0.7248],\n",
            "         [ 0.9646,  0.8618,  0.7419,  ...,  0.4337,  0.4166,  0.7591],\n",
            "         ...,\n",
            "         [ 1.8208,  1.8379,  1.8550,  ...,  1.1872,  1.0844,  1.0502],\n",
            "         [ 1.7694,  1.7865,  1.8550,  ...,  1.2214,  1.1187,  1.0502],\n",
            "         [ 1.9064,  1.8037,  1.8208,  ...,  1.2214,  1.0844,  0.9988]],\n",
            "\n",
            "        [[ 0.7479,  0.5028,  0.2227,  ..., -0.6001, -0.5126, -0.4076],\n",
            "         [ 0.3803,  0.2752, -0.0574,  ..., -0.5651, -0.5301, -0.2675],\n",
            "         [ 0.1527,  0.0301, -0.1625,  ..., -0.5476, -0.5826, -0.2850],\n",
            "         ...,\n",
            "         [ 0.5378,  0.5553,  0.5728,  ..., -0.2850, -0.3725, -0.4251],\n",
            "         [ 0.5553,  0.5553,  0.5728,  ..., -0.3375, -0.4076, -0.4426],\n",
            "         [ 0.7654,  0.6429,  0.6254,  ..., -0.3375, -0.4426, -0.4776]],\n",
            "\n",
            "        [[ 0.2173, -0.0441, -0.2707,  ..., -0.8981, -0.7761, -0.6541],\n",
            "         [-0.2010, -0.2707, -0.5147,  ..., -0.9330, -0.8633, -0.5495],\n",
            "         [-0.3230, -0.3927, -0.4973,  ..., -0.9504, -0.9504, -0.6018],\n",
            "         ...,\n",
            "         [-0.0092, -0.0092, -0.0267,  ..., -0.6890, -0.8807, -0.9504],\n",
            "         [-0.0964, -0.0790, -0.0441,  ..., -0.8110, -0.9330, -0.9678],\n",
            "         [ 0.0256, -0.0615, -0.0790,  ..., -0.8807, -0.9678, -1.0027]]]), tensor(0))\n",
            "Successfully unpacked batch 161\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 161\n",
            "\n",
            "Batch 162 type: <class 'tuple'>\n",
            "Batch 162 content: (tensor([[[ 0.9646,  1.0331,  1.0844,  ...,  0.4337,  0.4508,  0.5022],\n",
            "         [ 1.0159,  1.0159,  1.0331,  ...,  0.5022,  0.4508,  0.4679],\n",
            "         [ 0.9646,  0.9646,  0.9988,  ...,  0.5536,  0.5022,  0.4851],\n",
            "         ...,\n",
            "         [ 1.4098,  1.4269,  1.4440,  ...,  0.4508,  0.4508,  0.4337],\n",
            "         [ 1.3755,  1.3927,  1.4098,  ...,  0.4679,  0.4337,  0.4166],\n",
            "         [ 1.3927,  1.3584,  1.3755,  ...,  0.4679,  0.4508,  0.4337]],\n",
            "\n",
            "        [[-0.0924, -0.1275, -0.1099,  ..., -0.6001, -0.5301, -0.4776],\n",
            "         [-0.1275, -0.1625, -0.1800,  ..., -0.5651, -0.5826, -0.5651],\n",
            "         [-0.0924, -0.1450, -0.1450,  ..., -0.4776, -0.5126, -0.5126],\n",
            "         ...,\n",
            "         [ 0.1702,  0.2577,  0.2752,  ..., -0.4426, -0.4426, -0.4251],\n",
            "         [ 0.1702,  0.2402,  0.2752,  ..., -0.4426, -0.4601, -0.4076],\n",
            "         [ 0.2052,  0.2052,  0.2227,  ..., -0.4776, -0.4951, -0.4601]],\n",
            "\n",
            "        [[-0.2707, -0.2707, -0.2532,  ..., -0.8458, -0.8284, -0.8110],\n",
            "         [-0.3230, -0.3578, -0.3404,  ..., -0.8284, -0.8458, -0.8458],\n",
            "         [-0.3578, -0.4101, -0.3753,  ..., -0.8110, -0.8284, -0.8284],\n",
            "         ...,\n",
            "         [-0.1835, -0.1487, -0.1138,  ..., -0.7761, -0.7587, -0.7238],\n",
            "         [-0.2010, -0.1138, -0.0790,  ..., -0.7936, -0.7936, -0.7413],\n",
            "         [-0.0790, -0.0790, -0.0615,  ..., -0.8458, -0.8458, -0.8110]]]), tensor(2))\n",
            "Successfully unpacked batch 162\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 162\n",
            "\n",
            "Batch 163 type: <class 'tuple'>\n",
            "Batch 163 content: (tensor([[[-1.2788, -1.2788, -1.2959,  ..., -0.5424, -0.6623, -0.8507],\n",
            "         [-1.0904, -1.0733, -1.2103,  ..., -0.6623, -0.5596, -0.6623],\n",
            "         [-0.9363, -0.9192, -1.0048,  ..., -0.6965, -0.5596, -0.5424],\n",
            "         ...,\n",
            "         [ 0.4508,  0.4337,  0.4508,  ...,  0.5364,  0.5707,  0.5707],\n",
            "         [ 0.4166,  0.4166,  0.4166,  ...,  0.5536,  0.6049,  0.6049],\n",
            "         [ 0.4508,  0.4166,  0.4508,  ...,  0.5536,  0.5707,  0.5364]],\n",
            "\n",
            "        [[-1.1954, -1.1779, -1.1954,  ..., -0.6001, -0.6527, -0.8277],\n",
            "         [-1.0378, -1.0378, -1.1429,  ..., -0.7577, -0.6527, -0.7402],\n",
            "         [-0.9853, -0.9678, -1.0203,  ..., -0.8978, -0.7927, -0.8102],\n",
            "         ...,\n",
            "         [ 0.2052,  0.2227,  0.2577,  ..., -0.0924, -0.0574, -0.0224],\n",
            "         [ 0.1352,  0.1702,  0.2052,  ..., -0.0749, -0.0399, -0.0224],\n",
            "         [ 0.1176,  0.1176,  0.1877,  ..., -0.0574, -0.0399, -0.0574]],\n",
            "\n",
            "        [[-1.0376, -1.0898, -1.1596,  ..., -0.5321, -0.5670, -0.7587],\n",
            "         [-0.8981, -0.9504, -1.1073,  ..., -0.7064, -0.5495, -0.6541],\n",
            "         [-0.8284, -0.8284, -0.9330,  ..., -0.7761, -0.6193, -0.6193],\n",
            "         ...,\n",
            "         [ 0.2696,  0.2871,  0.3219,  ..., -0.2184, -0.2358, -0.2532],\n",
            "         [ 0.1999,  0.2522,  0.3045,  ..., -0.2010, -0.1835, -0.2184],\n",
            "         [ 0.1825,  0.1999,  0.2871,  ..., -0.1312, -0.1487, -0.2184]]]), tensor(0))\n",
            "Successfully unpacked batch 163\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 163\n",
            "\n",
            "Batch 164 type: <class 'tuple'>\n",
            "Batch 164 content: (tensor([[[ 0.0912,  0.0912,  0.0227,  ...,  0.3138,  0.3138,  0.2967],\n",
            "         [ 0.1254,  0.1083,  0.1083,  ...,  0.2624,  0.2967,  0.2624],\n",
            "         [ 0.0912,  0.0569,  0.1083,  ...,  0.2453,  0.2624,  0.2282],\n",
            "         ...,\n",
            "         [ 0.6563,  0.6906,  0.7591,  ...,  0.8618,  0.8961,  0.8961],\n",
            "         [ 0.6906,  0.7077,  0.7591,  ...,  0.8276,  0.8447,  0.8618],\n",
            "         [ 0.7591,  0.7248,  0.7419,  ...,  0.8447,  0.8447,  0.8618]],\n",
            "\n",
            "        [[-0.2675, -0.1800, -0.1800,  ..., -0.0924, -0.0399, -0.0574],\n",
            "         [-0.2850, -0.2500, -0.1800,  ..., -0.1099, -0.0574, -0.0574],\n",
            "         [-0.2850, -0.3025, -0.2325,  ..., -0.1275, -0.0749, -0.0924],\n",
            "         ...,\n",
            "         [ 0.4153,  0.4328,  0.4678,  ...,  0.5553,  0.6078,  0.6078],\n",
            "         [ 0.4153,  0.4153,  0.4678,  ...,  0.5728,  0.6078,  0.6254],\n",
            "         [ 0.4678,  0.4328,  0.4503,  ...,  0.5378,  0.5378,  0.5553]],\n",
            "\n",
            "        [[-0.0790, -0.0441, -0.0964,  ..., -0.0441,  0.0256,  0.0082],\n",
            "         [-0.0964, -0.1138, -0.0790,  ..., -0.0964, -0.0441, -0.0615],\n",
            "         [-0.1312, -0.2184, -0.1661,  ..., -0.1138, -0.0615, -0.0964],\n",
            "         ...,\n",
            "         [ 0.5311,  0.5311,  0.5311,  ...,  0.6705,  0.6705,  0.6531],\n",
            "         [ 0.5659,  0.5485,  0.5834,  ...,  0.6182,  0.6356,  0.6531],\n",
            "         [ 0.6182,  0.5834,  0.5834,  ...,  0.5485,  0.5834,  0.6182]]]), tensor(1))\n",
            "Successfully unpacked batch 164\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 164\n",
            "\n",
            "Batch 165 type: <class 'tuple'>\n",
            "Batch 165 content: (tensor([[[-1.3987, -1.4158, -1.4843,  ..., -1.5699, -1.6042, -1.6727],\n",
            "         [-1.2959, -1.2959, -1.3473,  ..., -1.6042, -1.6555, -1.7412],\n",
            "         [-1.2617, -1.2445, -1.2617,  ..., -1.5528, -1.6555, -1.7754],\n",
            "         ...,\n",
            "         [-1.5185, -1.5014, -1.5357,  ..., -0.3541, -0.3198, -0.2856],\n",
            "         [-1.4500, -1.4672, -1.4843,  ..., -0.2856, -0.2513, -0.2513],\n",
            "         [-1.3644, -1.3815, -1.3987,  ..., -0.2684, -0.2684, -0.2684]],\n",
            "\n",
            "        [[-1.4055, -1.4230, -1.4405,  ..., -1.5105, -1.5630, -1.6506],\n",
            "         [-1.4580, -1.4580, -1.4930,  ..., -1.4755, -1.5455, -1.6506],\n",
            "         [-1.4755, -1.4580, -1.4930,  ..., -1.4230, -1.5280, -1.6331],\n",
            "         ...,\n",
            "         [-1.5280, -1.5455, -1.5980,  ..., -0.6352, -0.6001, -0.5826],\n",
            "         [-1.5280, -1.5630, -1.6155,  ..., -0.6877, -0.6352, -0.6176],\n",
            "         [-1.5280, -1.5980, -1.6331,  ..., -0.7052, -0.6702, -0.6176]],\n",
            "\n",
            "        [[-1.4210, -1.3861, -1.3861,  ..., -1.4384, -1.4384, -1.5081],\n",
            "         [-1.4210, -1.3861, -1.4210,  ..., -1.4384, -1.4733, -1.5430],\n",
            "         [-1.4733, -1.4384, -1.4384,  ..., -1.3513, -1.4384, -1.5430],\n",
            "         ...,\n",
            "         [-1.4036, -1.4036, -1.4384,  ..., -0.8458, -0.8110, -0.8110],\n",
            "         [-1.3687, -1.4036, -1.4559,  ..., -0.8110, -0.7761, -0.8110],\n",
            "         [-1.3513, -1.4036, -1.4384,  ..., -0.7936, -0.7761, -0.7936]]]), tensor(0))\n",
            "Successfully unpacked batch 165\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 165\n",
            "\n",
            "Batch 166 type: <class 'tuple'>\n",
            "Batch 166 content: (tensor([[[ 1.4440,  1.4440,  1.4783,  ...,  1.3584,  1.3242,  1.3242],\n",
            "         [ 1.4783,  1.4954,  1.4612,  ...,  1.3927,  1.3584,  1.3413],\n",
            "         [ 1.4954,  1.4783,  1.4440,  ...,  1.3927,  1.3584,  1.3413],\n",
            "         ...,\n",
            "         [ 0.7762,  0.8276,  0.8447,  ...,  0.9303,  0.9132,  0.8961],\n",
            "         [ 0.8447,  0.8447,  0.8447,  ...,  0.9303,  0.9132,  0.8789],\n",
            "         [ 0.8276,  0.8104,  0.8276,  ...,  0.9817,  0.9474,  0.9132]],\n",
            "\n",
            "        [[ 0.6429,  0.6604,  0.6954,  ...,  1.4832,  1.4657,  1.4657],\n",
            "         [ 0.6604,  0.6779,  0.6429,  ...,  1.5007,  1.5007,  1.4832],\n",
            "         [ 0.7129,  0.6954,  0.6429,  ...,  1.5182,  1.5007,  1.4832],\n",
            "         ...,\n",
            "         [-0.3025, -0.2500, -0.1975,  ...,  1.0280,  1.0105,  0.9755],\n",
            "         [-0.3025, -0.3200, -0.2675,  ...,  1.0630,  1.0455,  1.0105],\n",
            "         [-0.3375, -0.3200, -0.2325,  ...,  1.0805,  1.0630,  1.0455]],\n",
            "\n",
            "        [[ 0.6705,  0.6531,  0.6705,  ...,  1.8557,  1.8208,  1.7860],\n",
            "         [ 0.6705,  0.6531,  0.6356,  ...,  1.8557,  1.8208,  1.7860],\n",
            "         [ 0.7054,  0.6705,  0.6356,  ...,  1.8208,  1.7860,  1.7685],\n",
            "         ...,\n",
            "         [-0.3753, -0.3230, -0.3055,  ...,  1.1585,  1.1585,  1.1411],\n",
            "         [-0.3927, -0.4275, -0.3927,  ...,  1.2108,  1.1934,  1.1759],\n",
            "         [-0.4973, -0.4973, -0.4450,  ...,  1.2457,  1.2108,  1.2108]]]), tensor(0))\n",
            "Successfully unpacked batch 166\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 166\n",
            "\n",
            "Batch 167 type: <class 'tuple'>\n",
            "Batch 167 content: (tensor([[[1.3584, 1.3755, 1.4440,  ..., 1.7352, 1.7180, 1.7352],\n",
            "         [1.3242, 1.3755, 1.4269,  ..., 1.7180, 1.7523, 1.8037],\n",
            "         [1.3242, 1.4098, 1.4269,  ..., 1.7694, 1.8208, 1.8379],\n",
            "         ...,\n",
            "         [2.1290, 2.1290, 2.1119,  ..., 2.1119, 2.1119, 2.1290],\n",
            "         [2.1119, 2.0777, 2.1119,  ..., 2.1290, 2.1119, 2.1462],\n",
            "         [2.0948, 2.0605, 2.0605,  ..., 2.1462, 2.1633, 2.1633]],\n",
            "\n",
            "        [[0.4153, 0.3803, 0.4503,  ..., 1.0630, 1.1331, 1.2031],\n",
            "         [0.3978, 0.4153, 0.4853,  ..., 1.0805, 1.1856, 1.2731],\n",
            "         [0.3803, 0.4503, 0.5203,  ..., 1.1506, 1.2206, 1.2556],\n",
            "         ...,\n",
            "         [1.1155, 1.1331, 1.1331,  ..., 1.4657, 1.4657, 1.4832],\n",
            "         [1.0280, 1.0455, 1.1155,  ..., 1.4832, 1.4482, 1.4832],\n",
            "         [0.9930, 0.9755, 0.9930,  ..., 1.5357, 1.5532, 1.5357]],\n",
            "\n",
            "        [[0.1302, 0.1302, 0.2522,  ..., 1.0191, 1.0714, 1.1237],\n",
            "         [0.0431, 0.1128, 0.2173,  ..., 1.0539, 1.1411, 1.2631],\n",
            "         [0.0256, 0.1476, 0.2348,  ..., 1.1411, 1.2282, 1.2805],\n",
            "         ...,\n",
            "         [1.1062, 1.1062, 1.0714,  ..., 1.5768, 1.5768, 1.6117],\n",
            "         [1.1062, 1.0714, 1.1062,  ..., 1.5942, 1.5768, 1.6291],\n",
            "         [1.0539, 1.0365, 1.0191,  ..., 1.6117, 1.6291, 1.6465]]]), tensor(0))\n",
            "Successfully unpacked batch 167\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 167\n",
            "\n",
            "Batch 168 type: <class 'tuple'>\n",
            "Batch 168 content: (tensor([[[-1.6898, -1.6384, -1.6555,  ...,  0.7419,  1.0331,  0.9817],\n",
            "         [-1.6555, -1.6555, -1.7412,  ...,  0.8104,  0.9646,  0.9817],\n",
            "         [-1.6727, -1.7412, -1.7925,  ...,  0.9303,  1.0331,  1.0159],\n",
            "         ...,\n",
            "         [ 0.5364,  0.5022,  0.4508,  ...,  1.1358,  1.1529,  1.1700],\n",
            "         [ 0.4166,  0.4851,  0.5193,  ...,  1.1358,  1.1529,  1.1872],\n",
            "         [ 0.4508,  0.4679,  0.5364,  ...,  1.1700,  1.2043,  1.2557]],\n",
            "\n",
            "        [[-1.5455, -1.5280, -1.5980,  ...,  0.0301,  0.3452,  0.2927],\n",
            "         [-1.5455, -1.5630, -1.6681,  ...,  0.0826,  0.2577,  0.2577],\n",
            "         [-1.6331, -1.6681, -1.7031,  ...,  0.0826,  0.2052,  0.2052],\n",
            "         ...,\n",
            "         [-0.3025, -0.3375, -0.4601,  ...,  0.1352,  0.1176,  0.1001],\n",
            "         [-0.4076, -0.3901, -0.4251,  ...,  0.1176,  0.1001,  0.1001],\n",
            "         [-0.4076, -0.3901, -0.4076,  ...,  0.0476,  0.0826,  0.1176]],\n",
            "\n",
            "        [[-1.4210, -1.4210, -1.5081,  ..., -0.0964,  0.1651,  0.0605],\n",
            "         [-1.3861, -1.4384, -1.5604,  ..., -0.0790,  0.0431, -0.0267],\n",
            "         [-1.4559, -1.5081, -1.5604,  ..., -0.0441,  0.0256, -0.0441],\n",
            "         ...,\n",
            "         [-0.5670, -0.6018, -0.6541,  ..., -0.2358, -0.2358, -0.2184],\n",
            "         [-0.5670, -0.5321, -0.4973,  ..., -0.2010, -0.2010, -0.1835],\n",
            "         [-0.4973, -0.4798, -0.4624,  ..., -0.2184, -0.1835, -0.1661]]]), tensor(0))\n",
            "Successfully unpacked batch 168\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 168\n",
            "\n",
            "Batch 169 type: <class 'tuple'>\n",
            "Batch 169 content: (tensor([[[ 1.1187,  1.1872,  1.2043,  ..., -1.3644, -1.0048, -0.7308],\n",
            "         [ 1.0502,  1.1529,  1.2557,  ..., -1.4158, -1.1589, -0.9020],\n",
            "         [ 1.0159,  1.0844,  1.2043,  ..., -1.3473, -1.2788, -1.0733],\n",
            "         ...,\n",
            "         [ 1.7865,  1.7180,  1.7180,  ...,  0.8618,  0.8104,  0.9817],\n",
            "         [ 1.8037,  1.7694,  1.7009,  ...,  1.0159,  1.2728,  1.4269],\n",
            "         [ 1.8037,  1.7865,  1.7352,  ...,  1.5810,  1.5810,  1.0844]],\n",
            "\n",
            "        [[ 0.0301,  0.1176,  0.0476,  ..., -1.4230, -1.1954, -1.0903],\n",
            "         [-0.0399,  0.0651,  0.1001,  ..., -1.4405, -1.3354, -1.2129],\n",
            "         [-0.0224,  0.0476,  0.1702,  ..., -1.4580, -1.4755, -1.4055],\n",
            "         ...,\n",
            "         [ 0.6429,  0.5728,  0.5903,  ...,  0.2227,  0.2052,  0.4503],\n",
            "         [ 0.6954,  0.6429,  0.5903,  ...,  0.4678,  0.8004,  0.9755],\n",
            "         [ 0.7129,  0.6779,  0.6078,  ...,  1.1155,  1.1506,  0.6604]],\n",
            "\n",
            "        [[-0.1835, -0.0964, -0.1138,  ..., -1.4384, -1.2467, -1.1770],\n",
            "         [-0.2707, -0.1312, -0.0092,  ..., -1.4036, -1.3164, -1.2467],\n",
            "         [-0.2532, -0.1835, -0.0441,  ..., -1.4036, -1.4210, -1.3861],\n",
            "         ...,\n",
            "         [ 0.1651,  0.0953,  0.0953,  ..., -0.3230, -0.2881, -0.0092],\n",
            "         [ 0.1999,  0.1302,  0.0605,  ..., -0.0441,  0.3045,  0.5485],\n",
            "         [ 0.1999,  0.1128,  0.0431,  ...,  0.6182,  0.6531,  0.1825]]]), tensor(0))\n",
            "Successfully unpacked batch 169\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 169\n",
            "\n",
            "Batch 170 type: <class 'tuple'>\n",
            "Batch 170 content: (tensor([[[ 1.8037,  1.8208,  1.7865,  ...,  0.2282,  0.2796,  0.2282],\n",
            "         [ 1.6324,  1.6667,  1.6667,  ...,  0.1768,  0.2282,  0.2111],\n",
            "         [ 1.7180,  1.8208,  1.9064,  ...,  0.1426,  0.1939,  0.2453],\n",
            "         ...,\n",
            "         [ 1.1700,  1.1700,  1.2043,  ...,  0.2624,  0.3309,  0.3138],\n",
            "         [ 1.2043,  1.1872,  1.1187,  ...,  0.2967,  0.3138,  0.2796],\n",
            "         [ 1.2728,  1.2214,  1.1872,  ...,  0.3652,  0.3481,  0.2967]],\n",
            "\n",
            "        [[ 0.8004,  0.8354,  0.8529,  ..., -0.0574, -0.0924, -0.1975],\n",
            "         [ 0.6429,  0.6604,  0.7129,  ..., -0.0924, -0.0924, -0.1800],\n",
            "         [ 0.7304,  0.8704,  1.0630,  ..., -0.1625, -0.1450, -0.1625],\n",
            "         ...,\n",
            "         [ 0.3277,  0.3277,  0.3627,  ..., -0.3200, -0.2850, -0.2850],\n",
            "         [ 0.3978,  0.3627,  0.3102,  ..., -0.3375, -0.3200, -0.3375],\n",
            "         [ 0.4328,  0.3803,  0.3452,  ..., -0.2850, -0.2675, -0.3375]],\n",
            "\n",
            "        [[ 0.2348,  0.2522,  0.2696,  ..., -0.2881, -0.2707, -0.3753],\n",
            "         [-0.0092,  0.0605,  0.1651,  ..., -0.2881, -0.2707, -0.3578],\n",
            "         [ 0.0779,  0.2871,  0.5659,  ..., -0.3578, -0.3578, -0.3578],\n",
            "         ...,\n",
            "         [-0.1487, -0.1138, -0.0790,  ..., -0.5321, -0.4798, -0.4973],\n",
            "         [-0.0615, -0.0615, -0.1487,  ..., -0.5844, -0.5321, -0.5495],\n",
            "         [-0.0092, -0.0441, -0.0790,  ..., -0.5147, -0.4798, -0.5321]]]), tensor(0))\n",
            "Successfully unpacked batch 170\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 170\n",
            "\n",
            "Batch 171 type: <class 'tuple'>\n",
            "Batch 171 content: (tensor([[[ 0.5536,  0.5364,  0.5364,  ...,  0.8447,  0.5193,  0.2111],\n",
            "         [ 0.5022,  0.5364,  0.5878,  ...,  1.1358,  0.9988,  0.8447],\n",
            "         [ 0.5707,  0.5878,  0.6563,  ...,  1.1700,  1.1872,  1.1358],\n",
            "         ...,\n",
            "         [ 1.5297,  1.5125,  1.5639,  ...,  0.0912, -0.6794, -1.0390],\n",
            "         [ 1.5297,  1.5125,  1.5468,  ..., -0.4054, -1.0562, -1.0733],\n",
            "         [ 1.5297,  1.5468,  1.5468,  ..., -0.8849, -1.2103, -0.9877]],\n",
            "\n",
            "        [[ 0.2402,  0.1877,  0.1176,  ...,  0.5203,  0.2752, -0.0399],\n",
            "         [ 0.1352,  0.1176,  0.1527,  ...,  0.7654,  0.6954,  0.5903],\n",
            "         [ 0.2052,  0.2052,  0.2227,  ...,  0.7654,  0.8179,  0.7829],\n",
            "         ...,\n",
            "         [ 1.1506,  1.1331,  1.1681,  ..., -0.1975, -0.7752, -0.9328],\n",
            "         [ 1.1681,  1.1681,  1.1681,  ..., -0.5476, -0.9853, -0.8452],\n",
            "         [ 1.1681,  1.2031,  1.1681,  ..., -0.8803, -1.0028, -0.6527]],\n",
            "\n",
            "        [[ 0.2173,  0.1999,  0.1651,  ...,  0.4788,  0.1999, -0.0964],\n",
            "         [ 0.1651,  0.1651,  0.1476,  ...,  0.8274,  0.6879,  0.5311],\n",
            "         [ 0.1651,  0.1825,  0.1999,  ...,  0.9319,  0.9319,  0.8448],\n",
            "         ...,\n",
            "         [ 1.2631,  1.2631,  1.2980,  ...,  0.2871,  0.0953,  0.2522],\n",
            "         [ 1.2457,  1.2457,  1.2805,  ...,  0.0605, -0.0092,  0.3916],\n",
            "         [ 1.2457,  1.2805,  1.2805,  ..., -0.1138,  0.0779,  0.5485]]]), tensor(1))\n",
            "Successfully unpacked batch 171\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 171\n",
            "\n",
            "Batch 172 type: <class 'tuple'>\n",
            "Batch 172 content: (tensor([[[ 0.1083,  0.1083,  0.1768,  ...,  1.0331,  1.0331,  0.9988],\n",
            "         [ 0.0912,  0.0227,  0.1597,  ...,  1.0673,  1.0844,  1.0502],\n",
            "         [ 0.1939,  0.1768,  0.2624,  ...,  1.0331,  1.0331,  0.9817],\n",
            "         ...,\n",
            "         [ 0.0912,  0.0912,  0.1254,  ...,  1.2385,  1.3070,  1.3070],\n",
            "         [ 0.0398,  0.0569,  0.0398,  ...,  1.2214,  1.3070,  1.3242],\n",
            "         [ 0.0569,  0.0912,  0.0569,  ...,  1.1872,  1.2899,  1.3242]],\n",
            "\n",
            "        [[-0.2850, -0.2325, -0.1975,  ...,  0.6078,  0.6254,  0.6254],\n",
            "         [-0.2850, -0.2850, -0.1800,  ...,  0.5553,  0.5728,  0.5728],\n",
            "         [-0.1625, -0.1625, -0.0924,  ...,  0.5728,  0.5728,  0.5553],\n",
            "         ...,\n",
            "         [-0.2850, -0.2850, -0.3025,  ...,  0.7304,  0.7479,  0.7829],\n",
            "         [-0.3025, -0.3025, -0.3550,  ...,  0.7479,  0.7829,  0.8004],\n",
            "         [-0.2675, -0.2675, -0.3550,  ...,  0.7829,  0.8179,  0.8004]],\n",
            "\n",
            "        [[-0.4275, -0.3753, -0.2881,  ...,  0.4439,  0.4962,  0.4788],\n",
            "         [-0.4275, -0.4450, -0.3230,  ...,  0.4962,  0.5485,  0.5136],\n",
            "         [-0.2707, -0.2881, -0.2184,  ...,  0.5485,  0.6008,  0.5659],\n",
            "         ...,\n",
            "         [-0.2184, -0.2184, -0.1835,  ...,  0.6008,  0.6705,  0.7228],\n",
            "         [-0.2358, -0.2358, -0.3055,  ...,  0.6182,  0.7054,  0.7576],\n",
            "         [-0.2010, -0.2358, -0.3578,  ...,  0.6531,  0.7228,  0.7576]]]), tensor(0))\n",
            "Successfully unpacked batch 172\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 172\n",
            "\n",
            "Batch 173 type: <class 'tuple'>\n",
            "Batch 173 content: (tensor([[[-0.1999, -0.1999, -0.1657,  ...,  1.2728,  1.1700,  1.1187],\n",
            "         [-0.2342, -0.2171, -0.1828,  ...,  1.3070,  1.1872,  1.1358],\n",
            "         [-0.3369, -0.3369, -0.2684,  ...,  1.3242,  1.1872,  1.1700],\n",
            "         ...,\n",
            "         [ 0.2796,  0.2453,  0.2453,  ...,  1.3242,  1.2214,  1.1358],\n",
            "         [ 0.2967,  0.2282,  0.2111,  ...,  1.2557,  1.1358,  1.1015],\n",
            "         [ 0.2967,  0.2624,  0.2282,  ...,  1.2214,  1.1358,  1.1187]],\n",
            "\n",
            "        [[-0.8803, -0.8627, -0.8803,  ...,  0.3803,  0.3452,  0.3102],\n",
            "         [-0.9153, -0.9153, -0.9153,  ...,  0.4328,  0.3803,  0.3452],\n",
            "         [-0.9328, -0.9503, -0.9153,  ...,  0.4328,  0.3803,  0.3627],\n",
            "         ...,\n",
            "         [-0.6702, -0.7052, -0.6877,  ..., -0.0049, -0.0924, -0.1625],\n",
            "         [-0.6527, -0.6877, -0.7052,  ...,  0.0126, -0.0749, -0.1099],\n",
            "         [-0.6352, -0.6702, -0.6877,  ...,  0.0126, -0.0749, -0.0924]],\n",
            "\n",
            "        [[-0.9330, -0.9330, -0.9504,  ...,  0.3219,  0.2522,  0.2173],\n",
            "         [-0.9678, -0.9678, -0.9853,  ...,  0.4265,  0.3742,  0.3393],\n",
            "         [-1.0027, -1.0376, -1.0027,  ...,  0.4265,  0.4091,  0.4265],\n",
            "         ...,\n",
            "         [-0.7936, -0.8807, -0.9330,  ...,  0.0256, -0.0267, -0.0964],\n",
            "         [-0.7761, -0.8981, -0.9678,  ...,  0.0082, -0.0790, -0.1138],\n",
            "         [-0.7761, -0.8807, -0.9504,  ..., -0.0092, -0.0790, -0.1138]]]), tensor(0))\n",
            "Successfully unpacked batch 173\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 173\n",
            "\n",
            "Batch 174 type: <class 'tuple'>\n",
            "Batch 174 content: (tensor([[[ 1.2728,  1.2728,  1.2385,  ...,  1.8208,  1.8208,  1.8208],\n",
            "         [ 1.2214,  1.2214,  1.2043,  ...,  1.7865,  1.8037,  1.8037],\n",
            "         [ 1.1700,  1.1700,  1.2385,  ...,  1.8037,  1.8037,  1.8037],\n",
            "         ...,\n",
            "         [ 2.0092,  2.0263,  2.0092,  ...,  1.9920,  1.9920,  1.9749],\n",
            "         [ 1.9920,  1.9749,  2.0092,  ...,  1.9920,  2.0092,  1.9920],\n",
            "         [ 1.9235,  1.9749,  2.0434,  ...,  1.9920,  2.0092,  2.0092]],\n",
            "\n",
            "        [[ 0.2577,  0.2752,  0.2227,  ...,  1.0280,  1.0105,  1.0455],\n",
            "         [ 0.2577,  0.2577,  0.2227,  ...,  1.0630,  1.0280,  1.0280],\n",
            "         [ 0.1702,  0.1702,  0.2227,  ...,  1.0805,  1.0280,  1.0105],\n",
            "         ...,\n",
            "         [ 1.1506,  1.1856,  1.2031,  ...,  0.9930,  0.9930,  0.9930],\n",
            "         [ 1.0630,  1.0630,  1.1506,  ...,  0.9580,  0.9755,  0.9930],\n",
            "         [ 0.9930,  1.0630,  1.1681,  ...,  0.9580,  0.9755,  1.0105]],\n",
            "\n",
            "        [[-0.0790, -0.0964, -0.1487,  ...,  0.9319,  0.9319,  0.9668],\n",
            "         [-0.0092, -0.0441, -0.0790,  ...,  0.9494,  0.9145,  0.9494],\n",
            "         [-0.0790, -0.0790, -0.0267,  ...,  0.9319,  0.8971,  0.9145],\n",
            "         ...,\n",
            "         [ 1.1759,  1.2108,  1.1934,  ...,  1.0714,  1.1062,  1.1062],\n",
            "         [ 1.0888,  1.1062,  1.1585,  ...,  1.0539,  1.0888,  1.1062],\n",
            "         [ 1.0365,  1.1062,  1.1934,  ...,  1.0539,  1.0714,  1.0888]]]), tensor(0))\n",
            "Successfully unpacked batch 174\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 174\n",
            "\n",
            "Batch 175 type: <class 'tuple'>\n",
            "Batch 175 content: (tensor([[[ 0.1426,  0.1939,  0.1426,  ...,  1.2043,  1.2557,  1.2557],\n",
            "         [ 0.1083,  0.1254,  0.1083,  ...,  1.2557,  1.2557,  1.2385],\n",
            "         [ 0.1083,  0.1254,  0.0741,  ...,  1.2728,  1.2728,  1.2557],\n",
            "         ...,\n",
            "         [ 0.2111,  0.2111,  0.2453,  ...,  1.8722,  1.8893,  1.8893],\n",
            "         [ 0.1426,  0.1768,  0.2282,  ...,  1.8208,  1.8550,  1.8722],\n",
            "         [ 0.1254,  0.1426,  0.2111,  ...,  1.7865,  1.8550,  1.9064]],\n",
            "\n",
            "        [[-0.5301, -0.5301, -0.6176,  ...,  0.3627,  0.3978,  0.4503],\n",
            "         [-0.5651, -0.6352, -0.7227,  ...,  0.3978,  0.3803,  0.3803],\n",
            "         [-0.5651, -0.6352, -0.7227,  ...,  0.4153,  0.3803,  0.3627],\n",
            "         ...,\n",
            "         [-0.4076, -0.3725, -0.3375,  ...,  1.0280,  1.0455,  1.0280],\n",
            "         [-0.4251, -0.3725, -0.3725,  ...,  0.9755,  1.0105,  1.0105],\n",
            "         [-0.4076, -0.4076, -0.4251,  ...,  0.9405,  0.9930,  1.0455]],\n",
            "\n",
            "        [[-0.7587, -0.7936, -0.8284,  ...,  0.2522,  0.2871,  0.3219],\n",
            "         [-0.8458, -0.8981, -0.9156,  ...,  0.3045,  0.3045,  0.3045],\n",
            "         [-0.8633, -0.8981, -0.9504,  ...,  0.3045,  0.2871,  0.2871],\n",
            "         ...,\n",
            "         [-0.8110, -0.7761, -0.7064,  ...,  1.1062,  1.1062,  1.1062],\n",
            "         [-0.8458, -0.8110, -0.7761,  ...,  1.0365,  1.0888,  1.1237],\n",
            "         [-0.8284, -0.8284, -0.8284,  ...,  0.9842,  1.0714,  1.1759]]]), tensor(1))\n",
            "Successfully unpacked batch 175\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 175\n",
            "\n",
            "Batch 176 type: <class 'tuple'>\n",
            "Batch 176 content: (tensor([[[1.2385, 1.2385, 1.2728,  ..., 1.7180, 1.8379, 2.0092],\n",
            "         [1.2385, 1.2385, 1.2385,  ..., 1.9407, 1.8379, 1.8379],\n",
            "         [1.2043, 1.2214, 1.2043,  ..., 1.8550, 2.0263, 1.9749],\n",
            "         ...,\n",
            "         [2.2489, 2.2318, 2.1975,  ..., 1.9578, 1.9920, 2.0605],\n",
            "         [2.2318, 2.2318, 2.1975,  ..., 2.0092, 2.0092, 2.0092],\n",
            "         [2.1975, 2.2318, 2.2318,  ..., 2.0092, 1.9407, 1.9920]],\n",
            "\n",
            "        [[0.3102, 0.3102, 0.3627,  ..., 1.4307, 1.5532, 1.7108],\n",
            "         [0.3102, 0.3102, 0.3277,  ..., 1.6583, 1.5357, 1.5357],\n",
            "         [0.2752, 0.3102, 0.3277,  ..., 1.5532, 1.7283, 1.6408],\n",
            "         ...,\n",
            "         [1.8333, 1.8158, 1.7633,  ..., 1.5357, 1.5532, 1.6057],\n",
            "         [1.9034, 1.9209, 1.8333,  ..., 1.5532, 1.5532, 1.5532],\n",
            "         [1.8683, 1.9034, 1.9209,  ..., 1.5532, 1.4832, 1.5357]],\n",
            "\n",
            "        [[0.0779, 0.0779, 0.1651,  ..., 1.2980, 1.4200, 1.6117],\n",
            "         [0.1128, 0.1128, 0.1825,  ..., 1.5768, 1.4374, 1.4025],\n",
            "         [0.1825, 0.1999, 0.1999,  ..., 1.4548, 1.6640, 1.5942],\n",
            "         ...,\n",
            "         [1.8383, 1.8208, 1.7685,  ..., 1.4722, 1.4897, 1.5420],\n",
            "         [1.8731, 1.8905, 1.8557,  ..., 1.5245, 1.4897, 1.4897],\n",
            "         [1.8383, 1.8731, 1.9254,  ..., 1.5420, 1.4722, 1.5071]]]), tensor(1))\n",
            "Successfully unpacked batch 176\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 176\n",
            "\n",
            "Batch 177 type: <class 'tuple'>\n",
            "Batch 177 content: (tensor([[[-0.3541, -0.2513, -0.5082,  ...,  1.1700,  1.1872,  1.1358],\n",
            "         [-0.3027, -0.1999, -0.4568,  ...,  1.2385,  1.1700,  1.0844],\n",
            "         [-0.4054, -0.2513, -0.4739,  ...,  1.2043,  1.1700,  1.1187],\n",
            "         ...,\n",
            "         [ 1.1358,  1.1015,  1.1187,  ...,  1.0844,  1.0331,  0.9646],\n",
            "         [ 1.1187,  1.0844,  1.1358,  ...,  1.0844,  1.0331,  0.9817],\n",
            "         [ 1.1358,  1.1700,  1.1529,  ...,  1.0331,  0.9474,  0.9817]],\n",
            "\n",
            "        [[-0.9678, -0.8102, -1.0028,  ...,  0.1176,  0.1176,  0.0476],\n",
            "         [-0.9328, -0.7577, -1.0028,  ...,  0.1527,  0.0651, -0.0224],\n",
            "         [-0.9328, -0.7577, -1.0028,  ...,  0.1176,  0.0651,  0.0126],\n",
            "         ...,\n",
            "         [ 0.4678,  0.3978,  0.3803,  ..., -0.0924, -0.1450, -0.1800],\n",
            "         [ 0.4328,  0.3627,  0.3627,  ..., -0.0749, -0.1275, -0.1625],\n",
            "         [ 0.3978,  0.3978,  0.3627,  ..., -0.0924, -0.1800, -0.1450]],\n",
            "\n",
            "        [[-1.1421, -1.0027, -1.2641,  ..., -0.0092,  0.0431, -0.0267],\n",
            "         [-1.0898, -0.9330, -1.1944,  ...,  0.0256, -0.0267, -0.0964],\n",
            "         [-1.0898, -0.9330, -1.1596,  ..., -0.0964, -0.1312, -0.1661],\n",
            "         ...,\n",
            "         [ 0.5834,  0.5136,  0.4788,  ..., -0.3230, -0.3578, -0.4101],\n",
            "         [ 0.5485,  0.4439,  0.4265,  ..., -0.3230, -0.3578, -0.3927],\n",
            "         [ 0.4788,  0.4439,  0.3916,  ..., -0.4101, -0.4973, -0.4624]]]), tensor(0))\n",
            "Successfully unpacked batch 177\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 177\n",
            "\n",
            "Batch 178 type: <class 'tuple'>\n",
            "Batch 178 content: (tensor([[[ 0.4337,  0.5022,  0.4679,  ...,  1.0159,  1.0331,  0.9988],\n",
            "         [ 0.4166,  0.4337,  0.3823,  ...,  1.0159,  0.9988,  0.9474],\n",
            "         [ 0.2796,  0.3652,  0.3138,  ...,  0.8961,  0.9132,  0.8789],\n",
            "         ...,\n",
            "         [ 1.2899,  1.2899,  1.2385,  ...,  1.5982,  1.6153,  1.5639],\n",
            "         [ 1.2899,  1.2899,  1.2385,  ...,  1.6153,  1.5982,  1.4954],\n",
            "         [ 1.3070,  1.2899,  1.2385,  ...,  1.5810,  1.5639,  1.5468]],\n",
            "\n",
            "        [[-0.0574, -0.0224, -0.0924,  ...,  0.2052,  0.2052,  0.1176],\n",
            "         [-0.0574, -0.0574, -0.1275,  ...,  0.1176,  0.0651, -0.0049],\n",
            "         [-0.2325, -0.1450, -0.1975,  ..., -0.0049, -0.0224, -0.0574],\n",
            "         ...,\n",
            "         [ 0.4153,  0.4153,  0.3803,  ...,  0.6604,  0.6604,  0.6429],\n",
            "         [ 0.4153,  0.4153,  0.4153,  ...,  0.6954,  0.6779,  0.6254],\n",
            "         [ 0.4153,  0.4153,  0.3978,  ...,  0.6779,  0.6779,  0.7304]],\n",
            "\n",
            "        [[-0.0964, -0.0092, -0.0092,  ...,  0.1999,  0.1999,  0.0779],\n",
            "         [-0.1138, -0.0441, -0.0441,  ...,  0.1302,  0.0605, -0.0615],\n",
            "         [-0.2532, -0.1138, -0.1138,  ...,  0.0256, -0.0092, -0.0790],\n",
            "         ...,\n",
            "         [ 0.0953,  0.0779,  0.0256,  ...,  0.4091,  0.4091,  0.4265],\n",
            "         [ 0.0605,  0.0605,  0.0082,  ...,  0.4788,  0.4614,  0.4265],\n",
            "         [ 0.0431,  0.0082, -0.0267,  ...,  0.4439,  0.4788,  0.5136]]]), tensor(0))\n",
            "Successfully unpacked batch 178\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 178\n",
            "\n",
            "Batch 179 type: <class 'tuple'>\n",
            "Batch 179 content: (tensor([[[0.9988, 0.9646, 0.9303,  ..., 1.2728, 1.2899, 1.3070],\n",
            "         [1.0159, 0.9646, 0.9303,  ..., 1.1700, 1.2214, 1.2557],\n",
            "         [0.9817, 0.9474, 0.9474,  ..., 1.1187, 1.1700, 1.1872],\n",
            "         ...,\n",
            "         [1.8379, 1.8893, 1.9749,  ..., 1.6667, 1.6324, 1.6838],\n",
            "         [2.0948, 2.0434, 1.9578,  ..., 1.7523, 1.8037, 1.8208],\n",
            "         [1.9749, 2.0434, 1.9064,  ..., 1.7865, 1.7523, 1.7352]],\n",
            "\n",
            "        [[0.5903, 0.6078, 0.6078,  ..., 1.0105, 1.0105, 1.0280],\n",
            "         [0.5553, 0.5378, 0.5728,  ..., 0.9580, 0.9755, 0.9755],\n",
            "         [0.5553, 0.5378, 0.5553,  ..., 0.9580, 0.9755, 0.9755],\n",
            "         ...,\n",
            "         [1.4307, 1.5007, 1.6408,  ..., 1.3606, 1.3957, 1.4657],\n",
            "         [1.6933, 1.6232, 1.5882,  ..., 1.4307, 1.5532, 1.6408],\n",
            "         [1.5707, 1.6232, 1.5357,  ..., 1.4307, 1.4832, 1.5182]],\n",
            "\n",
            "        [[0.4962, 0.4614, 0.4265,  ..., 1.0365, 1.0017, 1.0017],\n",
            "         [0.4614, 0.3916, 0.3568,  ..., 0.9145, 0.8971, 0.8971],\n",
            "         [0.4265, 0.3742, 0.3393,  ..., 0.8971, 0.8448, 0.8448],\n",
            "         ...,\n",
            "         [1.4025, 1.4897, 1.6465,  ..., 1.3677, 1.4025, 1.4897],\n",
            "         [1.6640, 1.6291, 1.5942,  ..., 1.4374, 1.5768, 1.6814],\n",
            "         [1.5071, 1.6117, 1.5594,  ..., 1.4374, 1.5071, 1.5594]]]), tensor(0))\n",
            "Successfully unpacked batch 179\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 179\n",
            "\n",
            "Batch 180 type: <class 'tuple'>\n",
            "Batch 180 content: (tensor([[[ 0.2111,  0.2111,  0.2282,  ..., -0.1828, -0.1657, -0.1486],\n",
            "         [ 0.2282,  0.2624,  0.3138,  ..., -0.2171, -0.1657, -0.0972],\n",
            "         [ 0.2624,  0.2967,  0.3481,  ..., -0.2171, -0.1828, -0.1143],\n",
            "         ...,\n",
            "         [ 0.0912,  0.0227, -0.0287,  ...,  0.0227,  0.0398,  0.0398],\n",
            "         [ 0.1083,  0.0741, -0.0116,  ...,  0.0569,  0.0569,  0.1083],\n",
            "         [ 0.1254,  0.1083,  0.0741,  ...,  0.0569,  0.1254,  0.0912]],\n",
            "\n",
            "        [[-0.4426, -0.4076, -0.3025,  ..., -0.6527, -0.6352, -0.6702],\n",
            "         [-0.4601, -0.4251, -0.3375,  ..., -0.7227, -0.6702, -0.6176],\n",
            "         [-0.4251, -0.4076, -0.3901,  ..., -0.7402, -0.7227, -0.6352],\n",
            "         ...,\n",
            "         [-0.3375, -0.3200, -0.3200,  ..., -0.3550, -0.3901, -0.3725],\n",
            "         [-0.3025, -0.2850, -0.2850,  ..., -0.3200, -0.3550, -0.3200],\n",
            "         [-0.3375, -0.3200, -0.3025,  ..., -0.3375, -0.2500, -0.2500]],\n",
            "\n",
            "        [[-0.3230, -0.3404, -0.3230,  ..., -0.6890, -0.6715, -0.6541],\n",
            "         [-0.3230, -0.3230, -0.3055,  ..., -0.7413, -0.6890, -0.5844],\n",
            "         [-0.2881, -0.2881, -0.2881,  ..., -0.7936, -0.7064, -0.5844],\n",
            "         ...,\n",
            "         [-0.4275, -0.4624, -0.5321,  ..., -0.3404, -0.3055, -0.2358],\n",
            "         [-0.4101, -0.4798, -0.5670,  ..., -0.2881, -0.2184, -0.1487],\n",
            "         [-0.4973, -0.5321, -0.5844,  ..., -0.2707, -0.1312, -0.1312]]]), tensor(1))\n",
            "Successfully unpacked batch 180\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 180\n",
            "\n",
            "Batch 181 type: <class 'tuple'>\n",
            "Batch 181 content: (tensor([[[ 0.9303,  0.9817,  0.9988,  ...,  0.6734,  0.7419,  0.7419],\n",
            "         [ 0.8961,  0.9817,  1.0331,  ...,  0.6221,  0.6563,  0.6734],\n",
            "         [ 0.8789,  0.9474,  1.0502,  ...,  0.6049,  0.6221,  0.6221],\n",
            "         ...,\n",
            "         [ 0.0398,  0.5022,  0.9132,  ...,  0.8276,  0.8447,  0.8104],\n",
            "         [ 0.1939,  0.5707,  0.8789,  ...,  0.7933,  0.8447,  0.8447],\n",
            "         [ 0.3994,  0.5707,  0.8447,  ...,  0.9132,  0.9303,  0.8961]],\n",
            "\n",
            "        [[ 0.5378,  0.6078,  0.6779,  ..., -0.1099, -0.0749, -0.0924],\n",
            "         [ 0.5378,  0.6078,  0.6954,  ..., -0.1450, -0.1450, -0.1800],\n",
            "         [ 0.5203,  0.5903,  0.7129,  ..., -0.1275, -0.1800, -0.2150],\n",
            "         ...,\n",
            "         [-0.2500,  0.2927,  0.7129,  ..., -0.1099, -0.1099, -0.2325],\n",
            "         [-0.0749,  0.3627,  0.6954,  ..., -0.1450, -0.1099, -0.1800],\n",
            "         [ 0.0651,  0.3452,  0.6429,  ..., -0.0574, -0.0924, -0.1450]],\n",
            "\n",
            "        [[ 0.5485,  0.6356,  0.7228,  ..., -0.2010, -0.1487, -0.1661],\n",
            "         [ 0.5311,  0.6531,  0.7751,  ..., -0.2358, -0.2707, -0.2707],\n",
            "         [ 0.4439,  0.5485,  0.7054,  ..., -0.2881, -0.3578, -0.3404],\n",
            "         ...,\n",
            "         [-0.1487,  0.3916,  0.8274,  ..., -0.1138, -0.0964, -0.1661],\n",
            "         [ 0.0082,  0.4265,  0.7925,  ..., -0.1487, -0.0964, -0.1312],\n",
            "         [ 0.1825,  0.4265,  0.7402,  ..., -0.0790, -0.0964, -0.1138]]]), tensor(0))\n",
            "Successfully unpacked batch 181\n",
            "Images shape: torch.Size([1, 3, 224, 224])\n",
            "Labels shape: torch.Size([1])\n",
            "Successfully processed batch 181\n",
            "\n",
            "Extracted features from 182 batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List contents of the project directory\n",
        "base_path = '/content/drive/MyDrive/ML final project/Trained_models/Classifier'\n",
        "print(f\"Contents of {base_path}:\")\n",
        "print(os.listdir(base_path))"
      ],
      "metadata": {
        "id": "ALUCHgOEZ5-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# 1. Add class weights to handle imbalance\n",
        "class_counts = np.bincount(true_labels)\n",
        "total_samples = len(true_labels)\n",
        "class_weights = torch.FloatTensor(total_samples / (len(class_counts) * class_counts))\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "\n",
        "# 2. Modify the training data with augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 3. Implement balanced sampling\n",
        "class_sample_counts = np.bincount(true_labels)\n",
        "weights = 1. / class_sample_counts\n",
        "samples_weights = weights[true_labels]\n",
        "sampler = WeightedRandomSampler(weights=samples_weights,\n",
        "                               num_samples=len(true_labels),\n",
        "                               replacement=True)\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/ML final project/datasets/EYE_IMAGES_FULL.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/drive/MyDrive/ML final project/datasets/EYE_IMAGES_FULL')  # Extract to a directory\n",
        "\n",
        "train_dataset = TestDataset(  # Assuming you are reusing your TestDataset class for the training data\n",
        "    image_dir='/content/drive/MyDrive/ML final project/datasets/EYE_IMAGES_FULL',\n",
        "    labels_csv='/content/drive/MyDrive/ML final project/datasets/iris_labels_full.csv'\n",
        ")\n",
        "\n",
        "# 4. Modify DataLoader to use the sampler\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    sampler=sampler,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "# 5. Add validation metrics\n",
        "def calculate_metrics(true_labels, predicted_labels):\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Per-class metrics\n",
        "    for idx, class_name in enumerate(color_to_idx.keys()):\n",
        "        class_precision = precision_score(true_labels, predicted_labels, average=None)[idx]\n",
        "        class_recall = recall_score(true_labels, predicted_labels, average=None)[idx]\n",
        "        class_f1 = f1_score(true_labels, predicted_labels, average=None)[idx]\n",
        "        print(f\"\\n{class_name}:\")\n",
        "        print(f\"Precision: {class_precision:.4f}\")\n",
        "        print(f\"Recall: {class_recall:.4f}\")\n",
        "        print(f\"F1 Score: {class_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loGe8k29kjxc",
        "outputId": "c62ad8bb-887e-4845-975a-469c521df573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CSV from: /content/drive/MyDrive/ML final project/datasets/iris_labels_full.csv\n",
            "CSV shape: (11101, 2)\n",
            "First few rows of CSV:\n",
            "        filename  label\n",
            "0  C1_S1_I1.tiff  brown\n",
            "1  C1_S1_I2.tiff  brown\n",
            "2  C1_S1_I3.tiff  brown\n",
            "3  C1_S1_I4.tiff  brown\n",
            "4  C1_S1_I5.tiff  brown\n",
            "\n",
            "Found 0 images in directory\n",
            "First few image files: []\n",
            "\n",
            "Successfully matched 0 images with labels\n",
            "Unique labels: ['brown' 'hazel' 'blue' 'green' 'gray']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nCreating visualizations...\")\n",
        "visualizer.plot_feature_space(test_features, true_labels)\n",
        "visualizer.plot_confusion_matrix(true_labels, predicted_labels)\n",
        "visualizer.plot_loss_history()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NW3p-eeW_SYc",
        "outputId": "ccf876bf-be42-4420-c05f-8badb8d14b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating visualizations...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will now try to improve the confusion matrix using methods such as validation metrics,"
      ],
      "metadata": {
        "id": "aQv-n1S7j9jB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "NRWK2Fa4bLyV",
        "outputId": "cc6cd5cf-0f91-449c-8035-1a81d9bbf287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_labels' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-db2405869777>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1. Add class weights to handle imbalance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_samples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_labels' is not defined"
          ]
        }
      ]
    }
  ]
}